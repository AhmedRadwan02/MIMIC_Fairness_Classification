{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 16:18:45.747197: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-14 16:18:45.769090: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-14 16:18:45.795258: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-14 16:18:45.803245: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-14 16:18:45.822085: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "                                          file_paths\n",
      "0  files/p10/p10000032/s50414267/02aa804e-bde0afd...\n",
      "1  files/p10/p10000032/s53189527/2a2277a9-b0ded15...\n",
      "2  files/p10/p10000032/s53911762/68b5c4b1-227d048...\n",
      "3  files/p10/p10000032/s53911762/fffabebf-74fd3a1...\n",
      "4  files/p10/p10000032/s56699142/ea030e7a-2e3b134...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# File path\n",
    "file_path = \"/home/ahmedyra/scratch/Dataset/generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0/SHA256SUMS.txt\"\n",
    "\n",
    "# Read the file and extract paths\n",
    "with open(file_path, \"r\") as file:\n",
    "    lines = [line.strip().split(maxsplit=1)[-1] for line in file if \"files/\" in line]  # Extract only paths\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(lines, columns=[\"file_paths\"])\n",
    "\n",
    "# Show first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 16:21:39,031 - INFO - Loaded labels: 227827 rows\n",
      "2025-03-14 16:21:39,339 - INFO - Found 243324 TFRecord files\n",
      "2025-03-14 16:21:39,339 - INFO - Sample paths: ['files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.tfrecord', 'files/p10/p10000032/s53189527/2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab.tfrecord']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Base path for dataset\n",
    "base_path = \"/home/ahmedyra/scratch/Dataset/generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0/\"\n",
    "\n",
    "# Load labels\n",
    "labels_path = \"/home/ahmedyra/scratch/Dataset/mimic-cxr-2.0.0-chexpert.csv\"\n",
    "try:\n",
    "    labels_df = pd.read_csv(labels_path)\n",
    "    labels_df['subject_id'] = labels_df['subject_id'].astype(str)\n",
    "    labels_df['study_id'] = labels_df['study_id'].astype(str)\n",
    "    logger.info(f\"Loaded labels: {labels_df.shape[0]} rows\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading labels: {e}\")\n",
    "    labels_df = pd.DataFrame(columns=['subject_id', 'study_id'])\n",
    "\n",
    "# Label columns\n",
    "label_columns = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', \n",
    "                'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', \n",
    "                'Lung Opacity', 'No Finding', 'Pleural Effusion', \n",
    "                'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "\n",
    "# TFRecord feature description\n",
    "feature_description = {\n",
    "    'embedding': tf.io.FixedLenFeature([1376], tf.float32),\n",
    "    'image/id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/format': tf.io.FixedLenFeature([], tf.string)\n",
    "}\n",
    "\n",
    "def extract_ids_from_path(path):\n",
    "    \"\"\"Extract subject_id and study_id from image path\"\"\"\n",
    "    p_pattern = r'/p(\\d+)/p(\\d+)/s(\\d+)/'\n",
    "    match = re.search(p_pattern, path)\n",
    "    \n",
    "    if match:\n",
    "        subject_id = match.group(2)\n",
    "        study_id = match.group(3)\n",
    "        return subject_id, study_id\n",
    "    \n",
    "    # Fallback pattern\n",
    "    alt_pattern = r'p(\\d+)/s(\\d+)'\n",
    "    alt_match = re.search(alt_pattern, path)\n",
    "    if alt_match:\n",
    "        subject_id = alt_match.group(1)\n",
    "        study_id = alt_match.group(2)\n",
    "        return subject_id, study_id\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "class MIMICEmbeddingDataset(Dataset):\n",
    "    def __init__(self, file_paths, base_path, labels_df):\n",
    "        self.file_paths = file_paths\n",
    "        self.base_path = base_path\n",
    "        self.labels_df = labels_df\n",
    "        self.label_columns = label_columns\n",
    "        self.data = []\n",
    "        \n",
    "        self.matched_count = 0\n",
    "        self.unmatched_count = 0\n",
    "        self.skipped_files = 0\n",
    "        \n",
    "        # Create labels lookup dictionary\n",
    "        self.label_dict = {}\n",
    "        if not self.labels_df.empty:\n",
    "            for _, row in self.labels_df.iterrows():\n",
    "                key = (row['subject_id'], row['study_id'])\n",
    "                self.label_dict[key] = row[self.label_columns].to_dict()\n",
    "                \n",
    "        logger.info(f\"Created label dictionary with {len(self.label_dict)} entries\")\n",
    "        \n",
    "        # Test extraction with a sample path\n",
    "        if self.file_paths:\n",
    "            test_path = self.file_paths[0]\n",
    "            full_test_path = os.path.join(self.base_path, test_path)\n",
    "            if os.path.exists(full_test_path):\n",
    "                self._test_extraction(full_test_path)\n",
    "        \n",
    "        # Load dataset\n",
    "        logger.info(\"Loading TFRecord files...\")\n",
    "        self._load_data()\n",
    "        logger.info(f\"Records with matched labels: {self.matched_count}\")\n",
    "        logger.info(f\"Records without matched labels: {self.unmatched_count}\")\n",
    "        logger.info(f\"Skipped files: {self.skipped_files}\")\n",
    "    \n",
    "    def _test_extraction(self, test_path):\n",
    "        \"\"\"Test ID extraction on a sample file\"\"\"\n",
    "        try:\n",
    "            dataset = tf.data.TFRecordDataset(test_path)\n",
    "            for record in dataset:\n",
    "                parsed = tf.io.parse_single_example(record, feature_description)\n",
    "                image_id = parsed['image/id'].numpy().decode('utf-8')\n",
    "                subject_id, study_id = extract_ids_from_path(image_id)\n",
    "                logger.info(f\"Sample image_id: {image_id}\")\n",
    "                logger.info(f\"Extracted IDs: subject_id={subject_id}, study_id={study_id}\")\n",
    "                key = (subject_id, study_id)\n",
    "                if key in self.label_dict:\n",
    "                    logger.info(f\"✓ Found matching entry in labels\")\n",
    "                else:\n",
    "                    logger.warning(f\"✗ No matching entry in labels\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error testing extraction: {e}\")\n",
    "        \n",
    "    def _load_data(self):\n",
    "        # Process files in batches\n",
    "        batch_size = 1000\n",
    "        total_files = len(self.file_paths)\n",
    "        \n",
    "        for batch_start in range(0, total_files, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, total_files)\n",
    "            batch_paths = self.file_paths[batch_start:batch_end]\n",
    "            batch_num = batch_start // batch_size + 1\n",
    "            total_batches = (total_files + batch_size - 1) // batch_size\n",
    "            \n",
    "            logger.info(f\"Processing batch {batch_num}/{total_batches}\")\n",
    "            \n",
    "            for path in tqdm(batch_paths, desc=f\"Batch {batch_num}/{total_batches}\"):\n",
    "                full_path = os.path.join(self.base_path, path)\n",
    "                \n",
    "                if not os.path.exists(full_path):\n",
    "                    self.skipped_files += 1\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    dataset = tf.data.TFRecordDataset(\n",
    "                        full_path,\n",
    "                        buffer_size=1280*1024*1024, \n",
    "                        num_parallel_reads=tf.data.experimental.AUTOTUNE\n",
    "                    )\n",
    "                    \n",
    "                    batch_matched = 0\n",
    "                    for record in dataset:\n",
    "                        try:\n",
    "                            parsed = tf.io.parse_single_example(record, feature_description)\n",
    "                            embedding = parsed['embedding'].numpy()\n",
    "                            image_id = parsed['image/id'].numpy().decode('utf-8')\n",
    "                            subject_id, study_id = extract_ids_from_path(image_id)\n",
    "                            \n",
    "                            # Find matching labels\n",
    "                            labels = None\n",
    "                            if subject_id and study_id:\n",
    "                                key = (subject_id, study_id)\n",
    "                                if key in self.label_dict:\n",
    "                                    labels = self.label_dict[key]\n",
    "                                    self.matched_count += 1\n",
    "                                    batch_matched += 1\n",
    "                                else:\n",
    "                                    self.unmatched_count += 1\n",
    "                            else:\n",
    "                                self.unmatched_count += 1\n",
    "                            \n",
    "                            # Add to dataset\n",
    "                            self.data.append({\n",
    "                                'embedding': embedding,\n",
    "                                'image_id': image_id,\n",
    "                                'subject_id': subject_id,\n",
    "                                'study_id': study_id,\n",
    "                                'labels': labels\n",
    "                            })\n",
    "                            \n",
    "                        except (tf.errors.DataLossError, tf.errors.OutOfRangeError):\n",
    "                            continue\n",
    "                        except Exception:\n",
    "                            continue\n",
    "                \n",
    "                except Exception:\n",
    "                    self.skipped_files += 1\n",
    "            \n",
    "            # Log progress and free memory\n",
    "            logger.info(f\"Batch {batch_num} complete. Total records: {len(self.data)}\")\n",
    "            import gc\n",
    "            gc.collect()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        embedding_tensor = torch.tensor(item['embedding'], dtype=torch.float32)\n",
    "        \n",
    "        result = {\n",
    "            'embedding': embedding_tensor,\n",
    "            'subject_id': item['subject_id'],\n",
    "            'study_id': item['study_id']\n",
    "        }\n",
    "        \n",
    "        # Process labels\n",
    "        if item['labels'] is not None:\n",
    "            # Convert to binary labels (handling NaN as 0)\n",
    "            label_values = []\n",
    "            for col in self.label_columns:\n",
    "                value = item['labels'].get(col, 0)\n",
    "                if pd.isna(value):\n",
    "                    value = 0\n",
    "                label_values.append(float(value))\n",
    "            \n",
    "            # Create label tensors\n",
    "            labels_tensor = torch.tensor(label_values, dtype=torch.float32)\n",
    "            result['labels'] = labels_tensor\n",
    "            \n",
    "            # Create one-hot encoding for positive findings\n",
    "            positive_indices = [i for i, val in enumerate(label_values) if val == 1]\n",
    "            one_hot = torch.zeros(len(self.label_columns))\n",
    "            \n",
    "            if positive_indices:\n",
    "                for idx in positive_indices:\n",
    "                    one_hot[idx] = 1\n",
    "            else:\n",
    "                # If no positives, mark as \"No Finding\"\n",
    "                no_finding_idx = self.label_columns.index('No Finding')\n",
    "                one_hot[no_finding_idx] = 1\n",
    "                \n",
    "            result['labels_one_hot'] = one_hot\n",
    "        else:\n",
    "            # Default labels if none available\n",
    "            result['labels'] = torch.zeros(len(self.label_columns), dtype=torch.float32)\n",
    "            result['labels_one_hot'] = torch.zeros(len(self.label_columns), dtype=torch.float32)\n",
    "            no_finding_idx = self.label_columns.index('No Finding')\n",
    "            result['labels_one_hot'][no_finding_idx] = 1\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Load data and create dataset\n",
    "try:\n",
    "    # Load file paths from SHA256SUMS.txt\n",
    "    file_path = \"/home/ahmedyra/scratch/Dataset/generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0/SHA256SUMS.txt\"\n",
    "    \n",
    "    # Read the file and extract paths\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = [line.strip().split(maxsplit=1)[-1] for line in file if \"files/\" in line]  # Extract only paths\n",
    "    \n",
    "    # Filter for TFRecord files\n",
    "    file_paths = [path for path in lines if path.endswith('.tfrecord')]\n",
    "    \n",
    "    logger.info(f\"Found {len(file_paths)} TFRecord files\")\n",
    "    if file_paths:\n",
    "        logger.info(f\"Sample paths: {file_paths[:2]}\")\n",
    "    \n",
    "    # Create the dataset\n",
    "    dataset = MIMICEmbeddingDataset(file_paths, base_path, labels_df)\n",
    "    logger.info(f\"Dataset size: {len(dataset)}\")\n",
    "    \n",
    "    # Display sample\n",
    "    if dataset.data:\n",
    "        sample = dataset[0]\n",
    "        logger.info(f\"Embedding shape: {sample['embedding'].shape}\")\n",
    "        logger.info(f\"Labels shape: {sample['labels'].shape}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Define a simple neural network model\n",
    "class ChestXrayClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=1376, hidden_dims=[512, 256], output_dim=14):\n",
    "        super(ChestXrayClassifier, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        # Create hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer (no activation, will use BCEWithLogitsLoss)\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Split dataset into train and test\n",
    "test_size = 0.2\n",
    "dataset_to_use = dataset  # Use the subset for testing\n",
    "# dataset_to_use = dataset  # Uncomment to use full dataset\n",
    "dataset_size = len(dataset_to_use)\n",
    "test_count = int(test_size * dataset_size)\n",
    "train_count = dataset_size - test_count\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset_to_use, [train_count, test_count], \n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"Training on {len(train_dataset)} samples, testing on {len(test_dataset)} samples\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Initialize model\n",
    "model = ChestXrayClassifier(input_dim=1376, output_dim=len(label_columns))\n",
    "model.to(device)\n",
    "\n",
    "# Initialize loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train model\n",
    "num_epochs = 20\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_aucs = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for batch in progress_bar:\n",
    "        # Move data to device\n",
    "        inputs = batch['embedding'].to(device)\n",
    "        targets = batch['labels_one_hot'].to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch['embedding'].to(device)\n",
    "            targets = batch['labels_one_hot'].to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    # Calculate AUC for each label\n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "    all_probs = 1 / (1 + np.exp(-all_outputs))  # sigmoid\n",
    "    \n",
    "    aucs = {}\n",
    "    for i, label in enumerate(label_columns):\n",
    "        if sum(all_targets[:, i]) > 0:  # Only if there are positive examples\n",
    "            aucs[label] = roc_auc_score(all_targets[:, i], all_probs[:, i])\n",
    "    \n",
    "    mean_auc = np.mean(list(aucs.values()))\n",
    "    test_aucs.append(mean_auc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Mean AUC: {mean_auc:.4f}\")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_aucs, label='Mean AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation\n",
    "model.eval()\n",
    "all_outputs = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch['embedding'].to(device)\n",
    "        targets = batch['labels_one_hot'].to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        all_outputs.append(outputs.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "all_outputs = np.vstack(all_outputs)\n",
    "all_targets = np.vstack(all_targets)\n",
    "all_probs = 1 / (1 + np.exp(-all_outputs))  # sigmoid\n",
    "all_preds = (all_probs >= 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics for each label\n",
    "print(\"\\nFinal metrics by condition:\")\n",
    "for i, label in enumerate(label_columns):\n",
    "    # Skip if no positive examples\n",
    "    if sum(all_targets[:, i]) > 0:\n",
    "        auc = roc_auc_score(all_targets[:, i], all_probs[:, i])\n",
    "        accuracy = accuracy_score(all_targets[:, i], all_preds[:, i])\n",
    "        precision = precision_score(all_targets[:, i], all_preds[:, i], zero_division=0)\n",
    "        recall = recall_score(all_targets[:, i], all_preds[:, i], zero_division=0)\n",
    "        f1 = f1_score(all_targets[:, i], all_preds[:, i], zero_division=0)\n",
    "        \n",
    "        print(f\"{label}:\")\n",
    "        print(f\"  AUC: {auc:.4f}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nOverall Mean AUC: {np.mean(list(aucs.values())):.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'chest_xray_model.pth')\n",
    "print(\"Model saved to 'chest_xray_model.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing PKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 228905\n",
      "\n",
      "Sample contents:\n",
      "embedding: Tensor shape torch.Size([1376])\n",
      "labels: Tensor shape torch.Size([14])\n",
      "demographics: ['F' 'Medicaid' 52.0 'WHITE']\n",
      "gender: F\n",
      "insurance: Medicaid\n",
      "anchor_age: 52.0\n",
      "race: WHITE\n",
      "study_id: 50414267\n",
      "dicom_id: 02aa804e-bde0afdd-112c0b34-7bc16630-4e384014\n",
      "path: generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.tfrecord\n",
      "\n",
      "First 10 embedding values:\n",
      "tensor([ 0.1257, -1.8030,  1.2843, -1.8088,  0.1278, -0.1912,  0.6093,  0.8306,\n",
      "        -0.4438,  1.2389])\n",
      "\n",
      "Labels:\n",
      "Enlarged Cardiomediastinum: 0.0\n",
      "Cardiomegaly: 0.0\n",
      "Lung Opacity: 0.0\n",
      "Lung Lesion: 0.0\n",
      "Edema: 0.0\n",
      "Consolidation: 0.0\n",
      "Pneumonia: 0.0\n",
      "Atelectasis: 0.0\n",
      "Pneumothorax: 0.0\n",
      "Pleural Effusion: 0.0\n",
      "Pleural Other: 0.0\n",
      "Fracture: 0.0\n",
      "Support Devices: 0.0\n",
      "No Finding: 1.0\n",
      "dict_keys(['embedding', 'labels', 'demographics', 'gender', 'insurance', 'anchor_age', 'race', 'study_id', 'dicom_id', 'path'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class MIMICDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for the MIMIC Chest X-ray data with embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, base_path=\"/home/ahmedyra/scratch/Dataset/\", transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path (str): Path to the pickle file containing the preprocessed data\n",
    "            base_path (str): Base path to the embeddings\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        self.data_df = pd.read_pickle(data_path)\n",
    "        self.transform = transform\n",
    "        self.base_path = base_path\n",
    "        self.labels = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "                       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "                       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "                       'Support Devices', 'No Finding']\n",
    "        self.demographic = ['gender', 'insurance', 'anchor_age', 'race']\n",
    "    \n",
    "    def __read_tf_record__(self, file_path):\n",
    "        \"\"\"Read a TensorFlow record file and parse the example\"\"\"\n",
    "        full_path = f\"{self.base_path}/{file_path}\"\n",
    "        raw_dataset = tf.data.TFRecordDataset(full_path)\n",
    "        for raw_record in raw_dataset.take(1):\n",
    "            example = tf.train.Example()\n",
    "            example.ParseFromString(raw_record.numpy())\n",
    "            return example\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of samples\"\"\"\n",
    "        return len(self.data_df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index of the sample to fetch\n",
    "        Returns:\n",
    "            dict: A dictionary containing the data sample\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        # Get the row from the dataframe\n",
    "        row = self.data_df.iloc[idx]\n",
    "        \n",
    "        # Get the embedding\n",
    "        try:\n",
    "            example = self.__read_tf_record__(row['path'])\n",
    "            # Extract embedding values from float_list\n",
    "            embedding_values = np.array(example.features.feature['embedding'].float_list.value, dtype=np.float32)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading embedding for {row['path']}: {e}\")\n",
    "            # Fallback to zeros if there's an error\n",
    "            embedding_values = np.zeros(1376, dtype=np.float32)\n",
    "        \n",
    "        # Get the labels\n",
    "        labels = row[self.labels].values.astype(np.float32)\n",
    "        \n",
    "        # Get the demographic data\n",
    "        demographics = row[self.demographic].values\n",
    "        \n",
    "        # Create sample dictionary\n",
    "        sample = {\n",
    "            'embedding': torch.tensor(embedding_values, dtype=torch.float32),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float32),\n",
    "            'demographics': demographics,\n",
    "            'gender': row['gender'],\n",
    "            'insurance': row['insurance'],\n",
    "            'anchor_age': row['anchor_age'],\n",
    "            'race': row['race'],\n",
    "            'study_id': row['study_id'],\n",
    "            'dicom_id': row['dicom_id'],\n",
    "            'path': row['path']\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "\n",
    "# Create the dataset\n",
    "dataset = MIMICDataset(\"/home/ahmedyra/projects/def-hinat/ahmedyra/EECS_Fairness_Project/preprocessed_data.pkl\")\n",
    "\n",
    "# Print the dataset length\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "\n",
    "# Get and print one sample (the first one)\n",
    "sample = dataset[0]\n",
    "print(\"\\nSample contents:\")\n",
    "for key, value in sample.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key}: Tensor shape {value.shape}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Print the first few values of the embedding\n",
    "print(\"\\nFirst 10 embedding values:\")\n",
    "print(sample['embedding'][:10])\n",
    "\n",
    "# Print the labels\n",
    "print(\"\\nLabels:\")\n",
    "for i, label_name in enumerate(dataset.labels):\n",
    "    print(f\"{label_name}: {sample['labels'][i]}\")\n",
    "print(sample.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
