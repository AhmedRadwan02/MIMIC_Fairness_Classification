{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11035066,"sourceType":"datasetVersion","datasetId":6873191},{"sourceId":11036050,"sourceType":"datasetVersion","datasetId":6873886}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nprint(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n\n# File path\nfile_path = \"/kaggle/input/mimic-data/generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0/generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0/SHA256SUMS.txt\"\n\n# Read the file and extract paths\nwith open(file_path, \"r\") as file:\n    lines = [line.strip().split(maxsplit=1)[-1] for line in file if \"files/\" in line]  # Extract only paths\n\n# Create a DataFrame\ndf = pd.DataFrame(lines, columns=[\"file_paths\"])\n\n# Show first few rows\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:42:30.363687Z","iopub.execute_input":"2025-03-15T05:42:30.364055Z","iopub.status.idle":"2025-03-15T05:42:46.935096Z","shell.execute_reply.started":"2025-03-15T05:42:30.364008Z","shell.execute_reply":"2025-03-15T05:42:46.934298Z"}},"outputs":[{"name":"stdout","text":"GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n                                          file_paths\n0  files/p10/p10000032/s50414267/02aa804e-bde0afd...\n1  files/p10/p10000032/s53189527/2a2277a9-b0ded15...\n2  files/p10/p10000032/s53911762/68b5c4b1-227d048...\n3  files/p10/p10000032/s53911762/fffabebf-74fd3a1...\n4  files/p10/p10000032/s56699142/ea030e7a-2e3b134...\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport torch\nfrom torch.utils.data import Dataset\nimport numpy as np\nimport os\nimport re\nfrom tqdm import tqdm\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\ntf.get_logger().setLevel(logging.ERROR)\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n# Base path for dataset\nbase_path = \"/kaggle/input/mimic-data/generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0/generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0\"\n\n# Load labels\nlabels_path = \"/kaggle/input/mimic-data/mimic-cxr-2.0.0-chexpert.csv\"\ntry:\n    labels_df = pd.read_csv(labels_path)\n    labels_df['subject_id'] = labels_df['subject_id'].astype(str)\n    labels_df['study_id'] = labels_df['study_id'].astype(str)\n    logger.info(f\"Loaded labels: {labels_df.shape[0]} rows\")\nexcept Exception as e:\n    logger.error(f\"Error loading labels: {e}\")\n    labels_df = pd.DataFrame(columns=['subject_id', 'study_id'])\n\n# Label columns\nlabel_columns = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', \n                'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', \n                'Lung Opacity', 'No Finding', 'Pleural Effusion', \n                'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n\n# TFRecord feature description\nfeature_description = {\n    'embedding': tf.io.FixedLenFeature([1376], tf.float32),\n    'image/id': tf.io.FixedLenFeature([], tf.string),\n    'image/format': tf.io.FixedLenFeature([], tf.string)\n}\n\ndef extract_ids_from_path(path):\n    \"\"\"Extract subject_id and study_id from image path\"\"\"\n    p_pattern = r'/p(\\d+)/p(\\d+)/s(\\d+)/'\n    match = re.search(p_pattern, path)\n    \n    if match:\n        subject_id = match.group(2)\n        study_id = match.group(3)\n        return subject_id, study_id\n    \n    # Fallback pattern\n    alt_pattern = r'p(\\d+)/s(\\d+)'\n    alt_match = re.search(alt_pattern, path)\n    if alt_match:\n        subject_id = alt_match.group(1)\n        study_id = alt_match.group(2)\n        return subject_id, study_id\n    \n    return None, None\n\nclass MIMICEmbeddingDataset(Dataset):\n    def __init__(self, file_paths, base_path, labels_df):\n        self.file_paths = file_paths\n        self.base_path = base_path\n        self.labels_df = labels_df\n        self.label_columns = label_columns\n        self.data = []\n        \n        self.matched_count = 0\n        self.unmatched_count = 0\n        self.skipped_files = 0\n        \n        # Create labels lookup dictionary\n        self.label_dict = {}\n        if not self.labels_df.empty:\n            for _, row in self.labels_df.iterrows():\n                key = (row['subject_id'], row['study_id'])\n                self.label_dict[key] = row[self.label_columns].to_dict()\n                \n        logger.info(f\"Created label dictionary with {len(self.label_dict)} entries\")\n        \n        # Test extraction with a sample path\n        if self.file_paths:\n            test_path = self.file_paths[0]\n            full_test_path = os.path.join(self.base_path, test_path)\n            if os.path.exists(full_test_path):\n                self._test_extraction(full_test_path)\n        \n        # Load dataset\n        logger.info(\"Loading TFRecord files...\")\n        self._load_data()\n        logger.info(f\"Records with matched labels: {self.matched_count}\")\n        logger.info(f\"Records without matched labels: {self.unmatched_count}\")\n        logger.info(f\"Skipped files: {self.skipped_files}\")\n    \n    def _test_extraction(self, test_path):\n        \"\"\"Test ID extraction on a sample file\"\"\"\n        try:\n            dataset = tf.data.TFRecordDataset(test_path)\n            for record in dataset:\n                parsed = tf.io.parse_single_example(record, feature_description)\n                image_id = parsed['image/id'].numpy().decode('utf-8')\n                subject_id, study_id = extract_ids_from_path(image_id)\n                logger.info(f\"Sample image_id: {image_id}\")\n                logger.info(f\"Extracted IDs: subject_id={subject_id}, study_id={study_id}\")\n                key = (subject_id, study_id)\n                if key in self.label_dict:\n                    logger.info(f\"✓ Found matching entry in labels\")\n                else:\n                    logger.warning(f\"✗ No matching entry in labels\")\n                return\n        except Exception as e:\n            logger.warning(f\"Error testing extraction: {e}\")\n        \n    def _load_data(self):\n        # Process files in batches\n        batch_size = 500\n        total_files = len(self.file_paths)\n        \n        for batch_start in range(0, total_files, batch_size):\n            batch_end = min(batch_start + batch_size, total_files)\n            batch_paths = self.file_paths[batch_start:batch_end]\n            batch_num = batch_start // batch_size + 1\n            total_batches = (total_files + batch_size - 1) // batch_size\n            \n            logger.info(f\"Processing batch {batch_num}/{total_batches}\")\n            \n            for path in tqdm(batch_paths, desc=f\"Batch {batch_num}/{total_batches}\"):\n                full_path = os.path.join(self.base_path, path)\n                \n                if not os.path.exists(full_path):\n                    self.skipped_files += 1\n                    continue\n                    \n                try:\n                    dataset = tf.data.TFRecordDataset(\n                        full_path,\n                        buffer_size=200,\n                        num_parallel_reads=tf.data.experimental.AUTOTUNE\n                    )\n                    \n                    batch_matched = 0\n                    for record in dataset:\n                        try:\n                            parsed = tf.io.parse_single_example(record, feature_description)\n                            embedding = parsed['embedding'].numpy()\n                            image_id = parsed['image/id'].numpy().decode('utf-8')\n                            subject_id, study_id = extract_ids_from_path(image_id)\n                            \n                            # Find matching labels\n                            labels = None\n                            if subject_id and study_id:\n                                key = (subject_id, study_id)\n                                if key in self.label_dict:\n                                    labels = self.label_dict[key]\n                                    self.matched_count += 1\n                                    batch_matched += 1\n                                else:\n                                    self.unmatched_count += 1\n                            else:\n                                self.unmatched_count += 1\n                            \n                            # Add to dataset\n                            self.data.append({\n                                'embedding': embedding,\n                                'image_id': image_id,\n                                'subject_id': subject_id,\n                                'study_id': study_id,\n                                'labels': labels\n                            })\n                            \n                        except (tf.errors.DataLossError, tf.errors.OutOfRangeError):\n                            continue\n                        except Exception:\n                            continue\n                \n                except Exception:\n                    self.skipped_files += 1\n            \n            # Log progress and free memory\n            logger.info(f\"Batch {batch_num} complete. Total records: {len(self.data)}\")\n            import gc\n            gc.collect()\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        item = self.data[idx]\n        embedding_tensor = torch.tensor(item['embedding'], dtype=torch.float32)\n        \n        result = {\n            'embedding': embedding_tensor,\n            'subject_id': item['subject_id'],\n            'study_id': item['study_id']\n        }\n        \n        # Process labels\n        if item['labels'] is not None:\n            # Convert to binary labels (handling NaN as 0)\n            label_values = []\n            for col in self.label_columns:\n                value = item['labels'].get(col, 0)\n                if pd.isna(value):\n                    value = 0\n                label_values.append(float(value))\n            \n            # Create label tensors\n            labels_tensor = torch.tensor(label_values, dtype=torch.float32)\n            result['labels'] = labels_tensor\n            \n            # Create one-hot encoding for positive findings\n            positive_indices = [i for i, val in enumerate(label_values) if val == 1]\n            one_hot = torch.zeros(len(self.label_columns))\n            \n            if positive_indices:\n                for idx in positive_indices:\n                    one_hot[idx] = 1\n            else:\n                # If no positives, mark as \"No Finding\"\n                no_finding_idx = self.label_columns.index('No Finding')\n                one_hot[no_finding_idx] = 1\n                \n            result['labels_one_hot'] = one_hot\n        else:\n            # Default labels if none available\n            result['labels'] = torch.zeros(len(self.label_columns), dtype=torch.float32)\n            result['labels_one_hot'] = torch.zeros(len(self.label_columns), dtype=torch.float32)\n            no_finding_idx = self.label_columns.index('No Finding')\n            result['labels_one_hot'][no_finding_idx] = 1\n        \n        return result\n\n# Load data and create dataset\ntry:\n    # Load file paths from SHA256SUMS.txt\n    file_path = \"/kaggle/input/mimic-data/generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0/generalized-image-embeddings-for-the-mimic-chest-x-ray-dataset-1.0/SHA256SUMS.txt\"\n    \n    # Read the file and extract paths\n    with open(file_path, \"r\") as file:\n        lines = [line.strip().split(maxsplit=1)[-1] for line in file if \"files/\" in line]  # Extract only paths\n    \n    # Filter for TFRecord files\n    file_paths = [path for path in lines if path.endswith('.tfrecord')]\n    \n    logger.info(f\"Found {len(file_paths)} TFRecord files\")\n    if file_paths:\n        logger.info(f\"Sample paths: {file_paths[:2]}\")\n    \n    # Create the dataset\n    dataset = MIMICEmbeddingDataset(file_paths, base_path, labels_df)\n    logger.info(f\"Dataset size: {len(dataset)}\")\n    \n    # Display sample\n    if dataset.data:\n        sample = dataset[0]\n        logger.info(f\"Embedding shape: {sample['embedding'].shape}\")\n        logger.info(f\"Labels shape: {sample['labels'].shape}\")\nexcept Exception as e:\n    logger.error(f\"Error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:42:46.936212Z","iopub.execute_input":"2025-03-15T05:42:46.936761Z"}},"outputs":[{"name":"stderr","text":"Batch 1/487: 100%|██████████| 500/500 [00:12<00:00, 40.55it/s]\nBatch 2/487: 100%|██████████| 500/500 [00:12<00:00, 38.91it/s]\nBatch 3/487: 100%|██████████| 500/500 [00:12<00:00, 39.10it/s]\nBatch 4/487: 100%|██████████| 500/500 [00:12<00:00, 39.30it/s]\nBatch 5/487: 100%|██████████| 500/500 [00:12<00:00, 38.65it/s]\nBatch 6/487: 100%|██████████| 500/500 [00:12<00:00, 38.95it/s]\nBatch 7/487: 100%|██████████| 500/500 [00:13<00:00, 35.94it/s]\nBatch 8/487: 100%|██████████| 500/500 [00:22<00:00, 22.43it/s]\nBatch 9/487: 100%|██████████| 500/500 [00:22<00:00, 22.44it/s]\nBatch 10/487: 100%|██████████| 500/500 [00:23<00:00, 21.41it/s]\nBatch 11/487: 100%|██████████| 500/500 [00:14<00:00, 34.58it/s]\nBatch 12/487: 100%|██████████| 500/500 [00:12<00:00, 39.70it/s]\nBatch 13/487: 100%|██████████| 500/500 [00:12<00:00, 40.46it/s]\nBatch 14/487: 100%|██████████| 500/500 [00:12<00:00, 38.94it/s]\nBatch 15/487: 100%|██████████| 500/500 [00:12<00:00, 39.04it/s]\nBatch 16/487: 100%|██████████| 500/500 [00:12<00:00, 39.45it/s]\nBatch 17/487: 100%|██████████| 500/500 [00:14<00:00, 34.32it/s]\nBatch 18/487: 100%|██████████| 500/500 [00:17<00:00, 28.06it/s]\nBatch 19/487: 100%|██████████| 500/500 [00:18<00:00, 27.17it/s]\nBatch 20/487: 100%|██████████| 500/500 [00:12<00:00, 38.48it/s]\nBatch 21/487: 100%|██████████| 500/500 [00:12<00:00, 39.05it/s]\nBatch 22/487: 100%|██████████| 500/500 [00:13<00:00, 37.64it/s]\nBatch 23/487: 100%|██████████| 500/500 [00:13<00:00, 37.96it/s]\nBatch 24/487: 100%|██████████| 500/500 [00:13<00:00, 38.17it/s]\nBatch 25/487: 100%|██████████| 500/500 [00:13<00:00, 36.64it/s]\nBatch 26/487: 100%|██████████| 500/500 [00:14<00:00, 35.63it/s]\nBatch 27/487: 100%|██████████| 500/500 [00:18<00:00, 27.26it/s]\nBatch 28/487: 100%|██████████| 500/500 [00:14<00:00, 33.73it/s]\nBatch 29/487: 100%|██████████| 500/500 [00:15<00:00, 31.74it/s]\nBatch 30/487: 100%|██████████| 500/500 [00:12<00:00, 39.42it/s]\nBatch 31/487: 100%|██████████| 500/500 [00:12<00:00, 38.71it/s]\nBatch 32/487: 100%|██████████| 500/500 [00:12<00:00, 39.56it/s]\nBatch 33/487: 100%|██████████| 500/500 [00:12<00:00, 40.09it/s]\nBatch 34/487: 100%|██████████| 500/500 [00:12<00:00, 39.86it/s]\nBatch 35/487: 100%|██████████| 500/500 [00:12<00:00, 39.14it/s]\nBatch 36/487: 100%|██████████| 500/500 [00:12<00:00, 39.00it/s]\nBatch 37/487: 100%|██████████| 500/500 [00:12<00:00, 39.80it/s]\nBatch 38/487: 100%|██████████| 500/500 [00:12<00:00, 40.16it/s]\nBatch 39/487: 100%|██████████| 500/500 [00:13<00:00, 38.32it/s]\nBatch 40/487: 100%|██████████| 500/500 [00:12<00:00, 39.08it/s]\nBatch 41/487: 100%|██████████| 500/500 [00:12<00:00, 39.31it/s]\nBatch 42/487: 100%|██████████| 500/500 [00:12<00:00, 39.89it/s]\nBatch 43/487: 100%|██████████| 500/500 [00:12<00:00, 39.97it/s]\nBatch 44/487: 100%|██████████| 500/500 [00:12<00:00, 38.75it/s]\nBatch 45/487: 100%|██████████| 500/500 [00:12<00:00, 39.36it/s]\nBatch 46/487: 100%|██████████| 500/500 [00:12<00:00, 38.88it/s]\nBatch 47/487: 100%|██████████| 500/500 [00:12<00:00, 39.32it/s]\nBatch 48/487: 100%|██████████| 500/500 [00:13<00:00, 38.36it/s]\nBatch 49/487: 100%|██████████| 500/500 [00:12<00:00, 38.72it/s]\nBatch 50/487: 100%|██████████| 500/500 [00:12<00:00, 39.25it/s]\nBatch 51/487: 100%|██████████| 500/500 [00:12<00:00, 39.07it/s]\nBatch 52/487: 100%|██████████| 500/500 [00:12<00:00, 40.22it/s]\nBatch 53/487: 100%|██████████| 500/500 [00:12<00:00, 39.33it/s]\nBatch 54/487: 100%|██████████| 500/500 [00:13<00:00, 38.04it/s]\nBatch 55/487: 100%|██████████| 500/500 [00:12<00:00, 39.96it/s]\nBatch 56/487: 100%|██████████| 500/500 [00:12<00:00, 39.44it/s]\nBatch 57/487: 100%|██████████| 500/500 [00:12<00:00, 40.33it/s]\nBatch 58/487: 100%|██████████| 500/500 [00:13<00:00, 36.39it/s]\nBatch 59/487: 100%|██████████| 500/500 [00:14<00:00, 35.22it/s]\nBatch 60/487: 100%|██████████| 500/500 [00:12<00:00, 39.17it/s]\nBatch 61/487: 100%|██████████| 500/500 [00:12<00:00, 40.47it/s]\nBatch 62/487: 100%|██████████| 500/500 [00:13<00:00, 38.27it/s]\nBatch 63/487: 100%|██████████| 500/500 [00:13<00:00, 37.16it/s]\nBatch 64/487: 100%|██████████| 500/500 [00:12<00:00, 38.90it/s]\nBatch 65/487: 100%|██████████| 500/500 [00:12<00:00, 38.82it/s]\nBatch 66/487: 100%|██████████| 500/500 [00:13<00:00, 37.42it/s]\nBatch 67/487: 100%|██████████| 500/500 [00:13<00:00, 36.38it/s]\nBatch 68/487: 100%|██████████| 500/500 [00:13<00:00, 37.20it/s]\nBatch 69/487: 100%|██████████| 500/500 [00:14<00:00, 34.89it/s]\nBatch 70/487: 100%|██████████| 500/500 [00:16<00:00, 30.59it/s]\nBatch 71/487: 100%|██████████| 500/500 [00:16<00:00, 30.49it/s]\nBatch 72/487: 100%|██████████| 500/500 [00:14<00:00, 33.69it/s]\nBatch 73/487: 100%|██████████| 500/500 [00:16<00:00, 31.04it/s]\nBatch 74/487: 100%|██████████| 500/500 [00:13<00:00, 37.86it/s]\nBatch 75/487: 100%|██████████| 500/500 [00:13<00:00, 37.33it/s]\nBatch 76/487: 100%|██████████| 500/500 [00:14<00:00, 34.72it/s]\nBatch 77/487: 100%|██████████| 500/500 [00:13<00:00, 37.42it/s]\nBatch 78/487: 100%|██████████| 500/500 [00:12<00:00, 39.12it/s]\nBatch 79/487: 100%|██████████| 500/500 [00:13<00:00, 36.93it/s]\nBatch 80/487: 100%|██████████| 500/500 [00:13<00:00, 37.82it/s]\nBatch 81/487: 100%|██████████| 500/500 [00:13<00:00, 38.39it/s]\nBatch 82/487: 100%|██████████| 500/500 [00:13<00:00, 37.53it/s]\nBatch 83/487: 100%|██████████| 500/500 [00:14<00:00, 34.76it/s]\nBatch 84/487: 100%|██████████| 500/500 [00:14<00:00, 33.92it/s]\nBatch 85/487: 100%|██████████| 500/500 [00:15<00:00, 32.90it/s]\nBatch 86/487: 100%|██████████| 500/500 [00:13<00:00, 36.98it/s]\nBatch 87/487: 100%|██████████| 500/500 [00:13<00:00, 38.42it/s]\nBatch 88/487: 100%|██████████| 500/500 [00:13<00:00, 37.39it/s]\nBatch 89/487: 100%|██████████| 500/500 [00:12<00:00, 38.72it/s]\nBatch 90/487: 100%|██████████| 500/500 [00:13<00:00, 36.30it/s]\nBatch 91/487: 100%|██████████| 500/500 [00:13<00:00, 37.35it/s]\nBatch 92/487: 100%|██████████| 500/500 [00:16<00:00, 30.68it/s]\nBatch 93/487: 100%|██████████| 500/500 [00:14<00:00, 34.95it/s]\nBatch 94/487: 100%|██████████| 500/500 [00:14<00:00, 35.53it/s]\nBatch 95/487: 100%|██████████| 500/500 [00:14<00:00, 34.01it/s]\nBatch 96/487: 100%|██████████| 500/500 [00:14<00:00, 34.69it/s]\nBatch 97/487: 100%|██████████| 500/500 [00:14<00:00, 34.02it/s]\nBatch 98/487: 100%|██████████| 500/500 [00:13<00:00, 35.91it/s]\nBatch 99/487: 100%|██████████| 500/500 [00:13<00:00, 36.56it/s]\nBatch 100/487: 100%|██████████| 500/500 [00:13<00:00, 38.00it/s]\nBatch 101/487: 100%|██████████| 500/500 [00:13<00:00, 37.26it/s]\nBatch 102/487: 100%|██████████| 500/500 [00:13<00:00, 38.06it/s]\nBatch 103/487: 100%|██████████| 500/500 [00:12<00:00, 38.46it/s]\nBatch 104/487: 100%|██████████| 500/500 [00:13<00:00, 37.56it/s]\nBatch 105/487: 100%|██████████| 500/500 [00:13<00:00, 37.57it/s]\nBatch 106/487: 100%|██████████| 500/500 [00:13<00:00, 36.69it/s]\nBatch 107/487: 100%|██████████| 500/500 [00:13<00:00, 38.21it/s]\nBatch 108/487: 100%|██████████| 500/500 [00:13<00:00, 38.42it/s]\nBatch 109/487: 100%|██████████| 500/500 [00:14<00:00, 35.00it/s]\nBatch 110/487: 100%|██████████| 500/500 [00:13<00:00, 37.89it/s]\nBatch 111/487: 100%|██████████| 500/500 [00:13<00:00, 38.01it/s]\nBatch 112/487: 100%|██████████| 500/500 [00:13<00:00, 37.68it/s]\nBatch 113/487: 100%|██████████| 500/500 [00:14<00:00, 35.65it/s]\nBatch 114/487: 100%|██████████| 500/500 [00:14<00:00, 33.38it/s]\nBatch 115/487: 100%|██████████| 500/500 [00:14<00:00, 35.44it/s]\nBatch 116/487: 100%|██████████| 500/500 [00:14<00:00, 35.69it/s]\nBatch 117/487: 100%|██████████| 500/500 [00:14<00:00, 35.43it/s]\nBatch 118/487: 100%|██████████| 500/500 [00:13<00:00, 36.53it/s]\nBatch 119/487: 100%|██████████| 500/500 [00:13<00:00, 37.06it/s]\nBatch 120/487: 100%|██████████| 500/500 [00:14<00:00, 34.64it/s]\nBatch 121/487: 100%|██████████| 500/500 [00:15<00:00, 32.07it/s]\nBatch 122/487: 100%|██████████| 500/500 [00:14<00:00, 35.40it/s]\nBatch 123/487: 100%|██████████| 500/500 [00:13<00:00, 36.25it/s]\nBatch 124/487: 100%|██████████| 500/500 [00:13<00:00, 37.85it/s]\nBatch 125/487: 100%|██████████| 500/500 [00:13<00:00, 37.59it/s]\nBatch 126/487: 100%|██████████| 500/500 [00:13<00:00, 36.43it/s]\nBatch 127/487: 100%|██████████| 500/500 [00:15<00:00, 32.65it/s]\nBatch 128/487: 100%|██████████| 500/500 [00:14<00:00, 33.36it/s]\nBatch 129/487: 100%|██████████| 500/500 [00:13<00:00, 36.08it/s]\nBatch 130/487: 100%|██████████| 500/500 [00:13<00:00, 36.94it/s]\nBatch 131/487: 100%|██████████| 500/500 [00:13<00:00, 37.20it/s]\nBatch 132/487: 100%|██████████| 500/500 [00:13<00:00, 38.22it/s]\nBatch 133/487: 100%|██████████| 500/500 [00:13<00:00, 37.90it/s]\nBatch 134/487: 100%|██████████| 500/500 [00:14<00:00, 35.55it/s]\nBatch 135/487: 100%|██████████| 500/500 [00:14<00:00, 35.64it/s]\nBatch 136/487: 100%|██████████| 500/500 [00:13<00:00, 36.61it/s]\nBatch 137/487: 100%|██████████| 500/500 [00:13<00:00, 37.47it/s]\nBatch 138/487: 100%|██████████| 500/500 [00:13<00:00, 37.48it/s]\nBatch 139/487: 100%|██████████| 500/500 [00:14<00:00, 35.36it/s]\nBatch 140/487: 100%|██████████| 500/500 [00:13<00:00, 37.25it/s]\nBatch 141/487: 100%|██████████| 500/500 [00:13<00:00, 36.72it/s]\nBatch 142/487: 100%|██████████| 500/500 [00:13<00:00, 37.34it/s]\nBatch 143/487: 100%|██████████| 500/500 [00:14<00:00, 34.50it/s]\nBatch 144/487: 100%|██████████| 500/500 [00:20<00:00, 24.57it/s]\nBatch 145/487: 100%|██████████| 500/500 [00:13<00:00, 37.17it/s]\nBatch 146/487:  34%|███▎      | 168/500 [00:04<00:09, 36.54it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport os\nimport seaborn as sns\n\n# Load demographic data from MIMIC\ndef load_demographic_data():\n    \"\"\"\n    Load patient demographics from MIMIC CSV files\n    Returns: \n        admissions_df: DataFrame with admission information\n        patients_df: DataFrame with patient information\n    \"\"\"\n    admissions_df = pd.read_csv(\"/kaggle/input/mimic-patients/admissions.csv\")\n    patients_df = pd.read_csv(\"/kaggle/input/mimic-patients/patients.csv\")\n    \n    # Check for duplicate subject_ids and handle them (e.g., keep most recent)\n    if admissions_df['subject_id'].duplicated().any():\n        print(\"Warning: duplicate subject_ids found in admissions data\")\n        # Keep most recent admission for each patient (assuming there's an admission_time column)\n        if 'admittime' in admissions_df.columns:\n            admissions_df = admissions_df.sort_values('admittime').drop_duplicates('subject_id', keep='last')\n    \n    # Only keep relevant columns\n    admissions_cols = ['subject_id', 'insurance', 'marital_status', 'ethnicity']\n    patients_cols = ['subject_id', 'gender', 'anchor_year_group']\n    \n    admissions_df = admissions_df[admissions_cols]\n    patients_df = patients_df[patients_cols]\n    \n    return admissions_df, patients_df\n\n# ChestXrayClassifier model definition (same as before)\nclass ChestXrayClassifier(nn.Module):\n    def __init__(self, input_dim=1376, hidden_dims=[512, 384, 256], output_dim=14):\n        super(ChestXrayClassifier, self).__init__()\n        \n        # Input normalization layer (learnable)\n        self.batch_norm_input = nn.BatchNorm1d(input_dim)\n        \n        # Main network with residual connections\n        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n        self.bn1 = nn.BatchNorm1d(hidden_dims[0])\n        self.dropout1 = nn.Dropout(0.3)\n        \n        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n        self.bn2 = nn.BatchNorm1d(hidden_dims[1])\n        self.dropout2 = nn.Dropout(0.3)\n        \n        self.fc3 = nn.Linear(hidden_dims[1], hidden_dims[2])\n        self.bn3 = nn.BatchNorm1d(hidden_dims[2])\n        self.dropout3 = nn.Dropout(0.3)\n        \n        # Residual connection (from input to hidden layer 2)\n        self.res_fc1 = nn.Linear(input_dim, hidden_dims[1])\n        \n        # Attention mechanism\n        self.attention = nn.Sequential(\n            nn.Linear(hidden_dims[2], hidden_dims[2] // 4),\n            nn.ReLU(),\n            nn.Linear(hidden_dims[2] // 4, hidden_dims[2]),\n            nn.Sigmoid()\n        )\n        \n        # Disease-specific layers for each output class\n        self.disease_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(hidden_dims[2], hidden_dims[2] // 2),\n                nn.ReLU(),\n                nn.Linear(hidden_dims[2] // 2, 1)\n            ) for _ in range(output_dim)\n        ])\n    \n    def forward(self, x):\n        # Input normalization\n        x_norm = self.batch_norm_input(x)\n        \n        # First block with residual connection\n        res = x_norm\n        x = self.fc1(x_norm)\n        x = self.bn1(x)\n        x = nn.functional.leaky_relu(x, 0.1)\n        x = self.dropout1(x)\n        \n        # Residual connection from input to second layer\n        res = self.res_fc1(res)\n        \n        # Second block\n        x = self.fc2(x)\n        x = self.bn2(x)\n        x = nn.functional.leaky_relu(x, 0.1)\n        x = self.dropout2(x)\n        \n        # Add residual connection\n        x = x + res\n        \n        # Third block\n        x = self.fc3(x)\n        x = self.bn3(x)\n        x = nn.functional.leaky_relu(x, 0.1)\n        x = self.dropout3(x)\n        \n        # Apply attention\n        attention_weights = self.attention(x)\n        x = x * attention_weights\n        \n        # Disease-specific predictions\n        outputs = []\n        for disease_layer in self.disease_layers:\n            outputs.append(disease_layer(x))\n        \n        # Concatenate all outputs\n        return torch.cat(outputs, dim=1)\n\n# Modified function to save predictions with demographic information\ndef save_predictions_to_csv(dataset_loader, model, device, label_columns, file_name, \n                          admissions_df=None, patients_df=None):\n    \"\"\"\n    Generate and save model predictions with demographic information\n    \n    Args:\n        dataset_loader: DataLoader with the dataset\n        model: Trained model to generate predictions\n        device: Device to run model on\n        label_columns: List of disease label names\n        file_name: Where to save the CSV\n        admissions_df: DataFrame with admission information\n        patients_df: DataFrame with patient information\n    \n    Returns:\n        all_probs: Array of prediction probabilities\n        all_targets: Array of ground truth labels\n    \"\"\"\n    model.eval()\n    all_outputs = []\n    all_targets = []\n    subject_ids = []\n    study_ids = []\n    image_ids = []\n    \n    with torch.no_grad():\n        for batch in dataset_loader:\n            inputs = batch['embedding'].to(device)\n            targets = batch['labels_one_hot'].to(device)\n            \n            # Extract subject and study IDs from the batch\n            if 'subject_id' in batch and 'study_id' in batch:\n                subject_ids.extend(batch['subject_id'])\n                study_ids.extend(batch['study_id'])\n            else:\n                # If IDs don't exist, create sequential placeholders\n                batch_size = inputs.size(0)\n                start_idx = len(subject_ids)\n                subject_ids.extend([f\"subject_{i}\" for i in range(start_idx, start_idx + batch_size)])\n                study_ids.extend([f\"study_{i}\" for i in range(start_idx, start_idx + batch_size)])\n            \n            # Get image IDs if available\n            if 'image_id' in batch:\n                image_ids.extend(batch['image_id'])\n            else:\n                batch_size = inputs.size(0)\n                start_idx = len(image_ids)\n                image_ids.extend([f\"image_{i}\" for i in range(start_idx, start_idx + batch_size)])\n            \n            outputs = model(inputs)\n            all_outputs.append(outputs.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n    \n    all_outputs = np.vstack(all_outputs)\n    all_targets = np.vstack(all_targets)\n    all_probs = 1 / (1 + np.exp(-all_outputs))  # sigmoid\n    all_binary_preds = (all_probs >= 0.5).astype(int)  # Convert to binary predictions\n    \n    # Create DataFrame for predictions\n    pred_df = pd.DataFrame()\n    pred_df['subject_id'] = subject_ids\n    pred_df['study_id'] = study_ids\n    pred_df['image_id'] = image_ids\n    \n    # Add only ground truth and binary predictions for each disease\n    for i, label in enumerate(label_columns):\n        pred_df[f\"{label}_true\"] = all_targets[:, i]\n        pred_df[f\"{label}\"] = all_binary_preds[:, i]  # Only binary predictions\n    \n    # Add demographic information if available\n    if admissions_df is not None and patients_df is not None:\n        # Convert subject_id to the same type before merging\n        pred_df['subject_id'] = pred_df['subject_id'].astype(str)\n        admissions_df['subject_id'] = admissions_df['subject_id'].astype(str)\n        patients_df['subject_id'] = patients_df['subject_id'].astype(str)\n        \n        # Merge with admissions data\n        pred_df = pd.merge(\n            pred_df, \n            admissions_df[['subject_id', 'insurance', 'marital_status', 'ethnicity']], \n            on='subject_id', \n            how='left'\n        )\n        \n        # Merge with patients data\n        pred_df = pd.merge(\n            pred_df, \n            patients_df[['subject_id', 'gender', 'anchor_year_group']], \n            on='subject_id', \n            how='left'\n        )\n    \n    # Save to CSV\n    pred_df.to_csv(file_name, index=False)\n    print(f\"Predictions saved to {file_name}\")\n    \n    return all_probs, all_targets, pred_df\n\n# Function to analyze predictions by demographic subgroups\ndef analyze_by_subgroups(predictions_df, label_columns, subgroup_cols=None):\n    \"\"\"\n    Analyze model performance across different demographic subgroups\n    \n    Args:\n        predictions_df: DataFrame with predictions and demographic info\n        label_columns: List of disease labels\n        subgroup_cols: List of demographic columns to analyze by\n                      (default: ['gender', 'ethnicity', 'insurance', 'marital_status', 'anchor_year_group'])\n    \n    Returns:\n        results_dict: Dictionary with performance metrics by subgroup\n    \"\"\"\n    if subgroup_cols is None:\n        subgroup_cols = ['gender', 'ethnicity', 'insurance', 'marital_status', 'anchor_year_group']\n    \n    results_dict = {}\n    \n    # Analyze each subgroup separately\n    for group_col in subgroup_cols:\n        if group_col not in predictions_df.columns:\n            continue\n            \n        # Get unique values for this subgroup\n        subgroups = predictions_df[group_col].dropna().unique()\n        \n        group_results = {}\n        for subgroup in subgroups:\n            # Filter for this subgroup\n            subgroup_df = predictions_df[predictions_df[group_col] == subgroup]\n            \n            if len(subgroup_df) < 10:  # Skip if too few samples\n                continue\n                \n            # Calculate metrics for each disease label\n            disease_metrics = {}\n            for label in label_columns:\n                true_col = f\"{label}_true\"\n                pred_col = f\"{label}\"\n                \n                # Extract ground truth and predictions\n                y_true = subgroup_df[true_col].values\n                y_pred = subgroup_df[pred_col].values\n                \n                # Skip if no positive examples\n                if sum(y_true) == 0:\n                    continue\n                    \n                # Calculate metrics\n                accuracy = accuracy_score(y_true, y_pred)\n                precision = precision_score(y_true, y_pred, zero_division=0)\n                recall = recall_score(y_true, y_pred, zero_division=0)\n                f1 = f1_score(y_true, y_pred, zero_division=0)\n                \n                # Store results\n                disease_metrics[label] = {\n                    'accuracy': accuracy,\n                    'precision': precision,\n                    'recall': recall,\n                    'f1': f1,\n                    'sample_count': len(y_true),\n                    'positive_count': sum(y_true)\n                }\n            \n            group_results[subgroup] = {\n                'sample_count': len(subgroup_df),\n                'disease_metrics': disease_metrics\n            }\n        \n        results_dict[group_col] = group_results\n    \n    return results_dict\n\n# Function to create visualizations of subgroup performance\ndef visualize_subgroup_performance(subgroup_results, metric='f1', output_dir='subgroup_analysis'):\n    \"\"\"\n    Create visualizations comparing model performance across subgroups\n    \n    Args:\n        subgroup_results: Results dictionary from analyze_by_subgroups\n        metric: Which metric to visualize ('accuracy', 'precision', 'recall', 'f1')\n        output_dir: Directory to save plots\n    \"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    \n    for group_name, group_data in subgroup_results.items():\n        # Get all diseases across all subgroups\n        all_diseases = set()\n        for subgroup, subgroup_data in group_data.items():\n            all_diseases.update(subgroup_data['disease_metrics'].keys())\n        \n        # Create a dataframe for plotting\n        plot_data = []\n        for subgroup, subgroup_data in group_data.items():\n            for disease, metrics in subgroup_data['disease_metrics'].items():\n                plot_data.append({\n                    'Subgroup': subgroup,\n                    'Disease': disease,\n                    metric: metrics[metric],\n                    'Sample Count': metrics['sample_count']\n                })\n        \n        if not plot_data:\n            continue\n            \n        plot_df = pd.DataFrame(plot_data)\n        \n        # Create heatmap\n        plt.figure(figsize=(12, 8))\n        pivot_table = plot_df.pivot_table(\n            values=metric, \n            index='Disease', \n            columns='Subgroup'\n        )\n        \n        sns.heatmap(pivot_table, annot=True, cmap='YlGnBu', fmt='.2f', linewidths=.5)\n        plt.title(f'{metric.capitalize()} by {group_name} Subgroups')\n        plt.tight_layout()\n        plt.savefig(f\"{output_dir}/{group_name}_{metric}_heatmap.png\")\n        plt.close()\n        \n        # Create grouped bar plot\n        plt.figure(figsize=(14, 10))\n        sns.barplot(x='Disease', y=metric, hue='Subgroup', data=plot_df)\n        plt.title(f'{metric.capitalize()} by Disease and {group_name}')\n        plt.xticks(rotation=45, ha='right')\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n        plt.tight_layout()\n        plt.savefig(f\"{output_dir}/{group_name}_{metric}_barplot.png\")\n        plt.close()\n\n# Main training function with demographic integration\ndef train_and_evaluate(dataset, label_columns, test_size=0.2, batch_size=64, num_epochs=25):\n    \"\"\"\n    Complete pipeline for training, evaluation, and subgroup analysis\n    \n    Args:\n        dataset: The dataset to use\n        label_columns: List of disease labels\n        test_size: Fraction of data to use for testing\n        batch_size: Batch size for training\n        num_epochs: Number of training epochs\n    \"\"\"\n    # Load demographic data\n    print(\"Loading demographic data...\")\n    admissions_df, patients_df = load_demographic_data()\n    print(f\"Loaded admissions data for {len(admissions_df)} patients\")\n    print(f\"Loaded patient data for {len(patients_df)} patients\")\n    \n    # Create output directories\n    os.makedirs('predictions', exist_ok=True)\n    os.makedirs('subgroup_analysis', exist_ok=True)\n    \n    # Setup device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Split dataset\n    dataset_size = len(dataset)\n    test_count = int(test_size * dataset_size)\n    train_count = dataset_size - test_count\n    train_dataset, test_dataset = random_split(\n        dataset, [train_count, test_count], \n        generator=torch.Generator().manual_seed(42)\n    )\n    print(f\"Training on {len(train_dataset)} samples, testing on {len(test_dataset)} samples\")\n    \n    # Create data loaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n    \n    # Initialize model\n    model = ChestXrayClassifier(input_dim=1376, output_dim=len(label_columns))\n    model.to(device)\n    \n    # Initialize loss and optimizer\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    # Training setup\n    train_losses = []\n    test_losses = []\n    test_aucs = []\n    \n    # Training loop\n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        train_loss = 0.0\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n        for batch in progress_bar:\n            # Move data to device\n            inputs = batch['embedding'].to(device)\n            targets = batch['labels_one_hot'].to(device)\n            \n            # Zero the gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            # Backward pass and optimize\n            loss.backward()\n            optimizer.step()\n            \n            # Update statistics\n            train_loss += loss.item() * inputs.size(0)\n            progress_bar.set_postfix({'loss': loss.item()})\n        \n        train_loss /= len(train_loader.dataset)\n        train_losses.append(train_loss)\n        \n        # Evaluation\n        model.eval()\n        test_loss = 0.0\n        all_outputs = []\n        all_targets = []\n        \n        with torch.no_grad():\n            for batch in test_loader:\n                inputs = batch['embedding'].to(device)\n                targets = batch['labels_one_hot'].to(device)\n                \n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                \n                test_loss += loss.item() * inputs.size(0)\n                all_outputs.append(outputs.cpu().numpy())\n                all_targets.append(targets.cpu().numpy())\n        \n        test_loss /= len(test_loader.dataset)\n        test_losses.append(test_loss)\n        \n        # Calculate AUC for each label\n        all_outputs = np.vstack(all_outputs)\n        all_targets = np.vstack(all_targets)\n        all_probs = 1 / (1 + np.exp(-all_outputs))  # sigmoid\n        \n        aucs = {}\n        for i, label in enumerate(label_columns):\n            if sum(all_targets[:, i]) > 0:  # Only if there are positive examples\n                aucs[label] = roc_auc_score(all_targets[:, i], all_probs[:, i])\n        \n        mean_auc = np.mean(list(aucs.values()))\n        test_aucs.append(mean_auc)\n        \n        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n        print(f\"  Train Loss: {train_loss:.4f}\")\n        print(f\"  Test Loss: {test_loss:.4f}\")\n        print(f\"  Mean AUC: {mean_auc:.4f}\")\n        \n        # Save predictions with demographic data every 5 epochs and at the last epoch\n        if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n            train_probs, train_targets, train_pred_df = save_predictions_to_csv(\n                train_loader, model, device, label_columns, \n                f'predictions/train_predictions_epoch_{epoch+1}.csv',\n                admissions_df, patients_df\n            )\n            \n            test_probs, test_targets, test_pred_df = save_predictions_to_csv(\n                test_loader, model, device, label_columns, \n                f'predictions/test_predictions_epoch_{epoch+1}.csv',\n                admissions_df, patients_df\n            )\n            \n            # Perform subgroup analysis at final epoch\n            if epoch == num_epochs - 1:\n                print(\"\\nPerforming subgroup analysis on test predictions...\")\n                subgroup_results = analyze_by_subgroups(test_pred_df, label_columns)\n                \n                # Save subgroup analysis results\n                with open('subgroup_analysis/subgroup_results.txt', 'w') as f:\n                    for group, group_data in subgroup_results.items():\n                        f.write(f\"===== {group} =====\\n\")\n                        for subgroup, metrics in group_data.items():\n                            f.write(f\"\\n-- {subgroup} (n={metrics['sample_count']}) --\\n\")\n                            for disease, disease_metrics in metrics['disease_metrics'].items():\n                                f.write(f\"  {disease}:\\n\")\n                                for metric_name, value in disease_metrics.items():\n                                    if metric_name in ['accuracy', 'precision', 'recall', 'f1']:\n                                        f.write(f\"    {metric_name}: {value:.4f}\\n\")\n                        f.write(\"\\n\\n\")\n                \n                # Create visualizations\n                print(\"Creating subgroup performance visualizations...\")\n                visualize_subgroup_performance(subgroup_results, metric='f1')\n                visualize_subgroup_performance(subgroup_results, metric='accuracy')\n    \n    # Plot training curves\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(test_losses, label='Test Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.subplot(1, 2, 2)\n    plt.plot(test_aucs, label='Mean AUC')\n    plt.xlabel('Epoch')\n    plt.ylabel('AUC')\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig('training_curves.png')\n    plt.show()\n    \n    # Final evaluation and save predictions\n    print(\"\\nGenerating final prediction CSVs...\")\n    train_probs, train_targets, train_pred_df = save_predictions_to_csv(\n        train_loader, model, device, label_columns, \n        'predictions/train_predictions_final.csv',\n        admissions_df, patients_df\n    )\n    \n    test_probs, test_targets, test_pred_df = save_predictions_to_csv(\n        test_loader, model, device, label_columns, \n        'predictions/test_predictions_final.csv',\n        admissions_df, patients_df\n    )\n    \n    # Calculate final metrics\n    test_preds = (test_probs >= 0.5).astype(int)\n    metrics_df = pd.DataFrame(columns=['Label', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1'])\n    \n    print(\"\\nFinal metrics by condition:\")\n    for i, label in enumerate(label_columns):\n        # Skip if no positive examples\n        if sum(test_targets[:, i]) > 0:\n            auc = roc_auc_score(test_targets[:, i], test_probs[:, i])\n            accuracy = accuracy_score(test_targets[:, i], test_preds[:, i])\n            precision = precision_score(test_targets[:, i], test_preds[:, i], zero_division=0)\n            recall = recall_score(test_targets[:, i], test_preds[:, i], zero_division=0)\n            f1 = f1_score(test_targets[:, i], test_preds[:, i], zero_division=0)\n            \n            print(f\"{label}:\")\n            print(f\"  AUC: {auc:.4f}\")\n            print(f\"  Accuracy: {accuracy:.4f}\")\n            print(f\"  Precision: {precision:.4f}\")\n            print(f\"  Recall: {recall:.4f}\")\n            print(f\"  F1: {f1:.4f}\")\n            \n            # Add to metrics dataframe\n            metrics_df = pd.concat([\n                metrics_df, \n                pd.DataFrame({\n                    'Label': [label],\n                    'AUC': [auc],\n                    'Accuracy': [accuracy],\n                    'Precision': [precision],\n                    'Recall': [recall],\n                    'F1': [f1]\n                })\n            ], ignore_index=True)\n    \n    print(f\"\\nOverall Mean AUC: {metrics_df['AUC'].mean():.4f}\")\n    metrics_df.to_csv('predictions/metrics_summary.csv', index=False)\n    \n    # Save model\n    torch.save(model.state_dict(), 'chest_xray_model.pth')\n    print(\"Model saved to 'chest_xray_model.pth'\")\n    \n    # Generate demographic fairness report\n    print(\"\\nGenerating fairness analysis across demographic groups...\")\n    fairness_df = pd.DataFrame(columns=['Group', 'Subgroup', 'Label', 'AUC', 'Accuracy', 'F1', 'Count'])\n    \n    for group_name, group_data in subgroup_results.items():\n        for subgroup, subgroup_data in group_data.items():\n            for disease, metrics in subgroup_data['disease_metrics'].items():\n                fairness_df = pd.concat([\n                    fairness_df,\n                    pd.DataFrame({\n                        'Group': [group_name],\n                        'Subgroup': [subgroup],\n                        'Label': [disease],\n                        'AUC': [metrics.get('auc', 0)],\n                        'Accuracy': [metrics['accuracy']],\n                        'F1': [metrics['f1']],\n                        'Count': [metrics['sample_count']]\n                    })\n                ], ignore_index=True)\n    \n    fairness_df.to_csv('predictions/fairness_analysis.csv', index=False)\n    \n    # Create disparity visualizations\n    plt.figure(figsize=(15, 10))\n    for metric in ['Accuracy', 'F1']:\n        for group in fairness_df['Group'].unique():\n            group_data = fairness_df[fairness_df['Group'] == group]\n            \n            plt.figure(figsize=(12, 8))\n            sns.boxplot(x='Label', y=metric, hue='Subgroup', data=group_data)\n            plt.title(f'{metric} Disparities by {group}')\n            plt.xticks(rotation=45, ha='right')\n            plt.tight_layout()\n            plt.savefig(f'subgroup_analysis/{group}_{metric}_disparity.png')\n            plt.close()\n    \n    # Summary analysis: Create a disparity metric\n    # (max performance - min performance) for each disease/group pair\n    disparity_df = fairness_df.groupby(['Group', 'Label']).agg({\n        'F1': ['min', 'max', lambda x: max(x) - min(x)],\n        'Accuracy': ['min', 'max', lambda x: max(x) - min(x)],\n        'Count': 'sum'\n    }).reset_index()\n    \n    # Rename the columns for clarity\n    disparity_df.columns = [\n        'Group', 'Label', 'F1_Min', 'F1_Max', 'F1_Disparity', \n        'Acc_Min', 'Acc_Max', 'Acc_Disparity', 'Total_Count'\n    ]\n    \n    # Sort by F1 disparity (largest disparities first)\n    disparity_df = disparity_df.sort_values('F1_Disparity', ascending=False)\n    disparity_df.to_csv('predictions/performance_disparities.csv', index=False)\n    \n    # Visualization of the largest disparities\n    top_disparities = disparity_df.head(10)  # Top 10 disparities\n    \n    plt.figure(figsize=(12, 8))\n    sns.barplot(x='Label', y='F1_Disparity', hue='Group', data=top_disparities)\n    plt.title('Top Performance Disparities (F1 Score)')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('subgroup_analysis/top_disparities.png')\n    \n    # Perform TPR analysis\n    print(\"\\nPerforming TPR analysis by demographic subgroups...\")\n    plot_subgroup_tpr_and_disparities(test_pred_df, label_columns)\n    \n    # Statistical analysis of TPR disparities\n    tpr_disparities = analyze_tpr_fairness(test_pred_df, label_columns)\n    tpr_disparities.to_csv('tpr_analysis/significant_tpr_disparities.csv', index=False)\n    \n    # Print significant disparities\n    significant_disparities = tpr_disparities[tpr_disparities['Significant']]\n    if len(significant_disparities) > 0:\n        print(\"\\nSignificant TPR disparities found:\")\n        for _, row in significant_disparities.sort_values('TPR_Disparity', ascending=False).head(5).iterrows():\n            print(f\"  {row['Disease']} - {row['Demographic_Group']}: {row['Reference']} vs {row['Subgroup']}\")\n            print(f\"    TPR disparity: {row['TPR_Disparity']:.4f} (p-value: {row['P_Value']:.4f})\")\n    \n    return model, metrics_df, fairness_df, disparity_df, tpr_disparities\n\n# Function for detailed analysis on a specific demographic group\ndef analyze_specific_subgroup(predictions_df, label_columns, group_col, subgroup_value):\n    \"\"\"\n    Perform detailed analysis on a specific demographic subgroup\n    \n    Args:\n        predictions_df: DataFrame with predictions and demographic data\n        label_columns: List of disease labels\n        group_col: Column name for the demographic group (e.g., 'gender', 'ethnicity')\n        subgroup_value: Specific value to analyze (e.g., 'F', 'White')\n        \n    Returns:\n        subgroup_metrics: Dictionary with detailed metrics\n    \"\"\"\n    # Filter for the specific subgroup\n    subgroup_df = predictions_df[predictions_df[group_col] == subgroup_value]\n    \n    if len(subgroup_df) == 0:\n        print(f\"No samples found for {group_col}={subgroup_value}\")\n        return None\n    \n    print(f\"Analyzing {len(subgroup_df)} samples for {group_col}={subgroup_value}\")\n    \n    # Calculate metrics for each disease\n    disease_metrics = {}\n    for label in label_columns:\n        true_col = f\"{label}_true\"\n        pred_col = f\"{label}\"\n        \n        # Extract ground truth and predictions\n        y_true = subgroup_df[true_col].values\n        y_pred = subgroup_df[pred_col].values\n        y_proba = np.array([0.5] * len(y_pred))  # Use 0.5 as placeholder if probabilities aren't available\n        \n        # Skip if no positive examples\n        if sum(y_true) == 0:\n            continue\n            \n        # Calculate confusion matrix elements\n        tn = np.sum((y_true == 0) & (y_pred == 0))\n        fp = np.sum((y_true == 0) & (y_pred == 1))\n        fn = np.sum((y_true == 1) & (y_pred == 0))\n        tp = np.sum((y_true == 1) & (y_pred == 1))\n        \n        # Calculate metrics\n        accuracy = (tp + tn) / (tp + tn + fp + fn)\n        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n        \n        # Store detailed metrics\n        disease_metrics[label] = {\n            'accuracy': accuracy,\n            'precision': precision,\n            'recall': recall,\n            'specificity': specificity,\n            'f1': f1,\n            'true_positives': int(tp),\n            'false_positives': int(fp),\n            'true_negatives': int(tn),\n            'false_negatives': int(fn),\n            'positive_count': int(sum(y_true)),\n            'sample_count': len(y_true),\n            'positive_rate': sum(y_true) / len(y_true)\n        }\n    \n    # Create demographics breakdown for this subgroup\n    demographics = {}\n    for demo_col in ['gender', 'ethnicity', 'insurance', 'marital_status', 'anchor_year_group']:\n        if demo_col != group_col and demo_col in subgroup_df.columns:\n            demographics[demo_col] = subgroup_df[demo_col].value_counts().to_dict()\n    \n    subgroup_metrics = {\n        'sample_count': len(subgroup_df),\n        'disease_metrics': disease_metrics,\n        'demographics': demographics\n    }\n    \n    return subgroup_metrics\n\n# Function to analyze TPR and disparities by subgroup\ndef plot_subgroup_tpr_and_disparities(predictions_df, label_columns, output_dir='tpr_analysis'):\n    \"\"\"\n    Create plots showing:\n    1. TPR (recall) for each subgroup within each demographic group\n    2. Disparity from overall TPR for each subgroup\n    \n    Args:\n        predictions_df: DataFrame with predictions and demographic data\n        label_columns: List of disease labels\n        output_dir: Directory to save output plots\n    \"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # Define demographic groups to analyze\n    demographic_groups = ['gender', 'ethnicity', 'insurance', 'marital_status', 'anchor_year_group']\n    demographic_groups = [g for g in demographic_groups if g in predictions_df.columns]\n    \n    # First, calculate overall TPR for each disease\n    overall_tpr = {}\n    for label in label_columns:\n        true_col = f\"{label}_true\"\n        pred_col = f\"{label}\"\n        \n        # Calculate overall TPR (recall)\n        y_true = predictions_df[true_col].values\n        y_pred = predictions_df[pred_col].values\n        \n        # Skip if no positive cases\n        if sum(y_true) == 0:\n            continue\n            \n        overall_tpr[label] = recall_score(y_true, y_pred, zero_division=0)\n    \n    # Now calculate TPR for each subgroup and the disparity\n    tpr_data = []\n    \n    for group in demographic_groups:\n        for label in overall_tpr.keys():\n            true_col = f\"{label}_true\"\n            pred_col = f\"{label}\"\n            \n            # Calculate TPR for each subgroup in this demographic group\n            for subgroup in predictions_df[group].dropna().unique():\n                subgroup_df = predictions_df[predictions_df[group] == subgroup]\n                \n                # Skip if too few samples\n                if len(subgroup_df) < 10:\n                    continue\n                \n                y_true = subgroup_df[true_col].values\n                y_pred = subgroup_df[pred_col].values\n                \n                # Skip if no positive cases in this subgroup\n                if sum(y_true) == 0:\n                    continue\n                \n                # Calculate TPR for this subgroup\n                subgroup_tpr = recall_score(y_true, y_pred, zero_division=0)\n                \n                # Calculate disparity from overall TPR\n                tpr_disparity = subgroup_tpr - overall_tpr[label]\n                \n                # Add to data collection\n                tpr_data.append({\n                    'Demographic_Group': group,\n                    'Subgroup': subgroup,\n                    'Disease': label,\n                    'TPR': subgroup_tpr,\n                    'Overall_TPR': overall_tpr[label],\n                    'TPR_Disparity': tpr_disparity,\n                    'Sample_Count': len(y_true),\n                    'Positive_Count': sum(y_true)\n                })\n    \n    # Convert to DataFrame\n    tpr_df = pd.DataFrame(tpr_data)\n    \n    # Save the data\n    tpr_df.to_csv(f\"{output_dir}/tpr_by_subgroup.csv\", index=False)\n    \n    # Create plots for each demographic group\n    for group in demographic_groups:\n        group_data = tpr_df[tpr_df['Demographic_Group'] == group]\n        \n        if len(group_data) == 0:\n            continue\n        \n        # Plot 1: TPR by subgroup for each disease\n        plt.figure(figsize=(14, 8))\n        sns.barplot(x='Disease', y='TPR', hue='Subgroup', data=group_data)\n        plt.title(f'True Positive Rate by {group} Subgroup')\n        plt.xticks(rotation=45, ha='right')\n        plt.ylim(0, 1)  # TPR ranges from 0 to 1\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n        plt.tight_layout()\n        plt.savefig(f\"{output_dir}/{group}_tpr_by_subgroup.png\")\n        plt.close()\n        \n        # Plot 2: TPR Disparity from overall TPR\n        plt.figure(figsize=(14, 8))\n        sns.barplot(x='Disease', y='TPR_Disparity', hue='Subgroup', data=group_data)\n        plt.title(f'TPR Disparity from Overall by {group} Subgroup')\n        plt.xticks(rotation=45, ha='right')\n        plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)  # Add a line at y=0\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n        plt.tight_layout()\n        plt.savefig(f\"{output_dir}/{group}_tpr_disparity.png\")\n        plt.close()\n        \n        # Plot 3: Heatmap of TPR by subgroup and disease\n        if len(group_data['Subgroup'].unique()) > 1 and len(group_data['Disease'].unique()) > 1:\n            plt.figure(figsize=(12, 8))\n            pivot_tpr = group_data.pivot_table(\n                values='TPR', \n                index='Disease', \n                columns='Subgroup'\n            )\n            sns.heatmap(pivot_tpr, annot=True, cmap='YlGnBu', fmt='.2f', linewidths=.5)\n            plt.title(f'TPR Heatmap by {group} Subgroup')\n            plt.tight_layout()\n            plt.savefig(f\"{output_dir}/{group}_tpr_heatmap.png\")\n            plt.close()\n            \n            # Plot 4: Heatmap of TPR disparities\n            plt.figure(figsize=(12, 8))\n            pivot_disparity = group_data.pivot_table(\n                values='TPR_Disparity', \n                index='Disease', \n                columns='Subgroup'\n            )\n            # Use a diverging colormap centered at 0\n            sns.heatmap(pivot_disparity, annot=True, cmap='RdBu_r', fmt='.2f', \n                         linewidths=.5, center=0)\n            plt.title(f'TPR Disparity Heatmap by {group} Subgroup')\n            plt.tight_layout()\n            plt.savefig(f\"{output_dir}/{group}_tpr_disparity_heatmap.png\")\n            plt.close()\n\n# Function to perform statistical analysis of TPR disparities\ndef analyze_tpr_fairness(predictions_df, label_columns, significance_threshold=0.05):\n    \"\"\"\n    Perform statistical analysis on TPR disparities to identify significant differences\n    \n    Args:\n        predictions_df: DataFrame with predictions and demographic info\n        label_columns: List of disease labels\n        significance_threshold: p-value threshold for statistical significance\n        \n    Returns:\n        DataFrame with significant TPR disparities\n    \"\"\"\n    from scipy.stats import fisher_exact\n    \n    demographic_groups = ['gender', 'ethnicity', 'insurance', 'marital_status', 'anchor_year_group']\n    demographic_groups = [g for g in demographic_groups if g in predictions_df.columns]\n    \n    result_data = []\n    \n    for group in demographic_groups:\n        # Get the majority subgroup as reference\n        reference = predictions_df[group].value_counts().index[0]\n        \n        for label in label_columns:\n            true_col = f\"{label}_true\"\n            pred_col = f\"{label}\"\n            \n            # Get reference subgroup contingency table \n            ref_df = predictions_df[predictions_df[group] == reference]\n            ref_tp = np.sum((ref_df[true_col] == 1) & (ref_df[pred_col] == 1))\n            ref_fn = np.sum((ref_df[true_col] == 1) & (ref_df[pred_col] == 0))\n            ref_tpr = ref_tp / (ref_tp + ref_fn) if (ref_tp + ref_fn) > 0 else 0\n            \n            # Compare with other subgroups\n            for subgroup in predictions_df[group].dropna().unique():\n                if subgroup == reference:\n                    continue\n                \n                subgroup_df = predictions_df[predictions_df[group] == subgroup]\n                \n                # Skip if too few samples\n                if len(subgroup_df) < 20:\n                    continue\n                \n                # Calculate TPR\n                sg_tp = np.sum((subgroup_df[true_col] == 1) & (subgroup_df[pred_col] == 1))\n                sg_fn = np.sum((subgroup_df[true_col] == 1) & (subgroup_df[pred_col] == 0))\n                sg_tpr = sg_tp / (sg_tp + sg_fn) if (sg_tp + sg_fn) > 0 else 0\n                \n                # Skip if no positive cases\n                if (ref_tp + ref_fn) == 0 or (sg_tp + sg_fn) == 0:\n                    continue\n                \n                # Statistical test (Fisher's exact test on the contingency table)\n                contingency = np.array([[ref_tp, ref_fn], [sg_tp, sg_fn]])\n                odds_ratio, p_value = fisher_exact(contingency)\n                \n                tpr_disparity = sg_tpr - ref_tpr\n                significant = p_value < significance_threshold\n                \n                result_data.append({\n                    'Demographic_Group': group,\n                    'Reference': reference,\n                    'Subgroup': subgroup,\n                    'Disease': label,\n                    'Reference_TPR': ref_tpr,\n                    'Subgroup_TPR': sg_tpr,\n                    'TPR_Disparity': tpr_disparity,\n                    'P_Value': p_value,\n                    'Significant': significant,\n                    'Reference_Positive_Count': ref_tp + ref_fn,\n                    'Subgroup_Positive_Count': sg_tp + sg_fn\n                })\n    \n    result_df = pd.DataFrame(result_data)\n    return result_df\n\n# Function for fairness gap analysis across multiple groups\ndef fairness_gap_analysis(predictions_df, label_columns, reference_groups=None):\n    \"\"\"\n    Calculate fairness gaps (performance differences) between demographic groups\n    \n    Args:\n        predictions_df: DataFrame with predictions and demographic data\n        label_columns: List of disease labels\n        reference_groups: Dictionary mapping demographic columns to reference groups\n                         (e.g., {'gender': 'M', 'ethnicity': 'White'})\n                         \n    Returns:\n        gaps_df: DataFrame with fairness gaps\n    \"\"\"\n    if reference_groups is None:\n        # Default reference groups (typically majority groups in each category)\n        reference_groups = {\n            'gender': predictions_df['gender'].value_counts().index[0],\n            'ethnicity': 'White',\n            'insurance': 'Private',\n            'marital_status': 'Married'\n        }\n    \n    gaps_data = []\n    \n    # For each demographic group\n    for group_col, ref_group in reference_groups.items():\n        if group_col not in predictions_df.columns:\n            continue\n            \n        # Skip if reference group doesn't exist in the data\n        if ref_group not in predictions_df[group_col].values:\n            continue\n            \n        # Get metrics for reference group\n        ref_metrics = analyze_specific_subgroup(predictions_df, label_columns, group_col, ref_group)\n        \n        if ref_metrics is None:\n            continue\n            \n        # Compare with other groups\n        for other_group in predictions_df[group_col].dropna().unique():\n            if other_group == ref_group:\n                continue\n                \n            other_metrics = analyze_specific_subgroup(predictions_df, label_columns, group_col, other_group)\n            \n            if other_metrics is None:\n                continue\n                \n            # Calculate gaps for each disease and metric\n            for disease in ref_metrics['disease_metrics'].keys():\n                if disease not in other_metrics['disease_metrics']:\n                    continue\n                    \n                for metric in ['accuracy', 'precision', 'recall', 'f1']:\n                    ref_value = ref_metrics['disease_metrics'][disease][metric]\n                    other_value = other_metrics['disease_metrics'][disease][metric]\n                    gap = other_value - ref_value\n                    \n                    gaps_data.append({\n                        'Group': group_col,\n                        'Reference': ref_group,\n                        'Comparison': other_group,\n                        'Disease': disease,\n                        'Metric': metric,\n                        'Reference_Value': ref_value,\n                        'Comparison_Value': other_value,\n                        'Gap': gap,\n                        'Relative_Gap': gap / ref_value if ref_value > 0 else 0,\n                        'Reference_Count': ref_metrics['disease_metrics'][disease]['sample_count'],\n                        'Comparison_Count': other_metrics['disease_metrics'][disease]['sample_count']\n                    })\n    \n    # Convert to DataFrame\n    gaps_df = pd.DataFrame(gaps_data)\n    \n    # Add an absolute gap column for sorting\n    gaps_df['Absolute_Gap'] = gaps_df['Gap'].abs()\n    \n    return gaps_df\n\n# Main execution\nif __name__ == \"__main__\":\n    # Assuming dataset and label_columns are defined elsewhere\n    \n    # Train the model and perform demographic analysis\n    model, metrics_df, fairness_df, disparity_df, tpr_disparities = train_and_evaluate(\n        dataset=dataset,\n        label_columns=label_columns,\n        num_epochs=25\n    )\n    \n    print(\"\\nTraining complete. Analysis saved to 'predictions', 'subgroup_analysis', and 'tpr_analysis' directories.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.read_csv(\"/kaggle/input/mimic-patients/admissions.csv\").head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.read_csv(\"/kaggle/input/mimic-patients/patients.csv\").head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}