{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":11036050,"sourceType":"datasetVersion","datasetId":6873886},{"sourceId":11093211,"sourceType":"datasetVersion","datasetId":6915183}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport os\nimport pickle\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\n\n# Path to processed data\ndata_path = \"/kaggle/input/mimic-embedding/processed_mimic_data\"\n\nclass ProcessedMIMICDataset(Dataset):\n    def __init__(self, data_path, data_format='pt'):\n        \"\"\"\n        Load a processed MIMIC dataset\n        \n        Args:\n            data_path: Path to the processed data directory\n            data_format: Format to load ('pt' for PyTorch tensors, 'npy' for NumPy, 'pkl' for Pickle)\n        \"\"\"\n        self.data_path = data_path\n        self.data_format = data_format\n        \n        if data_format == 'pkl':\n            # Load the pickle file\n            with open(os.path.join(data_path, \"all_data.pkl\"), 'rb') as f:\n                self.all_data = pickle.load(f)\n            \n            self.embeddings = self.all_data['embeddings']\n            self.labels = self.all_data['labels']\n            self.subject_ids = self.all_data['subject_ids']\n            self.study_ids = self.all_data['study_ids']\n            self.demographics = self.all_data['demographics']\n            \n        elif data_format == 'pt':\n            # Load PyTorch tensors with weights_only=True to avoid security warnings\n            self.embeddings = torch.load(os.path.join(data_path, \"embeddings.pt\"), weights_only=True)\n            self.labels = torch.load(os.path.join(data_path, \"labels.pt\"), weights_only=True)\n            \n            # Load IDs from CSV\n            ids_df = pd.read_csv(os.path.join(data_path, \"ids.csv\"))\n            self.subject_ids = ids_df['subject_id'].tolist()\n            self.study_ids = ids_df['study_id'].tolist()\n            \n            # Load demographics\n            with open(os.path.join(data_path, \"demographics.pkl\"), 'rb') as f:\n                self.demographics = pickle.load(f)\n                \n        elif data_format == 'npy':\n            # Load NumPy arrays\n            self.embeddings = np.load(os.path.join(data_path, \"embeddings.npy\"))\n            self.labels = np.load(os.path.join(data_path, \"labels.npy\"))\n            \n            # Load IDs from CSV\n            ids_df = pd.read_csv(os.path.join(data_path, \"ids.csv\"))\n            self.subject_ids = ids_df['subject_id'].tolist()\n            self.study_ids = ids_df['study_id'].tolist()\n            \n            # Load demographics\n            with open(os.path.join(data_path, \"demographics.pkl\"), 'rb') as f:\n                self.demographics = pickle.load(f)\n                \n        else:\n            raise ValueError(f\"Unsupported data format: {data_format}\")\n        \n        print(f\"Loaded dataset from {data_path} with {len(self.embeddings)} samples\")\n        \n    def __len__(self):\n        return len(self.embeddings)\n    \n    def __getitem__(self, idx):\n        if self.data_format == 'pt':\n            embedding = self.embeddings[idx]\n            labels = self.labels[idx]\n        else:\n            embedding = torch.tensor(self.embeddings[idx], dtype=torch.float32)\n            labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n            \n        return {\n            'embedding': embedding,\n            'labels': labels,\n            'subject_id': self.subject_ids[idx],\n            'study_id': self.study_ids[idx],\n            'demographics': self.demographics[idx]\n        }\n\n# Load the datasets\ntrain_dataset = ProcessedMIMICDataset(os.path.join(data_path, \"train\"), data_format='pt')\ntest_dataset = ProcessedMIMICDataset(os.path.join(data_path, \"test\"), data_format='pt')\n\n# Create validation set from train (if needed)\ndef create_train_val_split(train_dataset, val_ratio=0.1, random_seed=42):\n    \"\"\"Split training dataset into train and validation sets\"\"\"\n    dataset_size = len(train_dataset)\n    val_size = int(val_ratio * dataset_size)\n    train_size = dataset_size - val_size\n    \n    train_subset, val_subset = torch.utils.data.random_split(\n        train_dataset, \n        [train_size, val_size],\n        generator=torch.Generator().manual_seed(random_seed)\n    )\n    \n    print(f\"Split train dataset: {train_size} training samples, {val_size} validation samples\")\n    \n    return train_subset, val_subset\n\n# Create train/val split (optional)\ntrain_subset, val_subset = create_train_val_split(train_dataset)\n\n# Create data loaders\nbatch_size = 128\ntrain_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_subset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# Display dataset statistics\nprint(f\"Training samples: {len(train_subset)}\")\nprint(f\"Validation samples: {len(val_subset)}\")\nprint(f\"Test samples: {len(test_dataset)}\")\n\n# Example of accessing a batch\nsample_batch = next(iter(train_loader))\nprint(f\"Sample batch shapes:\")\nprint(f\"  Embeddings: {sample_batch['embedding'].shape}\")\nprint(f\"  Labels: {sample_batch['labels'].shape}\")\nprint(f\"  Batch keys {sample_batch.keys()}\")\nprint(f\"  Batch[demographic] keys {sample_batch['demographics'].keys()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T04:02:31.687993Z","iopub.execute_input":"2025-03-21T04:02:31.688303Z","iopub.status.idle":"2025-03-21T04:03:10.720012Z","shell.execute_reply.started":"2025-03-21T04:02:31.688266Z","shell.execute_reply":"2025-03-21T04:03:10.718764Z"}},"outputs":[{"name":"stdout","text":"Loaded dataset from /kaggle/input/mimic-embedding/processed_mimic_data/train with 207314 samples\nLoaded dataset from /kaggle/input/mimic-embedding/processed_mimic_data/test with 21591 samples\nSplit train dataset: 186583 training samples, 20731 validation samples\nTraining samples: 186583\nValidation samples: 20731\nTest samples: 21591\nSample batch shapes:\n  Embeddings: torch.Size([128, 1376])\n  Labels: torch.Size([128, 14])\n  Batch keys dict_keys(['embedding', 'labels', 'subject_id', 'study_id', 'demographics'])\n  Batch[demographic] keys dict_keys(['gender', 'insurance', 'race', 'anchor_age'])\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# LWBC Test","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, Subset, random_split\nimport numpy as np\nimport random\nfrom tqdm import tqdm\nfrom copy import deepcopy\nfrom sklearn.metrics import roc_auc_score\n\n# The MIMICClassifier from your code\nclass MIMICClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.2):\n        \"\"\"\n        Simple feed-forward neural network for multi-label classification\n        \n        Args:\n            input_dim: Dimension of input embeddings\n            hidden_dims: List of hidden layer dimensions\n            output_dim: Number of output classes\n            dropout_rate: Dropout probability for regularization\n        \"\"\"\n        super(MIMICClassifier, self).__init__()\n        \n        # Create the layers\n        layers = []\n        \n        # Input layer\n        layers.append(nn.Linear(input_dim, hidden_dims[0]))\n        layers.append(nn.ReLU())\n        layers.append(nn.BatchNorm1d(hidden_dims[0]))\n        layers.append(nn.Dropout(dropout_rate))\n        \n        # Hidden layers\n        for i in range(len(hidden_dims)-1):\n            layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n            layers.append(nn.ReLU())\n            layers.append(nn.BatchNorm1d(hidden_dims[i+1]))\n            layers.append(nn.Dropout(dropout_rate))\n        \n        # Output layer\n        layers.append(nn.Linear(hidden_dims[-1], output_dim))\n        \n        self.model = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)\n\n# Learning with Biased Committee implementation\nclass LWBC:\n    def __init__(\n        self,\n        train_loader,\n        val_loader,\n        input_dim=1376,\n        hidden_dims=[512, 256, 128],\n        output_dim=14,\n        committee_size=30,\n        subset_size=0.7,\n        alpha=0.02,\n        lambda_kd=0.6,\n        temperature=2.0,\n        device='cuda' if torch.cuda.is_available() else 'cpu'\n    ):\n        \"\"\"\n        LWBC implementation for MIMIC dataset.\n        \n        Args:\n            train_loader: DataLoader for training data\n            val_loader: DataLoader for validation data\n            input_dim: Input embedding dimension\n            hidden_dims: Hidden layer dimensions\n            output_dim: Number of output classes\n            committee_size: Number of classifiers in the committee\n            subset_size: Size of subset for each committee member (proportion)\n            alpha: Scaling parameter for weighting function\n            lambda_kd: Balance parameter for knowledge distillation\n            temperature: Temperature for knowledge distillation\n            device: Device to run computations on\n        \"\"\"\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.input_dim = input_dim\n        self.hidden_dims = hidden_dims\n        self.output_dim = output_dim\n        self.committee_size = committee_size\n        self.subset_size = subset_size\n        self.alpha = alpha\n        self.lambda_kd = lambda_kd\n        self.temperature = temperature\n        self.device = device\n        \n        # Initialize main classifier\n        self.main_classifier = MIMICClassifier(\n            input_dim, hidden_dims, output_dim\n        ).to(device)\n        \n        # Initialize committee of auxiliary classifiers\n        self.committee = [\n            MIMICClassifier(input_dim, hidden_dims, output_dim).to(device)\n            for _ in range(committee_size)\n        ]\n        \n        # Initialize optimizers\n        self.main_optimizer = optim.Adam(self.main_classifier.parameters(), lr=1e-3)\n        self.committee_optimizers = [\n            optim.Adam(classifier.parameters(), lr=1e-3)\n            for classifier in self.committee\n        ]\n        \n        # Loss function for multi-label classification\n        self.criterion = nn.BCEWithLogitsLoss(reduction='none')\n        \n        # Create subsets for each committee member\n        self.create_subsets()\n        \n    def create_subsets(self):\n        \"\"\"Create random subsets of training data for each committee member\"\"\"\n        # Count total samples in the training dataset\n        dataset_size = len(self.train_loader.dataset)\n        subset_count = int(dataset_size * self.subset_size)\n        \n        # Create subsets for each committee member\n        self.subsets = []\n        for _ in range(self.committee_size):\n            # Sample indices with replacement\n            subset_indices = random.choices(range(dataset_size), k=subset_count)\n            self.subsets.append(sorted(subset_indices))\n    \n    def compute_sample_weights(self, outputs, labels):\n        \"\"\"\n        Compute sample weights based on committee consensus\n        \n        Args:\n            outputs: List of outputs from committee members\n            labels: Ground truth labels\n            \n        Returns:\n            Tensor of sample weights\n        \"\"\"\n        batch_size = labels.size(0)\n        correct_count = torch.zeros(batch_size, device=self.device)\n        \n        # Count correct predictions for each sample across committee\n        for output in outputs:\n            preds = (torch.sigmoid(output) > 0.5).float()\n            correct = (preds == labels).all(dim=1).float()\n            correct_count += correct\n        \n        # Calculate proportion of committee members that predicted correctly\n        correct_proportion = correct_count / self.committee_size\n        \n        # Apply weighting function w(x) = 1 / (proportion + alpha)\n        weights = 1.0 / (correct_proportion + self.alpha)\n        \n        return weights\n    \n    def knowledge_distillation_loss(self, committee_output, main_output):\n        \"\"\"\n        Calculate knowledge distillation loss\n        \n        Args:\n            committee_output: Output from committee member\n            main_output: Output from main classifier\n            \n        Returns:\n            KD loss\n        \"\"\"\n        # Apply temperature scaling\n        committee_logits = committee_output / self.temperature\n        main_logits = main_output / self.temperature\n        \n        # KL divergence between softmax distributions\n        committee_probs = torch.sigmoid(committee_logits)\n        main_probs = torch.sigmoid(main_logits)\n        \n        # Calculate KL divergence for each output dimension\n        kl_div = main_probs * torch.log(main_probs / (committee_probs + 1e-8) + 1e-8) + \\\n                (1 - main_probs) * torch.log((1 - main_probs) / (1 - committee_probs + 1e-8) + 1e-8)\n                \n        return kl_div.mean()\n    \n    def train_committee_warmup(self, num_epochs=5):\n        \"\"\"Warm-up training for committee members\"\"\"\n        print(\"Starting committee warm-up training...\")\n        \n        # Create sample masks for committee members\n        committee_masks = []\n        dataset_size = len(self.train_loader.dataset)\n        for subset_indices in self.subsets:\n            mask = torch.zeros(dataset_size, dtype=torch.bool)\n            mask[subset_indices] = True\n            committee_masks.append(mask)\n        \n        for classifier_idx, classifier in enumerate(self.committee):\n            classifier.train()\n            optimizer = self.committee_optimizers[classifier_idx]\n            mask = committee_masks[classifier_idx]\n            \n            print(f\"Training committee member {classifier_idx+1}/{self.committee_size}\")\n            \n            for epoch in range(num_epochs):\n                total_loss = 0.0\n                num_batches = 0\n                \n                # Create a subset DataLoader\n                subset_dataset = Subset(self.train_loader.dataset, self.subsets[classifier_idx])\n                subset_loader = DataLoader(\n                    subset_dataset, \n                    batch_size=self.train_loader.batch_size,\n                    shuffle=True,\n                    num_workers=0  # Reduce if having memory issues\n                )\n                \n                for batch in subset_loader:\n                    # Extract data\n                    X = batch['embedding'].to(self.device)\n                    y = batch['labels'].to(self.device)\n                    \n                    # Forward pass\n                    outputs = classifier(X)\n                    loss = self.criterion(outputs, y).mean()\n                    \n                    # Backward pass and optimize\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n                    \n                    total_loss += loss.item()\n                    num_batches += 1\n                \n                avg_loss = total_loss / max(1, num_batches)\n                print(f\"  Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n    \n    def train_epoch(self):\n        \"\"\"Train for one epoch\"\"\"\n        self.main_classifier.train()\n        for classifier in self.committee:\n            classifier.train()\n        \n        total_main_loss = 0.0\n        total_committee_loss = 0.0\n        num_batches = 0\n        \n        # Calculate sample weights for all training data\n        print(\"Computing sample weights based on committee consensus...\")\n        sample_weights_dict = {}  # Map batch_idx -> sample_weights\n        \n        # Create mapping from global index to subset inclusion\n        dataset_size = len(self.train_loader.dataset)\n        subset_masks = []\n        for subset in self.subsets:\n            mask = torch.zeros(dataset_size, dtype=torch.bool)\n            mask[subset] = True\n            subset_masks.append(mask)\n            \n        # Get weights for all samples\n        global_sample_weights = torch.ones(dataset_size, device=self.device)\n        \n        # Since we can't fit all data at once, process in batches\n        batch_size = self.train_loader.batch_size\n        \n        # First, get predictions from committee for all samples\n        with torch.no_grad():\n            all_committee_preds = [[] for _ in range(self.committee_size)]\n            all_labels = []\n            batch_offsets = []\n            \n            # Get predictions for the entire dataset\n            offset = 0\n            for batch in tqdm(self.train_loader, desc=\"Getting committee predictions\"):\n                X = batch['embedding'].to(self.device)\n                y = batch['labels'].to(self.device)\n                \n                batch_offsets.append(offset)\n                \n                # Get predictions from each committee member\n                for i, classifier in enumerate(self.committee):\n                    preds = classifier(X)\n                    all_committee_preds[i].append(preds)\n                \n                all_labels.append(y)\n                offset += len(X)\n            \n            # Determine weights for each sample\n            for batch_idx, offset in enumerate(batch_offsets):\n                y = all_labels[batch_idx]\n                batch_size = y.size(0)\n                \n                # Count correct predictions for each sample\n                correct_count = torch.zeros(batch_size, device=self.device)\n                for i in range(self.committee_size):\n                    output = all_committee_preds[i][batch_idx]\n                    preds = (torch.sigmoid(output) > 0.5).float()\n                    correct = (preds == y).all(dim=1).float()\n                    correct_count += correct\n                \n                # Calculate proportion of committee members that predicted correctly\n                correct_proportion = correct_count / self.committee_size\n                \n                # Apply weighting function w(x) = 1 / (proportion + alpha)\n                weights = 1.0 / (correct_proportion + self.alpha)\n                \n                # Store for later use\n                sample_weights_dict[batch_idx] = weights\n        \n        # Main training loop\n        print(\"Training main classifier with weighted samples...\")\n        for batch_idx, batch in enumerate(tqdm(self.train_loader, desc=\"Training main classifier\")):\n            X = batch['embedding'].to(self.device)\n            y = batch['labels'].to(self.device)\n            batch_size = X.size(0)\n            \n            # Get sample weights for this batch\n            sample_weights = sample_weights_dict[batch_idx]\n            \n            # Train main classifier with weighted loss\n            self.main_optimizer.zero_grad()\n            main_outputs = self.main_classifier(X)\n            main_loss = (self.criterion(main_outputs, y) * sample_weights.unsqueeze(1)).mean()\n            main_loss.backward()\n            self.main_optimizer.step()\n            \n            total_main_loss += main_loss.item()\n            num_batches += 1\n        \n        # Train committee members with knowledge distillation\n        print(\"Training committee with knowledge distillation...\")\n        committee_loss_sum = 0.0\n        committee_batches = 0\n        \n        for classifier_idx, classifier in enumerate(self.committee):\n            classifier.train()\n            optimizer = self.committee_optimizers[classifier_idx]\n            \n            # Create subset dataset for this committee member\n            subset_dataset = Subset(self.train_loader.dataset, self.subsets[classifier_idx])\n            subset_loader = DataLoader(\n                subset_dataset,\n                batch_size=self.train_loader.batch_size,\n                shuffle=True,\n                num_workers=0\n            )\n            \n            # Create complement dataset for knowledge distillation\n            complement_indices = [i for i in range(dataset_size) if i not in self.subsets[classifier_idx]]\n            complement_dataset = Subset(self.train_loader.dataset, complement_indices)\n            complement_loader = DataLoader(\n                complement_dataset,\n                batch_size=self.train_loader.batch_size,\n                shuffle=True,\n                num_workers=0\n            )\n            \n            # Train on subset with supervised loss\n            for batch in subset_loader:\n                X = batch['embedding'].to(self.device)\n                y = batch['labels'].to(self.device)\n                \n                # Forward pass\n                optimizer.zero_grad()\n                outputs = classifier(X)\n                ce_loss = self.criterion(outputs, y).mean()\n                ce_loss.backward()\n                optimizer.step()\n            \n            # Train on complement with knowledge distillation\n            for batch in complement_loader:\n                X = batch['embedding'].to(self.device)\n                \n                # Forward pass\n                optimizer.zero_grad()\n                committee_output = classifier(X)\n                \n                # Get main classifier output\n                with torch.no_grad():\n                    main_output = self.main_classifier(X)\n                \n                # Knowledge distillation loss\n                kd_loss = self.knowledge_distillation_loss(committee_output, main_output)\n                kd_loss.backward()\n                optimizer.step()\n                \n                committee_loss_sum += kd_loss.item()\n                committee_batches += 1\n        \n        avg_committee_loss = committee_loss_sum / max(1, committee_batches)\n        \n        return total_main_loss / num_batches, avg_committee_loss\n    \n    def evaluate(self, loader):\n        \"\"\"Evaluate model on validation or test set\"\"\"\n        self.main_classifier.eval()\n        all_outputs = []\n        all_labels = []\n        \n        with torch.no_grad():\n            for batch in loader:\n                X = batch['embedding'].to(self.device)\n                y = batch['labels'].to(self.device)\n                \n                outputs = self.main_classifier(X)\n                all_outputs.append(outputs.cpu())\n                all_labels.append(y.cpu())\n        \n        all_outputs = torch.cat(all_outputs, dim=0)\n        all_labels = torch.cat(all_labels, dim=0)\n        \n        # Compute ROC-AUC score\n        all_outputs_sigmoid = torch.sigmoid(all_outputs).numpy()\n        all_labels_numpy = all_labels.numpy()\n        \n        # Handle case where a class might have all 0s or all 1s\n        auc_scores = []\n        for i in range(self.output_dim):\n            if len(np.unique(all_labels_numpy[:, i])) > 1:\n                auc_scores.append(roc_auc_score(all_labels_numpy[:, i], all_outputs_sigmoid[:, i]))\n            else:\n                auc_scores.append(0.5)  # Default for single-class\n        \n        macro_auc = np.mean(auc_scores)\n        \n        # Compute accuracy\n        predictions = (torch.sigmoid(all_outputs) > 0.5).float()\n        accuracy = (predictions == all_labels).float().mean().item()\n        \n        return accuracy, macro_auc, auc_scores\n    \n    def evaluate_by_demographic(self, loader, demographic_attr='gender'):\n        \"\"\"Evaluate model performance across demographic groups\"\"\"\n        self.main_classifier.eval()\n        results = {}\n        \n        # Initialize dictionaries to store outputs and labels for each group\n        group_outputs = {}\n        group_labels = {}\n        \n        with torch.no_grad():\n            for batch in loader:\n                X = batch['embedding'].to(self.device)\n                y = batch['labels'].to(self.device)\n                \n                # Get demographic attributes\n                demographic_values = batch['demographics'][demographic_attr]\n                \n                # Get model outputs\n                outputs = self.main_classifier(X)\n                \n                # Group by demographic\n                for i, demo_val in enumerate(demographic_values):\n                    demo_val = demo_val.item() if isinstance(demo_val, torch.Tensor) else demo_val\n                    if demo_val not in group_outputs:\n                        group_outputs[demo_val] = []\n                        group_labels[demo_val] = []\n                    \n                    group_outputs[demo_val].append(outputs[i:i+1].cpu())\n                    group_labels[demo_val].append(y[i:i+1].cpu())\n        \n        # Calculate metrics for each group\n        for group in group_outputs:\n            group_output_tensor = torch.cat(group_outputs[group], dim=0)\n            group_label_tensor = torch.cat(group_labels[group], dim=0)\n            \n            # Compute ROC-AUC\n            group_output_sigmoid = torch.sigmoid(group_output_tensor).numpy()\n            group_label_numpy = group_label_tensor.numpy()\n            \n            # Handle case where a class might have all 0s or all 1s\n            auc_scores = []\n            for i in range(self.output_dim):\n                if len(np.unique(group_label_numpy[:, i])) > 1:\n                    auc_scores.append(roc_auc_score(group_label_numpy[:, i], group_output_sigmoid[:, i]))\n                else:\n                    auc_scores.append(0.5)  # Default for single-class\n            \n            macro_auc = np.mean(auc_scores)\n            \n            # Compute accuracy\n            predictions = (torch.sigmoid(group_output_tensor) > 0.5).float()\n            accuracy = (predictions == group_label_tensor).float().mean().item()\n            \n            results[group] = {\n                'accuracy': accuracy,\n                'macro_auc': macro_auc,\n                'count': len(group_labels[group])\n            }\n        \n        return results\n    \n    def train(self, num_epochs=20, warmup_epochs=5):\n        \"\"\"Full training procedure\"\"\"\n        # Warm-up training for committee\n        self.train_committee_warmup(num_epochs=warmup_epochs)\n        \n        # Main training loop\n        best_auc = 0.0\n        best_model = None\n        history = {\n            'train_loss': [],\n            'committee_loss': [],\n            'val_accuracy': [],\n            'val_auc': []\n        }\n        \n        for epoch in range(num_epochs):\n            # Train one epoch\n            train_loss, committee_loss = self.train_epoch()\n            \n            # Evaluate\n            val_accuracy, val_auc, _ = self.evaluate(self.val_loader)\n            \n            # Store history\n            history['train_loss'].append(train_loss)\n            history['committee_loss'].append(committee_loss)\n            history['val_accuracy'].append(val_accuracy)\n            history['val_auc'].append(val_auc)\n            \n            # Print metrics\n            print(f\"Epoch {epoch+1}/{num_epochs}:\")\n            print(f\"  Train Loss: {train_loss:.4f}, Committee Loss: {committee_loss:.4f}\")\n            print(f\"  Val Accuracy: {val_accuracy:.4f}, Val AUC: {val_auc:.4f}\")\n            \n            # Save best model\n            if val_auc > best_auc:\n                best_auc = val_auc\n                best_model = deepcopy(self.main_classifier.state_dict())\n                print(f\"  New best model with Val AUC: {val_auc:.4f}\")\n        \n        # Load best model\n        if best_model is not None:\n            self.main_classifier.load_state_dict(best_model)\n        \n        return history\n    \n    def save_model(self, path):\n        \"\"\"Save the model to disk\"\"\"\n        torch.save(self.main_classifier.state_dict(), path)\n    \n    def load_model(self, path):\n        \"\"\"Load the model from disk\"\"\"\n        self.main_classifier.load_state_dict(torch.load(path, map_location=self.device))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T04:04:00.936904Z","iopub.execute_input":"2025-03-21T04:04:00.937332Z","iopub.status.idle":"2025-03-21T04:04:00.987308Z","shell.execute_reply.started":"2025-03-21T04:04:00.937304Z","shell.execute_reply":"2025-03-21T04:04:00.985768Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Initialize LWBC\nlwbc = LWBC(\n    train_loader=train_loader,\n    val_loader=val_loader,\n    input_dim=1376,\n    hidden_dims=[512, 256, 128],\n    output_dim=14,       \n    committee_size=3,\n    subset_size=0.7,\n    alpha=0.02,\n    lambda_kd=0.6\n)\n\n# Train the model\nhistory = lwbc.train(num_epochs=20, warmup_epochs=5)\n\n# Evaluate on test set\ntest_accuracy, test_auc, _ = lwbc.evaluate(test_loader)\nprint(f\"Test Accuracy: {test_accuracy:.4f}, Test AUC: {test_auc:.4f}\")\n\n# Evaluate across demographic groups\ngender_results = lwbc.evaluate_by_demographic(test_loader, demographic_attr='gender')\nfor gender, metrics in gender_results.items():\n    print(f\"Gender {gender}: Accuracy: {metrics['accuracy']:.4f}, AUC: {metrics['macro_auc']:.4f}, Count: {metrics['count']}\")\n\n# Save model\nlwbc.save_model('lwbc_mimic_model.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T04:04:01.697788Z","iopub.execute_input":"2025-03-21T04:04:01.698114Z"}},"outputs":[{"name":"stdout","text":"Starting committee warm-up training...\nTraining committee member 1/3\n  Epoch 1/5, Loss: 0.2999\n  Epoch 2/5, Loss: 0.2573\n  Epoch 3/5, Loss: 0.2545\n  Epoch 4/5, Loss: 0.2527\n  Epoch 5/5, Loss: 0.2516\nTraining committee member 2/3\n  Epoch 1/5, Loss: 0.3003\n  Epoch 2/5, Loss: 0.2572\n  Epoch 3/5, Loss: 0.2547\n  Epoch 4/5, Loss: 0.2528\n  Epoch 5/5, Loss: 0.2518\nTraining committee member 3/3\n  Epoch 1/5, Loss: 0.3007\n  Epoch 2/5, Loss: 0.2573\n  Epoch 3/5, Loss: 0.2546\n  Epoch 4/5, Loss: 0.2530\n  Epoch 5/5, Loss: 0.2517\nComputing sample weights based on committee consensus...\n","output_type":"stream"},{"name":"stderr","text":"Getting committee predictions: 100%|██████████| 1458/1458 [00:12<00:00, 113.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training main classifier with weighted samples...\n","output_type":"stream"},{"name":"stderr","text":"Training main classifier: 100%|██████████| 1458/1458 [00:16<00:00, 91.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training committee with knowledge distillation...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nimport time\nfrom tqdm import tqdm\nimport os\n\n# Define the neural network model\nclass MIMICClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.2):\n        \"\"\"\n        Simple feed-forward neural network for multi-label classification\n        \n        Args:\n            input_dim: Dimension of input embeddings\n            hidden_dims: List of hidden layer dimensions\n            output_dim: Number of output classes\n            dropout_rate: Dropout probability for regularization\n        \"\"\"\n        super(MIMICClassifier, self).__init__()\n        \n        # Create the layers\n        layers = []\n        \n        # Input layer\n        layers.append(nn.Linear(input_dim, hidden_dims[0]))\n        layers.append(nn.ReLU())\n        layers.append(nn.BatchNorm1d(hidden_dims[0]))\n        layers.append(nn.Dropout(dropout_rate))\n        \n        # Hidden layers\n        for i in range(len(hidden_dims)-1):\n            layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n            layers.append(nn.ReLU())\n            layers.append(nn.BatchNorm1d(hidden_dims[i+1]))\n            layers.append(nn.Dropout(dropout_rate))\n        \n        # Output layer\n        layers.append(nn.Linear(hidden_dims[-1], output_dim))\n        \n        # No activation function here since we're using BCEWithLogitsLoss\n        # which combines sigmoid and binary cross entropy\n        \n        self.model = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LinearVAE(nn.Module):\n    def __init__(self, input_dim=1376, hidden_dim=512, latent_dim=128):\n        super().__init__()\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.latent_dim = latent_dim\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.BatchNorm1d(hidden_dim // 2),\n            nn.ReLU()\n        )\n        \n        # Latent space parameters\n        self.fc_mu = nn.Linear(hidden_dim // 2, latent_dim)\n        self.fc_logvar = nn.Linear(hidden_dim // 2, latent_dim)\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim // 2),\n            nn.BatchNorm1d(hidden_dim // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 2, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, input_dim),\n            nn.Sigmoid()  # Use sigmoid if your embeddings are normalized between 0-1\n                          # or remove if using other normalization\n        )\n        \n    def encode(self, x):\n        hidden = self.encoder(x)\n        mu = self.fc_mu(hidden)\n        logvar = self.fc_logvar(hidden)\n        return mu, logvar\n    \n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        z = mu + eps * std\n        return z\n    \n    def decode(self, z):\n        return self.decoder(z)\n    \n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        reconstructed = self.decode(z)\n        return reconstructed, mu, logvar, z\n    \n    def get_latent(self, x):\n        \"\"\"Get latent representation without reconstruction\"\"\"\n        mu, logvar = self.encode(x)\n        return self.reparameterize(mu, logvar)\n\ndef VAE_LOSS(reconstructed, x, mu, logvar, kld_weight=0.005):\n    \"\"\"\n    VAE loss with KL divergence and reconstruction loss\n    \n    Args:\n        reconstructed: Reconstructed input from decoder\n        x: Original input \n        mu: Mean from encoder\n        logvar: Log variance from encoder\n        kld_weight: Weight for KL divergence term\n    \"\"\"\n    # Reconstruction loss (MSE or BCE depending on your data)\n    recon_loss = F.mse_loss(reconstructed, x, reduction='sum')\n    \n    # KL divergence: -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    \n    # Total loss\n    loss = recon_loss + kld_weight * kld_loss\n    \n    return loss, recon_loss, kld_loss\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:08:39.939282Z","iopub.execute_input":"2025-03-21T02:08:39.939597Z","iopub.status.idle":"2025-03-21T02:08:39.951630Z","shell.execute_reply.started":"2025-03-21T02:08:39.939575Z","shell.execute_reply":"2025-03-21T02:08:39.950931Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Function to create \"target\" labels for adversarial debiasing\ndef create_uniform_targets(batch_size, num_classes, device):\n    \"\"\"\n    Creates uniform probability targets (maximum uncertainty)\n    For binary classification this is 0.5, for multi-class it's 1/num_classes\n    \"\"\"\n    return torch.ones(batch_size, num_classes, device=device) / num_classes\n\n# Training function\ndef train_models(train_loader, val_loader, input_dim, output_dim, num_epochs=20, phase1_epochs=5, \n                 lambda_fair=1.0, lambda_adv=2.0, lambda_recon=0.5):\n    \"\"\"\n    Training pipeline for adversarial debiasing without demographic labels:\n    - Phase 1: Train attacker on original embeddings to learn inherent biases\n    - Phase 2: Adversarial training where generator tries to fool attacker\n    \n    Args:\n        train_loader: DataLoader for training data\n        val_loader: DataLoader for validation data\n        input_dim: Dimension of the embeddings\n        output_dim: Dimension of the task labels\n        num_epochs: Total number of epochs\n        phase1_epochs: Number of epochs for pre-training attacker\n        lambda_fair: Weight for fair model loss\n        lambda_adv: Weight for adversarial loss\n        lambda_recon: Weight for reconstruction loss\n    \"\"\"\n    # Set up device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Initialize models with provided classes\n    hidden_dims = [512, 256, 128]\n    \n    # The attacker model will learn biases in original embeddings\n    attacker_model = MIMICClassifier(input_dim, hidden_dims, output_dim)\n    \n    # The fair model will only be trained on debiased embeddings\n    fair_model = MIMICClassifier(input_dim, hidden_dims, output_dim)\n    \n    # The generator creates debiased embeddings\n    generator = LinearVAE(input_dim=input_dim, hidden_dim=512, latent_dim=128)\n    \n    # Move models to device\n    attacker_model = attacker_model.to(device)\n    fair_model = fair_model.to(device)\n    generator = generator.to(device)\n    \n    # Define optimizers\n    attacker_optimizer = optim.Adam(attacker_model.parameters(), lr=1e-4)\n    fair_optimizer = optim.Adam(fair_model.parameters(), lr=1e-4)\n    generator_optimizer = optim.Adam(generator.parameters(), lr=1e-4)\n    \n    # Loss function for classification\n    bce_loss = nn.BCEWithLogitsLoss()\n    \n    best_val_loss = float('inf')\n    history = {\n        'attacker_loss': [], 'fair_loss': [], 'generator_loss': [],\n        'val_attacker_loss': [], 'val_fair_loss': []\n    }\n    \n    for epoch in range(num_epochs):\n        epoch_start_time = time.time()\n        \n        # Phase 1: Pre-training - ONLY train the attacker to be biased\n        if epoch < phase1_epochs:\n            print(f\"Epoch {epoch+1}/{num_epochs} - Phase 1: Pre-training attacker only\")\n            \n            # Set models to appropriate modes\n            generator.eval()  # Generator not trained in phase 1\n            fair_model.eval()  # Fair model not trained in phase 1\n            attacker_model.train()  # Only attacker is trained\n            \n            epoch_attacker_loss = 0.0\n            att_batches = 0\n            \n            for batch in tqdm(train_loader, desc=\"Training Attacker (on original data)\"):\n                embeddings = batch['embedding'].to(device)\n                labels = batch['labels'].to(device)\n                \n                # Train attacker with original embeddings only to make it biased\n                attacker_optimizer.zero_grad()\n                pred = attacker_model(embeddings)\n                loss = bce_loss(pred, labels)\n                loss.backward()\n                attacker_optimizer.step()\n                \n                epoch_attacker_loss += loss.item()\n                att_batches += 1\n            \n            # Save metrics\n            avg_attacker_loss = epoch_attacker_loss / att_batches\n            history['attacker_loss'].append(avg_attacker_loss)\n            history['fair_loss'].append(0)  # Fair model not trained\n            history['generator_loss'].append(0)  # Generator not trained\n            \n            print(f\"Attacker Loss (original data): {avg_attacker_loss:.4f}\")\n            \n            # Evaluate attacker's bias on validation data\n            attacker_model.eval()\n            val_attacker_loss = 0.0\n            val_batches = 0\n            \n            with torch.no_grad():\n                for batch in val_loader:\n                    embeddings = batch['embedding'].to(device)\n                    labels = batch['labels'].to(device)\n                    \n                    # Check attacker performance (should be getting better/more biased)\n                    attacker_pred = attacker_model(embeddings)\n                    val_loss = bce_loss(attacker_pred, labels).item()\n                    \n                    val_attacker_loss += val_loss\n                    val_batches += 1\n            \n            val_attacker_loss /= val_batches\n            history['val_attacker_loss'].append(val_attacker_loss)\n            history['val_fair_loss'].append(0)  # Fair model not evaluated\n            \n            print(f\"Validation - Attacker Loss: {val_attacker_loss:.4f}\")\n        \n        # Phase 2: Adversarial training\n        else:\n            print(f\"Epoch {epoch+1}/{num_epochs} - Phase 2: Adversarial training\")\n            \n            # PHASE 2.1: Train Attacker (discriminator) - Only on original data\n            attacker_model.train()\n            fair_model.eval()\n            generator.eval()\n            \n            epoch_attacker_loss = 0.0\n            batches = 0\n            \n            for batch in tqdm(train_loader, desc=\"Training Attacker\"):\n                embeddings = batch['embedding'].to(device)\n                labels = batch['labels'].to(device)\n                \n                attacker_optimizer.zero_grad()\n                \n                # Train on real data to maintain bias\n                pred_real = attacker_model(embeddings)\n                attacker_loss = bce_loss(pred_real, labels)\n                attacker_loss.backward()\n                attacker_optimizer.step()\n                \n                epoch_attacker_loss += attacker_loss.item()\n                batches += 1\n            \n            avg_attacker_loss = epoch_attacker_loss / batches\n            history['attacker_loss'].append(avg_attacker_loss)\n            \n            # PHASE 2.2: Train Fair Model - Only on generated data\n            attacker_model.eval()\n            fair_model.train()\n            generator.eval()\n            \n            epoch_fair_loss = 0.0\n            batches = 0\n            \n            for batch in tqdm(train_loader, desc=\"Training Fair Model\"):\n                embeddings = batch['embedding'].to(device)\n                labels = batch['labels'].to(device)\n                \n                fair_optimizer.zero_grad()\n                \n                # Train ONLY on reconstructed embeddings\n                with torch.no_grad():\n                    reconstructed, _, _, _ = generator(embeddings)\n                \n                pred = fair_model(reconstructed)\n                fair_loss = bce_loss(pred, labels)\n                fair_loss.backward()\n                fair_optimizer.step()\n                \n                epoch_fair_loss += fair_loss.item()\n                batches += 1\n            \n            avg_fair_loss = epoch_fair_loss / batches\n            history['fair_loss'].append(avg_fair_loss)\n            \n            # PHASE 2.3: Train Generator (adversarial)\n            attacker_model.eval()\n            fair_model.eval()\n            generator.train()\n            \n            epoch_generator_loss = 0.0\n            batches = 0\n            \n            for batch in tqdm(train_loader, desc=\"Training Generator\"):\n                embeddings = batch['embedding'].to(device)\n                labels = batch['labels'].to(device)\n                batch_size = embeddings.size(0)\n                \n                generator_optimizer.zero_grad()\n                \n                # Get reconstructed embeddings\n                reconstructed, mu, logvar, latent = generator(embeddings)\n                \n                # 1. Reconstruction loss - should reconstruct well enough\n                recon_loss, bce, kld = VAE_LOSS(reconstructed, embeddings, mu, logvar, kld_weight=0.005)\n                weighted_recon_loss = lambda_recon * recon_loss\n                \n                # 2. Adversarial loss - attacker should NOT predict well\n                pred_attacker = attacker_model(reconstructed)\n                \n                # Create \"uncertain\" targets (e.g., 0.5 for binary classification)\n                uncertain_targets = create_uniform_targets(batch_size, output_dim, device)\n                \n                # Generator wants attacker predictions to be uncertain\n                # We use KL divergence between uniform distribution and attacker predictions\n                # Higher KL means predictions are less uniform (more certain)\n                adv_loss = lambda_adv * F.kl_div(\n                    F.log_softmax(pred_attacker, dim=1),\n                    uncertain_targets,\n                    reduction='batchmean'\n                )\n                \n                # 3. Fair model loss - fair model SHOULD predict well\n                pred_fair = fair_model(reconstructed)\n                fair_model_loss = lambda_fair * bce_loss(pred_fair, labels)\n                \n                # Total generator loss\n                # Note: we want to minimize adv_loss (KL divergence), \n                # so we use it directly rather than negating it\n                generator_loss = weighted_recon_loss + adv_loss + fair_model_loss\n                generator_loss.backward()\n                generator_optimizer.step()\n                \n                epoch_generator_loss += generator_loss.item()\n                batches += 1\n                \n                # Debug outputs\n                if batches % 100 == 0:\n                    print(f\"Batch {batches}: Recon Loss: {weighted_recon_loss.item():.4f}, \"\n                          f\"Adv Loss: {adv_loss.item():.4f}, \"\n                          f\"Fair Loss: {fair_model_loss.item():.4f}\")\n            \n            avg_generator_loss = epoch_generator_loss / batches\n            history['generator_loss'].append(avg_generator_loss)\n            \n            print(f\"Epoch Summary - Attacker Loss: {avg_attacker_loss:.4f}, \"\n                  f\"Fair Loss: {avg_fair_loss:.4f}, \"\n                  f\"Generator Loss: {avg_generator_loss:.4f}\")\n        \n            # Validation phase\n            attacker_model.eval()\n            fair_model.eval()\n            generator.eval()\n            val_attacker_loss_orig = 0.0\n            val_attacker_loss_recon = 0.0\n            val_fair_loss = 0.0\n            val_batches = 0\n            \n            with torch.no_grad():\n                for batch in val_loader:\n                    embeddings = batch['embedding'].to(device)\n                    labels = batch['labels'].to(device)\n                    \n                    # Validate attacker on original embeddings (baseline)\n                    attacker_pred_orig = attacker_model(embeddings)\n                    attacker_orig_loss = bce_loss(attacker_pred_orig, labels).item()\n                    \n                    # Generate debiased embeddings\n                    reconstructed, _, _, _ = generator(embeddings)\n                    \n                    # Validate attacker on reconstructed (debiased) embeddings\n                    attacker_pred_recon = attacker_model(reconstructed)\n                    attacker_recon_loss = bce_loss(attacker_pred_recon, labels).item()\n                    \n                    # Validate fair model on generated embeddings\n                    fair_pred = fair_model(reconstructed)\n                    val_fair_loss += bce_loss(fair_pred, labels).item()\n                    \n                    val_attacker_loss_orig += attacker_orig_loss\n                    val_attacker_loss_recon += attacker_recon_loss\n                    val_batches += 1\n            \n            val_attacker_loss_orig /= val_batches\n            val_attacker_loss_recon /= val_batches\n            val_fair_loss /= val_batches\n            \n            history['val_attacker_loss'].append(val_attacker_loss_recon)\n            history['val_fair_loss'].append(val_fair_loss)\n            \n            # Debiasing effectiveness = difference between attacker performance on original vs. debiased\n            debiasing_effect = val_attacker_loss_recon - val_attacker_loss_orig\n            \n            print(f\"Validation - Attacker Loss (orig): {val_attacker_loss_orig:.4f}\")\n            print(f\"Validation - Attacker Loss (recon): {val_attacker_loss_recon:.4f}\")\n            print(f\"Validation - Fair Loss: {val_fair_loss:.4f}\")\n            print(f\"Validation - Debiasing Effect: {debiasing_effect:.4f} (higher is better)\")\n            \n            # Save best model based on validation metrics\n            # We want high debiasing effect and low fair loss\n            fairness_score = debiasing_effect - val_fair_loss\n            \n            if fairness_score > best_val_loss:\n                best_val_loss = fairness_score\n                torch.save({\n                    'generator': generator.state_dict(),\n                    'fair_model': fair_model.state_dict(),\n                    'attacker_model': attacker_model.state_dict(),\n                    'epoch': epoch,\n                    'fairness_score': fairness_score\n                }, 'best_adversarial_models.pt')\n                print(f\"Saved best model with fairness score: {fairness_score:.4f}\")\n                \n        epoch_time = time.time() - epoch_start_time\n        print(f\"Epoch completed in {epoch_time:.2f} seconds\")\n        print(\"-\" * 80)\n    \n    return history, generator, attacker_model, fair_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:55:51.026537Z","iopub.execute_input":"2025-03-21T02:55:51.026853Z","iopub.status.idle":"2025-03-21T02:55:51.047351Z","shell.execute_reply.started":"2025-03-21T02:55:51.026832Z","shell.execute_reply":"2025-03-21T02:55:51.046545Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Updated Training Call\nhistory, generator, attacker_model, fair_model = train_models(\n    train_loader=train_loader,\n    val_loader=val_loader,\n    input_dim=1376,\n    output_dim=14,\n    num_epochs=30,          # ⬆️ More time for Phase 2 to work\n    phase1_epochs=5,        # Same (enough for attacker to become biased)\n    lambda_fair=5.0,        # ⬆️ Help fair model learn more strongly\n    lambda_adv=5.0,        # ⬆️ Stronger pressure on generator to fool attacker\n    lambda_recon=0.2        # ⬇️ Less emphasis on perfect reconstruction\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T03:38:49.538092Z","iopub.execute_input":"2025-03-21T03:38:49.538504Z","iopub.status.idle":"2025-03-21T03:47:48.678841Z","shell.execute_reply.started":"2025-03-21T03:38:49.538430Z","shell.execute_reply":"2025-03-21T03:47:48.677631Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30 - Phase 1: Pre-training attacker only\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker (on original data): 100%|██████████| 1458/1458 [00:07<00:00, 183.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Attacker Loss (original data): 0.4917\nValidation - Attacker Loss: 0.2913\nEpoch completed in 8.40 seconds\n--------------------------------------------------------------------------------\nEpoch 2/30 - Phase 1: Pre-training attacker only\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker (on original data): 100%|██████████| 1458/1458 [00:07<00:00, 185.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Attacker Loss (original data): 0.2738\nValidation - Attacker Loss: 0.2546\nEpoch completed in 8.29 seconds\n--------------------------------------------------------------------------------\nEpoch 3/30 - Phase 1: Pre-training attacker only\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker (on original data): 100%|██████████| 1458/1458 [00:08<00:00, 180.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Attacker Loss (original data): 0.2605\nValidation - Attacker Loss: 0.2539\nEpoch completed in 8.51 seconds\n--------------------------------------------------------------------------------\nEpoch 4/30 - Phase 1: Pre-training attacker only\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker (on original data): 100%|██████████| 1458/1458 [00:08<00:00, 180.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Attacker Loss (original data): 0.2578\nValidation - Attacker Loss: 0.2528\nEpoch completed in 8.52 seconds\n--------------------------------------------------------------------------------\nEpoch 5/30 - Phase 1: Pre-training attacker only\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker (on original data): 100%|██████████| 1458/1458 [00:08<00:00, 167.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Attacker Loss (original data): 0.2562\nValidation - Attacker Loss: 0.2514\nEpoch completed in 9.15 seconds\n--------------------------------------------------------------------------------\nEpoch 6/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:07<00:00, 188.93it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:09<00:00, 158.45it/s]\nTraining Generator:   8%|▊         | 115/1458 [00:01<00:14, 91.12it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 73337.8281, Adv Loss: 14.0440, Fair Loss: 4.4847\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▍        | 215/1458 [00:02<00:13, 91.50it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 70462.2734, Adv Loss: 9.4831, Fair Loss: 3.7010\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 315/1458 [00:03<00:12, 92.80it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 69795.2344, Adv Loss: 9.1542, Fair Loss: 3.8428\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  28%|██▊       | 415/1458 [00:04<00:10, 94.96it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 68358.5859, Adv Loss: 8.7667, Fair Loss: 4.1666\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▌      | 515/1458 [00:05<00:09, 95.49it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 69894.4531, Adv Loss: 9.4139, Fair Loss: 4.1904\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 615/1458 [00:06<00:08, 93.96it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 66504.1484, Adv Loss: 9.9384, Fair Loss: 3.7764\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 715/1458 [00:07<00:07, 93.28it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 67403.1484, Adv Loss: 10.3599, Fair Loss: 3.4607\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▌    | 815/1458 [00:08<00:06, 94.33it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 67116.4688, Adv Loss: 10.2478, Fair Loss: 4.5995\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 915/1458 [00:09<00:05, 94.89it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 66047.5547, Adv Loss: 10.1918, Fair Loss: 4.0953\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1014/1458 [00:10<00:04, 91.43it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 67062.2656, Adv Loss: 10.6366, Fair Loss: 4.8465\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  76%|███████▋  | 1114/1458 [00:12<00:03, 93.47it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 65512.7266, Adv Loss: 10.5845, Fair Loss: 4.0545\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  83%|████████▎ | 1214/1458 [00:13<00:02, 93.47it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 66833.9453, Adv Loss: 10.4241, Fair Loss: 5.2684\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1314/1458 [00:14<00:01, 94.37it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 65175.9805, Adv Loss: 10.7169, Fair Loss: 4.5109\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1414/1458 [00:15<00:00, 93.65it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 68550.0703, Adv Loss: 10.6805, Fair Loss: 4.2437\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:15<00:00, 92.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2546, Fair Loss: 0.5604, Generator Loss: 68918.8549\nValidation - Attacker Loss (orig): 0.2508\nValidation - Attacker Loss (recon): 0.4873\nValidation - Fair Loss: 0.9191\nValidation - Debiasing Effect: 0.2365 (higher is better)\nEpoch completed in 33.40 seconds\n--------------------------------------------------------------------------------\nEpoch 7/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:07<00:00, 191.44it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:09<00:00, 159.63it/s]\nTraining Generator:   7%|▋         | 109/1458 [00:01<00:14, 92.37it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 65954.4141, Adv Loss: 10.1342, Fair Loss: 1.4048\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  14%|█▍        | 209/1458 [00:02<00:13, 92.23it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 68449.3984, Adv Loss: 10.2169, Fair Loss: 1.3565\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  21%|██        | 309/1458 [00:03<00:12, 92.08it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 64915.6445, Adv Loss: 10.1943, Fair Loss: 1.2914\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  28%|██▊       | 409/1458 [00:04<00:11, 92.19it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 64383.1680, Adv Loss: 10.4197, Fair Loss: 1.3862\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▍      | 509/1458 [00:05<00:10, 93.33it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 67481.0391, Adv Loss: 10.7831, Fair Loss: 1.4104\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 609/1458 [00:06<00:09, 91.31it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 69996.4922, Adv Loss: 10.8170, Fair Loss: 1.3213\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 718/1458 [00:07<00:07, 92.62it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 64495.6523, Adv Loss: 10.7023, Fair Loss: 1.2866\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▌    | 818/1458 [00:08<00:06, 93.29it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 69433.0391, Adv Loss: 10.9384, Fair Loss: 1.2621\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 918/1458 [00:09<00:05, 92.49it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 65767.2031, Adv Loss: 10.7655, Fair Loss: 1.4167\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1018/1458 [00:11<00:04, 92.27it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 66720.6562, Adv Loss: 10.8150, Fair Loss: 1.2192\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  77%|███████▋  | 1118/1458 [00:12<00:03, 91.18it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 64861.4336, Adv Loss: 10.8323, Fair Loss: 1.2914\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  84%|████████▎ | 1218/1458 [00:13<00:02, 92.56it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 66746.8359, Adv Loss: 11.2551, Fair Loss: 1.4162\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1318/1458 [00:14<00:01, 93.27it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 67601.0625, Adv Loss: 11.1067, Fair Loss: 1.3250\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1418/1458 [00:15<00:00, 92.00it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 65751.6250, Adv Loss: 11.2311, Fair Loss: 1.3135\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:15<00:00, 92.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2534, Fair Loss: 0.2909, Generator Loss: 66259.5821\nValidation - Attacker Loss (orig): 0.2501\nValidation - Attacker Loss (recon): 0.4570\nValidation - Fair Loss: 0.2675\nValidation - Debiasing Effect: 0.2069 (higher is better)\nEpoch completed in 33.33 seconds\n--------------------------------------------------------------------------------\nEpoch 8/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:07<00:00, 192.72it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:09<00:00, 157.88it/s]\nTraining Generator:   8%|▊         | 118/1458 [00:01<00:14, 93.08it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 62425.7461, Adv Loss: 13.4719, Fair Loss: 1.3601\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▍        | 218/1458 [00:02<00:13, 93.47it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 63377.0000, Adv Loss: 13.3900, Fair Loss: 1.3100\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 318/1458 [00:03<00:12, 92.41it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 64224.5898, Adv Loss: 13.4708, Fair Loss: 1.2717\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  29%|██▊       | 417/1458 [00:04<00:11, 90.99it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 65697.0703, Adv Loss: 13.2880, Fair Loss: 1.2930\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▌      | 517/1458 [00:05<00:10, 92.02it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 64654.4570, Adv Loss: 13.2979, Fair Loss: 1.2995\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 617/1458 [00:06<00:09, 91.98it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 67977.8047, Adv Loss: 13.5902, Fair Loss: 1.3266\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 717/1458 [00:07<00:08, 91.29it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 69125.2969, Adv Loss: 12.7847, Fair Loss: 1.3370\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▌    | 817/1458 [00:08<00:06, 92.79it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 66145.3984, Adv Loss: 13.4832, Fair Loss: 1.3052\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 917/1458 [00:09<00:05, 92.72it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 66797.6250, Adv Loss: 13.6762, Fair Loss: 1.3106\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1017/1458 [00:11<00:04, 92.12it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 65295.0312, Adv Loss: 13.4917, Fair Loss: 1.1848\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  77%|███████▋  | 1116/1458 [00:12<00:03, 89.17it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 66770.7109, Adv Loss: 13.4016, Fair Loss: 1.2606\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  83%|████████▎ | 1216/1458 [00:13<00:02, 92.22it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 64618.4062, Adv Loss: 13.2958, Fair Loss: 1.3320\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1315/1458 [00:14<00:01, 91.22it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 68954.7344, Adv Loss: 12.9414, Fair Loss: 1.3817\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1415/1458 [00:15<00:00, 93.64it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 67321.7656, Adv Loss: 13.7416, Fair Loss: 1.2816\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:15<00:00, 91.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2526, Fair Loss: 0.2679, Generator Loss: 65923.6439\nValidation - Attacker Loss (orig): 0.2494\nValidation - Attacker Loss (recon): 0.4822\nValidation - Fair Loss: 0.2591\nValidation - Debiasing Effect: 0.2328 (higher is better)\nEpoch completed in 33.45 seconds\n--------------------------------------------------------------------------------\nEpoch 9/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:07<00:00, 190.84it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:08<00:00, 162.66it/s]\nTraining Generator:   8%|▊         | 117/1458 [00:01<00:14, 93.59it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 65217.0508, Adv Loss: 18.2726, Fair Loss: 1.2989\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▍        | 217/1458 [00:02<00:13, 92.25it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 65567.7812, Adv Loss: 18.4617, Fair Loss: 1.1482\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 317/1458 [00:03<00:12, 92.87it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 62964.2383, Adv Loss: 17.7824, Fair Loss: 1.3719\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  29%|██▊       | 417/1458 [00:04<00:11, 92.15it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 66232.8984, Adv Loss: 18.0172, Fair Loss: 1.2823\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▌      | 517/1458 [00:05<00:10, 91.01it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 65595.8281, Adv Loss: 17.7747, Fair Loss: 1.2472\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 617/1458 [00:06<00:09, 91.72it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 63430.2891, Adv Loss: 17.6950, Fair Loss: 1.2993\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 717/1458 [00:07<00:08, 91.91it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 62495.3516, Adv Loss: 18.1965, Fair Loss: 1.3789\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▌    | 817/1458 [00:08<00:07, 91.37it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 67889.1406, Adv Loss: 17.9163, Fair Loss: 1.2435\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 917/1458 [00:10<00:05, 91.69it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 63628.1758, Adv Loss: 18.0352, Fair Loss: 1.2697\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1015/1458 [00:11<00:04, 89.52it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 62274.4805, Adv Loss: 17.8474, Fair Loss: 1.2789\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  76%|███████▋  | 1115/1458 [00:12<00:03, 91.86it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 63861.0078, Adv Loss: 18.0368, Fair Loss: 1.2313\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  83%|████████▎ | 1215/1458 [00:13<00:02, 93.48it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 65081.3398, Adv Loss: 18.1239, Fair Loss: 1.3163\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1315/1458 [00:14<00:01, 93.04it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 67922.6797, Adv Loss: 17.4993, Fair Loss: 1.2194\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1415/1458 [00:15<00:00, 92.62it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 65763.0234, Adv Loss: 17.7400, Fair Loss: 1.2111\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:15<00:00, 91.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2520, Fair Loss: 0.2634, Generator Loss: 65791.9047\nValidation - Attacker Loss (orig): 0.2493\nValidation - Attacker Loss (recon): 0.5725\nValidation - Fair Loss: 0.2572\nValidation - Debiasing Effect: 0.3231 (higher is better)\nEpoch completed in 33.32 seconds\n--------------------------------------------------------------------------------\nEpoch 10/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:07<00:00, 187.44it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:09<00:00, 160.75it/s]\nTraining Generator:   7%|▋         | 109/1458 [00:01<00:14, 93.29it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 65565.1172, Adv Loss: 15.9999, Fair Loss: 1.2532\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▌        | 219/1458 [00:02<00:13, 94.64it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 62496.9062, Adv Loss: 16.4214, Fair Loss: 1.2686\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  21%|██        | 309/1458 [00:03<00:12, 93.89it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 67202.7188, Adv Loss: 16.1303, Fair Loss: 1.3953\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  28%|██▊       | 409/1458 [00:04<00:11, 92.74it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 64985.7305, Adv Loss: 15.9231, Fair Loss: 1.3096\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▍      | 509/1458 [00:05<00:10, 92.20it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 66611.2812, Adv Loss: 16.0869, Fair Loss: 1.0524\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 609/1458 [00:06<00:09, 91.84it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 64716.4570, Adv Loss: 15.7562, Fair Loss: 1.2096\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▊     | 709/1458 [00:07<00:08, 91.10it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 66041.5938, Adv Loss: 14.9416, Fair Loss: 1.3685\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  55%|█████▌    | 809/1458 [00:08<00:07, 91.68it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 63383.7461, Adv Loss: 16.0273, Fair Loss: 1.2256\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 919/1458 [00:09<00:05, 94.05it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 65866.9531, Adv Loss: 16.1681, Fair Loss: 1.2075\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  69%|██████▉   | 1009/1458 [00:10<00:04, 93.13it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 64334.0938, Adv Loss: 15.9939, Fair Loss: 1.3700\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  76%|███████▌  | 1109/1458 [00:12<00:03, 90.44it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 64555.2695, Adv Loss: 17.0725, Fair Loss: 1.1627\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  83%|████████▎ | 1209/1458 [00:13<00:02, 91.36it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 63384.0625, Adv Loss: 16.0998, Fair Loss: 1.1922\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1319/1458 [00:14<00:01, 93.94it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 65837.8047, Adv Loss: 14.6357, Fair Loss: 1.2556\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1409/1458 [00:15<00:00, 93.06it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 65627.2578, Adv Loss: 16.3618, Fair Loss: 1.2766\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:15<00:00, 92.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2513, Fair Loss: 0.2612, Generator Loss: 65714.1139\nValidation - Attacker Loss (orig): 0.2496\nValidation - Attacker Loss (recon): 0.5679\nValidation - Fair Loss: 0.2560\nValidation - Debiasing Effect: 0.3182 (higher is better)\nEpoch completed in 33.44 seconds\n--------------------------------------------------------------------------------\nEpoch 11/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:07<00:00, 191.19it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:08<00:00, 162.79it/s]\nTraining Generator:   7%|▋         | 109/1458 [00:01<00:14, 93.16it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 66090.5781, Adv Loss: 16.4364, Fair Loss: 1.2953\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  14%|█▍        | 209/1458 [00:02<00:13, 93.36it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 67186.8047, Adv Loss: 15.9311, Fair Loss: 1.2272\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  21%|██        | 309/1458 [00:03<00:12, 91.34it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 68384.2734, Adv Loss: 16.0917, Fair Loss: 1.2669\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  28%|██▊       | 409/1458 [00:04<00:11, 91.26it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 63328.9023, Adv Loss: 15.8820, Fair Loss: 1.2330\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  36%|███▌      | 519/1458 [00:05<00:09, 93.92it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 65872.7266, Adv Loss: 15.8989, Fair Loss: 1.1585\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 619/1458 [00:06<00:08, 93.76it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 62902.9492, Adv Loss: 16.0047, Fair Loss: 1.3261\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▊     | 709/1458 [00:07<00:07, 93.86it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 65585.1328, Adv Loss: 16.7924, Fair Loss: 1.4406\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  55%|█████▌    | 809/1458 [00:08<00:06, 92.88it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 62348.7773, Adv Loss: 15.9303, Fair Loss: 1.1456\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  62%|██████▏   | 909/1458 [00:09<00:05, 91.72it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 62017.3320, Adv Loss: 16.3441, Fair Loss: 1.2288\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  69%|██████▉   | 1009/1458 [00:10<00:04, 93.12it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 65502.6211, Adv Loss: 16.2348, Fair Loss: 1.3224\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  76%|███████▌  | 1109/1458 [00:11<00:03, 93.05it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 64515.6758, Adv Loss: 16.3821, Fair Loss: 1.4104\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  84%|████████▎ | 1219/1458 [00:13<00:02, 93.21it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 63204.5117, Adv Loss: 15.7456, Fair Loss: 1.2104\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1318/1458 [00:14<00:01, 88.88it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 63718.2266, Adv Loss: 16.1565, Fair Loss: 1.2082\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1413/1458 [00:15<00:00, 89.85it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 65344.7773, Adv Loss: 16.3207, Fair Loss: 1.3455\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:15<00:00, 91.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2505, Fair Loss: 0.2597, Generator Loss: 65663.8118\nValidation - Attacker Loss (orig): 0.2485\nValidation - Attacker Loss (recon): 0.5494\nValidation - Fair Loss: 0.2561\nValidation - Debiasing Effect: 0.3008 (higher is better)\nEpoch completed in 33.26 seconds\n--------------------------------------------------------------------------------\nEpoch 12/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:08<00:00, 180.23it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:09<00:00, 160.46it/s]\nTraining Generator:   7%|▋         | 109/1458 [00:01<00:14, 93.52it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 66105.3594, Adv Loss: 16.3066, Fair Loss: 1.1983\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▌        | 219/1458 [00:02<00:13, 94.88it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 64311.6641, Adv Loss: 16.3147, Fair Loss: 1.2892\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 319/1458 [00:03<00:12, 93.71it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 65781.9141, Adv Loss: 17.1278, Fair Loss: 1.3543\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  28%|██▊       | 409/1458 [00:04<00:12, 87.22it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 64434.7773, Adv Loss: 16.3843, Fair Loss: 1.2724\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▍      | 509/1458 [00:05<00:10, 91.09it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 63967.9258, Adv Loss: 16.7239, Fair Loss: 1.3777\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 609/1458 [00:06<00:09, 91.97it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 66696.8359, Adv Loss: 16.9817, Fair Loss: 1.3722\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▊     | 709/1458 [00:07<00:08, 91.25it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 66921.4297, Adv Loss: 16.4874, Fair Loss: 1.2885\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  55%|█████▌    | 809/1458 [00:08<00:07, 91.55it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 66273.3203, Adv Loss: 15.3262, Fair Loss: 1.2333\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  62%|██████▏   | 909/1458 [00:09<00:05, 92.05it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 66053.5000, Adv Loss: 16.9420, Fair Loss: 1.1613\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1018/1458 [00:11<00:04, 91.01it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 69271.1484, Adv Loss: 16.1389, Fair Loss: 1.2200\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  77%|███████▋  | 1118/1458 [00:12<00:03, 91.99it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 66106.2422, Adv Loss: 15.1955, Fair Loss: 1.3081\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  84%|████████▎ | 1218/1458 [00:13<00:02, 92.89it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 66662.7344, Adv Loss: 16.0926, Fair Loss: 1.4381\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1318/1458 [00:14<00:01, 93.12it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 65903.1719, Adv Loss: 16.1563, Fair Loss: 1.2395\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1418/1458 [00:15<00:00, 92.62it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 67058.3203, Adv Loss: 16.5429, Fair Loss: 1.1851\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:15<00:00, 92.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2500, Fair Loss: 0.2584, Generator Loss: 65628.8958\nValidation - Attacker Loss (orig): 0.2486\nValidation - Attacker Loss (recon): 0.5398\nValidation - Fair Loss: 0.2548\nValidation - Debiasing Effect: 0.2912 (higher is better)\nEpoch completed in 33.75 seconds\n--------------------------------------------------------------------------------\nEpoch 13/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:07<00:00, 187.67it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:08<00:00, 162.35it/s]\nTraining Generator:   8%|▊         | 119/1458 [00:01<00:14, 95.17it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 65064.4336, Adv Loss: 15.1165, Fair Loss: 1.3130\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▌        | 219/1458 [00:02<00:13, 94.78it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 67936.8047, Adv Loss: 15.3153, Fair Loss: 1.2340\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 319/1458 [00:03<00:12, 94.89it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 65317.4766, Adv Loss: 15.0293, Fair Loss: 1.2903\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  29%|██▊       | 419/1458 [00:04<00:10, 95.64it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 64564.5703, Adv Loss: 16.3672, Fair Loss: 1.2361\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  36%|███▌      | 519/1458 [00:05<00:09, 95.99it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 68569.8047, Adv Loss: 15.7300, Fair Loss: 1.4137\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 609/1458 [00:06<00:09, 90.29it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 65286.1445, Adv Loss: 16.4004, Fair Loss: 1.0948\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 719/1458 [00:07<00:07, 94.62it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 64528.9023, Adv Loss: 16.3316, Fair Loss: 1.2162\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▌    | 819/1458 [00:08<00:06, 95.01it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 65295.3867, Adv Loss: 15.0338, Fair Loss: 1.2189\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  62%|██████▏   | 909/1458 [00:09<00:05, 93.79it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 63261.7891, Adv Loss: 15.6373, Fair Loss: 1.2763\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1019/1458 [00:10<00:04, 96.61it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 62759.0625, Adv Loss: 16.6053, Fair Loss: 1.3040\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  77%|███████▋  | 1119/1458 [00:11<00:03, 96.60it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 65996.4609, Adv Loss: 16.6486, Fair Loss: 1.2018\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  84%|████████▎ | 1219/1458 [00:12<00:02, 96.35it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 63811.6836, Adv Loss: 15.8544, Fair Loss: 1.3796\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1319/1458 [00:13<00:01, 95.04it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 67077.5000, Adv Loss: 15.8944, Fair Loss: 1.2929\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1419/1458 [00:14<00:00, 95.01it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 65725.2812, Adv Loss: 16.1486, Fair Loss: 1.1881\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:15<00:00, 94.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2494, Fair Loss: 0.2575, Generator Loss: 65599.0076\nValidation - Attacker Loss (orig): 0.2493\nValidation - Attacker Loss (recon): 0.5418\nValidation - Fair Loss: 0.2544\nValidation - Debiasing Effect: 0.2925 (higher is better)\nEpoch completed in 32.93 seconds\n--------------------------------------------------------------------------------\nEpoch 14/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:07<00:00, 193.00it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:09<00:00, 161.03it/s]\nTraining Generator:   7%|▋         | 109/1458 [00:01<00:14, 93.28it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 66772.9062, Adv Loss: 18.1086, Fair Loss: 1.2181\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  14%|█▍        | 209/1458 [00:02<00:13, 91.78it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 61985.4805, Adv Loss: 17.2846, Fair Loss: 1.3216\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 319/1458 [00:03<00:12, 92.80it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 67227.4531, Adv Loss: 17.7201, Fair Loss: 1.2801\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  29%|██▊       | 418/1458 [00:04<00:11, 92.42it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 63188.5625, Adv Loss: 17.7044, Fair Loss: 1.2844\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  36%|███▌      | 518/1458 [00:05<00:10, 92.05it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 66621.5156, Adv Loss: 18.2846, Fair Loss: 1.1601\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 618/1458 [00:06<00:09, 93.05it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 66976.6406, Adv Loss: 17.8235, Fair Loss: 1.2667\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 718/1458 [00:07<00:07, 92.52it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 65726.8672, Adv Loss: 18.6174, Fair Loss: 1.1354\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▌    | 818/1458 [00:08<00:06, 92.79it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 62511.8867, Adv Loss: 18.1183, Fair Loss: 1.2832\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 918/1458 [00:09<00:05, 93.22it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 65018.0430, Adv Loss: 17.7450, Fair Loss: 1.3873\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1018/1458 [00:11<00:04, 92.59it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 65627.5469, Adv Loss: 17.5426, Fair Loss: 1.3611\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  77%|███████▋  | 1118/1458 [00:12<00:03, 93.52it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 63103.5195, Adv Loss: 17.8242, Fair Loss: 1.1402\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  84%|████████▎ | 1218/1458 [00:13<00:02, 93.53it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 67780.5234, Adv Loss: 16.2769, Fair Loss: 1.2596\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1318/1458 [00:14<00:01, 91.59it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 67717.2109, Adv Loss: 18.5727, Fair Loss: 1.2741\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1413/1458 [00:15<00:00, 84.52it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 63505.4453, Adv Loss: 18.1275, Fair Loss: 1.2254\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:15<00:00, 91.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2489, Fair Loss: 0.2567, Generator Loss: 65578.1422\nValidation - Attacker Loss (orig): 0.2481\nValidation - Attacker Loss (recon): 0.5276\nValidation - Fair Loss: 0.2538\nValidation - Debiasing Effect: 0.2795 (higher is better)\nEpoch completed in 33.34 seconds\n--------------------------------------------------------------------------------\nEpoch 15/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:07<00:00, 193.87it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:08<00:00, 169.40it/s]\nTraining Generator:   8%|▊         | 115/1458 [00:01<00:15, 87.27it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 67660.1406, Adv Loss: 18.2774, Fair Loss: 1.2973\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  14%|█▍        | 211/1458 [00:02<00:13, 90.48it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 64317.7617, Adv Loss: 18.5821, Fair Loss: 1.2407\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  21%|██▏       | 311/1458 [00:03<00:12, 90.13it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 67752.2344, Adv Loss: 18.6306, Fair Loss: 1.2541\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  29%|██▊       | 417/1458 [00:04<00:11, 91.37it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 66453.0391, Adv Loss: 18.8147, Fair Loss: 1.2423\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▌      | 517/1458 [00:05<00:10, 91.51it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 66382.5234, Adv Loss: 17.3697, Fair Loss: 1.2678\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 617/1458 [00:06<00:09, 90.67it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 66162.7422, Adv Loss: 18.4331, Fair Loss: 1.2278\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 717/1458 [00:07<00:08, 90.76it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 61003.4023, Adv Loss: 18.6045, Fair Loss: 1.1322\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▌    | 817/1458 [00:09<00:07, 90.80it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 68553.9375, Adv Loss: 18.0039, Fair Loss: 1.2360\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  62%|██████▏   | 909/1458 [00:10<00:06, 87.38it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 64554.8516, Adv Loss: 17.2930, Fair Loss: 1.2769\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  69%|██████▉   | 1013/1458 [00:11<00:04, 102.77it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 64281.9492, Adv Loss: 18.1439, Fair Loss: 1.1675\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  77%|███████▋  | 1121/1458 [00:12<00:02, 117.88it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 63378.4961, Adv Loss: 17.8597, Fair Loss: 1.2392\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  83%|████████▎ | 1217/1458 [00:12<00:02, 117.69it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 65536.5625, Adv Loss: 19.3103, Fair Loss: 1.2671\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1314/1458 [00:13<00:01, 105.17it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 62105.2891, Adv Loss: 17.5603, Fair Loss: 1.4170\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1413/1458 [00:14<00:00, 99.09it/s] ","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 67250.0312, Adv Loss: 18.8470, Fair Loss: 1.2437\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:15<00:00, 95.67it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2484, Fair Loss: 0.2562, Generator Loss: 65557.5817\nValidation - Attacker Loss (orig): 0.2478\nValidation - Attacker Loss (recon): 0.5316\nValidation - Fair Loss: 0.2538\nValidation - Debiasing Effect: 0.2838 (higher is better)\nEpoch completed in 32.04 seconds\n--------------------------------------------------------------------------------\nEpoch 16/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:06<00:00, 233.38it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:07<00:00, 183.69it/s]\nTraining Generator:   8%|▊         | 119/1458 [00:01<00:11, 115.85it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 65046.7305, Adv Loss: 18.4070, Fair Loss: 1.1542\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▍        | 217/1458 [00:01<00:10, 118.95it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 68316.8516, Adv Loss: 18.5711, Fair Loss: 1.1733\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 320/1458 [00:02<00:09, 119.42it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 64410.9492, Adv Loss: 18.8841, Fair Loss: 1.2345\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  29%|██▉       | 422/1458 [00:03<00:08, 120.60it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 64452.7188, Adv Loss: 19.6574, Fair Loss: 1.2606\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▌      | 513/1458 [00:04<00:07, 121.14it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 65349.6758, Adv Loss: 18.8675, Fair Loss: 1.1437\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 615/1458 [00:05<00:07, 120.27it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 68703.0391, Adv Loss: 18.2583, Fair Loss: 1.2190\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 714/1458 [00:06<00:06, 118.41it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 62985.0938, Adv Loss: 19.0355, Fair Loss: 1.1584\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▋    | 823/1458 [00:06<00:05, 118.22it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 63179.6328, Adv Loss: 19.6365, Fair Loss: 1.2524\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 919/1458 [00:07<00:04, 117.83it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 66535.4766, Adv Loss: 19.2167, Fair Loss: 1.2794\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1015/1458 [00:08<00:03, 116.73it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 67956.1328, Adv Loss: 18.4172, Fair Loss: 1.3287\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  77%|███████▋  | 1123/1458 [00:09<00:02, 116.86it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 66422.5469, Adv Loss: 18.3080, Fair Loss: 1.1471\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  84%|████████▎ | 1219/1458 [00:10<00:02, 118.51it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 66529.4531, Adv Loss: 18.7045, Fair Loss: 1.2409\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1315/1458 [00:11<00:01, 113.46it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 68683.8438, Adv Loss: 19.0404, Fair Loss: 1.3254\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  98%|█████████▊| 1423/1458 [00:12<00:00, 118.32it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 66715.5859, Adv Loss: 19.3590, Fair Loss: 1.1939\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:12<00:00, 117.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2482, Fair Loss: 0.2554, Generator Loss: 65541.7538\nValidation - Attacker Loss (orig): 0.2482\nValidation - Attacker Loss (recon): 0.5416\nValidation - Fair Loss: 0.2536\nValidation - Debiasing Effect: 0.2934 (higher is better)\nEpoch completed in 27.21 seconds\n--------------------------------------------------------------------------------\nEpoch 17/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:06<00:00, 230.15it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:07<00:00, 198.62it/s]\nTraining Generator:   8%|▊         | 120/1458 [00:01<00:11, 118.63it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 64623.5586, Adv Loss: 19.3641, Fair Loss: 1.1591\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▌        | 219/1458 [00:01<00:10, 120.70it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 68926.8047, Adv Loss: 18.7996, Fair Loss: 1.2607\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 323/1458 [00:02<00:09, 120.42it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 68553.1172, Adv Loss: 20.0304, Fair Loss: 1.1995\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  28%|██▊       | 412/1458 [00:03<00:08, 119.32it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 65498.7695, Adv Loss: 19.0436, Fair Loss: 1.3724\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▌      | 512/1458 [00:04<00:08, 113.40it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 64375.3203, Adv Loss: 18.8302, Fair Loss: 1.2267\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 615/1458 [00:05<00:06, 121.12it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 64099.8711, Adv Loss: 19.5898, Fair Loss: 1.2558\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 718/1458 [00:06<00:06, 119.97it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 65206.7070, Adv Loss: 18.6241, Fair Loss: 1.4564\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▋    | 822/1458 [00:06<00:05, 120.45it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 64127.3203, Adv Loss: 18.6975, Fair Loss: 1.2851\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 913/1458 [00:07<00:04, 121.23it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 64846.8711, Adv Loss: 18.9649, Fair Loss: 1.2448\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1014/1458 [00:08<00:04, 102.80it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 66614.1328, Adv Loss: 18.7187, Fair Loss: 1.1993\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  76%|███████▋  | 1115/1458 [00:09<00:03, 89.07it/s] ","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 66010.1484, Adv Loss: 19.3052, Fair Loss: 1.2278\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  83%|████████▎ | 1211/1458 [00:10<00:02, 94.32it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 63242.8945, Adv Loss: 18.5947, Fair Loss: 1.2964\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|████████▉ | 1312/1458 [00:11<00:01, 112.28it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 64875.4453, Adv Loss: 19.5515, Fair Loss: 1.2934\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1411/1458 [00:12<00:00, 116.69it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 65399.2461, Adv Loss: 19.1334, Fair Loss: 1.2186\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:12<00:00, 112.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2479, Fair Loss: 0.2549, Generator Loss: 65527.2582\nValidation - Attacker Loss (orig): 0.2479\nValidation - Attacker Loss (recon): 0.5438\nValidation - Fair Loss: 0.2541\nValidation - Debiasing Effect: 0.2959 (higher is better)\nEpoch completed in 27.27 seconds\n--------------------------------------------------------------------------------\nEpoch 18/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:06<00:00, 233.05it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:07<00:00, 189.06it/s]\nTraining Generator:   8%|▊         | 113/1458 [00:01<00:12, 105.58it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 68412.1172, Adv Loss: 18.6440, Fair Loss: 1.1376\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▍        | 215/1458 [00:02<00:10, 120.08it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 67861.2734, Adv Loss: 19.0163, Fair Loss: 1.2665\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 315/1458 [00:02<00:09, 118.32it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 62917.6133, Adv Loss: 18.1383, Fair Loss: 1.2748\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  29%|██▉       | 424/1458 [00:03<00:08, 119.45it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 65209.8086, Adv Loss: 19.9982, Fair Loss: 1.1910\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▌      | 514/1458 [00:04<00:07, 120.03it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 67076.7578, Adv Loss: 18.1915, Fair Loss: 1.2161\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 616/1458 [00:05<00:07, 116.83it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 66314.1406, Adv Loss: 18.7827, Fair Loss: 1.2562\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 719/1458 [00:06<00:06, 120.10it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 66254.9297, Adv Loss: 19.0270, Fair Loss: 1.2287\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▌    | 818/1458 [00:07<00:05, 118.26it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 66304.1797, Adv Loss: 18.5170, Fair Loss: 1.4707\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 920/1458 [00:07<00:04, 120.03it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 67210.0234, Adv Loss: 18.4021, Fair Loss: 1.3179\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1017/1458 [00:08<00:03, 117.97it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 64285.9961, Adv Loss: 19.3986, Fair Loss: 1.1909\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  76%|███████▋  | 1113/1458 [00:09<00:02, 119.03it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 66718.7812, Adv Loss: 18.2339, Fair Loss: 1.2769\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  83%|████████▎ | 1214/1458 [00:10<00:02, 120.66it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 66026.5547, Adv Loss: 19.4802, Fair Loss: 1.2918\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1316/1458 [00:11<00:01, 119.29it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 66540.9062, Adv Loss: 18.6221, Fair Loss: 1.3180\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1419/1458 [00:12<00:00, 121.44it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 66925.7422, Adv Loss: 18.8935, Fair Loss: 1.2633\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:12<00:00, 117.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2475, Fair Loss: 0.2544, Generator Loss: 65514.1437\nValidation - Attacker Loss (orig): 0.2476\nValidation - Attacker Loss (recon): 0.5364\nValidation - Fair Loss: 0.2533\nValidation - Debiasing Effect: 0.2888 (higher is better)\nEpoch completed in 27.07 seconds\n--------------------------------------------------------------------------------\nEpoch 19/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:06<00:00, 218.74it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:07<00:00, 198.14it/s]\nTraining Generator:   8%|▊         | 121/1458 [00:01<00:11, 119.09it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 67945.2969, Adv Loss: 19.1324, Fair Loss: 1.2770\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▌        | 223/1458 [00:01<00:10, 120.21it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 64673.9062, Adv Loss: 18.7595, Fair Loss: 1.2623\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 321/1458 [00:02<00:09, 118.39it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 63610.2930, Adv Loss: 17.9384, Fair Loss: 1.2088\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  29%|██▉       | 424/1458 [00:03<00:08, 120.70it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 66609.4375, Adv Loss: 17.3382, Fair Loss: 1.2057\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▌      | 514/1458 [00:04<00:07, 119.91it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 65964.8516, Adv Loss: 18.5282, Fair Loss: 1.2137\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 616/1458 [00:05<00:07, 119.88it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 65938.2109, Adv Loss: 18.1874, Fair Loss: 1.2539\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 719/1458 [00:06<00:06, 121.73it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 66548.3203, Adv Loss: 19.5034, Fair Loss: 1.2303\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▋    | 823/1458 [00:06<00:05, 121.83it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 65792.7734, Adv Loss: 18.2196, Fair Loss: 1.1844\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 914/1458 [00:07<00:04, 118.42it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 65873.6094, Adv Loss: 18.7520, Fair Loss: 1.2164\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  69%|██████▉   | 1010/1458 [00:08<00:04, 91.20it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 67751.6562, Adv Loss: 18.6279, Fair Loss: 1.2563\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  77%|███████▋  | 1118/1458 [00:09<00:03, 89.61it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 64558.3438, Adv Loss: 19.6836, Fair Loss: 1.3071\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  84%|████████▎ | 1218/1458 [00:10<00:02, 94.34it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 67972.9609, Adv Loss: 18.8111, Fair Loss: 1.2073\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1315/1458 [00:11<00:01, 117.80it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 66557.9297, Adv Loss: 18.8103, Fair Loss: 1.1538\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1418/1458 [00:12<00:00, 121.22it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 69191.3828, Adv Loss: 18.4793, Fair Loss: 1.1961\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:13<00:00, 112.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2471, Fair Loss: 0.2539, Generator Loss: 65502.8615\nValidation - Attacker Loss (orig): 0.2482\nValidation - Attacker Loss (recon): 0.5340\nValidation - Fair Loss: 0.2529\nValidation - Debiasing Effect: 0.2858 (higher is better)\nEpoch completed in 27.68 seconds\n--------------------------------------------------------------------------------\nEpoch 20/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:06<00:00, 237.13it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:07<00:00, 189.00it/s]\nTraining Generator:   8%|▊         | 114/1458 [00:01<00:15, 86.01it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 68029.1328, Adv Loss: 18.1742, Fair Loss: 1.2964\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▍        | 217/1458 [00:02<00:13, 94.08it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 65509.1055, Adv Loss: 18.8091, Fair Loss: 1.3460\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 316/1458 [00:03<00:09, 118.03it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 65333.8203, Adv Loss: 17.6835, Fair Loss: 1.2754\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  28%|██▊       | 415/1458 [00:04<00:08, 119.43it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 66545.6953, Adv Loss: 17.3309, Fair Loss: 1.3333\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▌      | 516/1458 [00:05<00:07, 118.65it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 65128.7891, Adv Loss: 17.6890, Fair Loss: 1.0351\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 618/1458 [00:05<00:06, 120.07it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 63912.9023, Adv Loss: 17.4640, Fair Loss: 1.2705\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 718/1458 [00:06<00:06, 119.67it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 64417.4766, Adv Loss: 17.5971, Fair Loss: 1.2055\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▌    | 820/1458 [00:07<00:05, 116.56it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 64144.3945, Adv Loss: 17.8761, Fair Loss: 1.3328\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 923/1458 [00:08<00:04, 121.46it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 63687.9648, Adv Loss: 17.3071, Fair Loss: 1.1762\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1014/1458 [00:09<00:03, 120.61it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 66194.4141, Adv Loss: 17.4134, Fair Loss: 1.3271\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  76%|███████▋  | 1114/1458 [00:10<00:02, 116.70it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 66323.7969, Adv Loss: 17.0246, Fair Loss: 1.1612\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  83%|████████▎ | 1216/1458 [00:10<00:02, 120.73it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 67598.2891, Adv Loss: 18.2742, Fair Loss: 1.2743\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1319/1458 [00:11<00:01, 114.56it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 69657.0391, Adv Loss: 19.0070, Fair Loss: 1.2658\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1418/1458 [00:12<00:00, 116.57it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 65119.3828, Adv Loss: 17.7785, Fair Loss: 1.2814\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:13<00:00, 111.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2468, Fair Loss: 0.2535, Generator Loss: 65491.4496\nValidation - Attacker Loss (orig): 0.2481\nValidation - Attacker Loss (recon): 0.5412\nValidation - Fair Loss: 0.2527\nValidation - Debiasing Effect: 0.2931 (higher is better)\nEpoch completed in 27.54 seconds\n--------------------------------------------------------------------------------\nEpoch 21/30 - Phase 2: Adversarial training\n","output_type":"stream"},{"name":"stderr","text":"Training Attacker: 100%|██████████| 1458/1458 [00:06<00:00, 218.26it/s]\nTraining Fair Model: 100%|██████████| 1458/1458 [00:07<00:00, 200.59it/s]\nTraining Generator:   8%|▊         | 114/1458 [00:00<00:11, 120.49it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 100: Recon Loss: 65365.7500, Adv Loss: 17.7607, Fair Loss: 1.3139\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  15%|█▍        | 218/1458 [00:01<00:10, 120.94it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 200: Recon Loss: 64794.8398, Adv Loss: 18.0883, Fair Loss: 1.1002\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  22%|██▏       | 320/1458 [00:02<00:09, 119.63it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 300: Recon Loss: 67286.6797, Adv Loss: 17.7737, Fair Loss: 1.2254\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  29%|██▊       | 418/1458 [00:03<00:08, 119.02it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 400: Recon Loss: 67558.9766, Adv Loss: 17.7110, Fair Loss: 1.2110\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  35%|███▌      | 515/1458 [00:04<00:08, 111.78it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 500: Recon Loss: 63990.6875, Adv Loss: 17.5081, Fair Loss: 1.2865\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  42%|████▏     | 618/1458 [00:05<00:07, 119.72it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 600: Recon Loss: 62137.9492, Adv Loss: 17.7746, Fair Loss: 1.3072\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  49%|████▉     | 711/1458 [00:06<00:08, 90.93it/s] ","output_type":"stream"},{"name":"stdout","text":"Batch 700: Recon Loss: 63440.4883, Adv Loss: 18.1203, Fair Loss: 1.3375\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  56%|█████▌    | 816/1458 [00:07<00:07, 89.62it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 800: Recon Loss: 66418.5781, Adv Loss: 19.1419, Fair Loss: 1.2600\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  63%|██████▎   | 921/1458 [00:08<00:05, 103.79it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 900: Recon Loss: 65858.4375, Adv Loss: 17.7233, Fair Loss: 1.3866\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  70%|██████▉   | 1017/1458 [00:09<00:03, 115.54it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1000: Recon Loss: 65046.4883, Adv Loss: 18.9069, Fair Loss: 1.3564\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  76%|███████▋  | 1115/1458 [00:10<00:02, 116.09it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1100: Recon Loss: 66116.3359, Adv Loss: 17.9465, Fair Loss: 1.1511\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  83%|████████▎ | 1214/1458 [00:10<00:02, 119.26it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1200: Recon Loss: 64752.3203, Adv Loss: 17.4905, Fair Loss: 1.2976\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  90%|█████████ | 1318/1458 [00:11<00:01, 119.97it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1300: Recon Loss: 67085.5547, Adv Loss: 17.9099, Fair Loss: 1.3977\n","output_type":"stream"},{"name":"stderr","text":"Training Generator:  97%|█████████▋| 1420/1458 [00:12<00:00, 121.94it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1400: Recon Loss: 63907.9492, Adv Loss: 18.1865, Fair Loss: 1.3008\n","output_type":"stream"},{"name":"stderr","text":"Training Generator: 100%|██████████| 1458/1458 [00:13<00:00, 112.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch Summary - Attacker Loss: 0.2465, Fair Loss: 0.2533, Generator Loss: 65481.9356\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-2c167c7c130a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Updated Training Call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history, generator, attacker_model, fair_model = train_models(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1376\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-31-cf589d0ca195>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(train_loader, val_loader, input_dim, output_dim, num_epochs, phase1_epochs, lambda_fair, lambda_adv, lambda_recon)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0;31m# Validate fair model on generated embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                     \u001b[0mfair_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfair_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m                     \u001b[0mval_fair_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfair_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-55e51f35b0d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":38},{"cell_type":"markdown","source":"# Evaluation on test","metadata":{}},{"cell_type":"code","source":"# Required imports for evaluation\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    roc_auc_score,\n    hamming_loss,\n    precision_recall_curve\n)\nfrom collections import defaultdict\n\n# Make sure plots are displayed properly in Kaggle\n%matplotlib inline\nplt.style.use('seaborn-whitegrid')\n\n# Set random seed for reproducibility\nnp.random.seed(42)\ntorch.manual_seed(42)\n\ndef find_optimal_threshold(y_true, y_pred):\n    \"\"\"\n    Find the threshold that maximizes F1 score for binary classification\n    by calculating precision and recall at each threshold\n    \n    Args:\n        y_true: Ground truth labels (numpy array)\n        y_pred: Predicted probabilities (numpy array)\n        \n    Returns:\n        Optimal threshold value\n    \"\"\"\n    # Handle case where all labels are same class (all 0s or all 1s)\n    if np.all(y_true == 0) or np.all(y_true == 1):\n        return 0.5  # Default to 0.5 if all labels are the same\n    \n    # Get precision-recall pairs for different thresholds\n    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n    \n    # Calculate F1 score for each precision-recall pair\n    # F1 = 2 * (precision * recall) / (precision + recall)\n    # Add a small epsilon to avoid division by zero\n    epsilon = 1e-7\n    f1_scores = 2 * (precision * recall) / (precision + recall + epsilon)\n    \n    # Find the threshold with the best F1 score\n    # Note: precision_recall_curve returns one more precision/recall value than thresholds\n    # So we need to handle this edge case\n    if len(f1_scores) == len(thresholds) + 1:\n        # Use all but the last f1_score value\n        best_idx = np.argmax(f1_scores[:-1])\n    else:\n        best_idx = np.argmax(f1_scores)\n        \n    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n    best_f1 = f1_scores[best_idx]\n    \n    # Print out the precision, recall, and F1 at the optimal threshold\n    if best_idx < len(precision) and best_idx < len(recall):\n        best_precision = precision[best_idx]\n        best_recall = recall[best_idx]\n        print(f\"  Optimal threshold: {best_threshold:.3f}, F1: {best_f1:.3f}, Precision: {best_precision:.3f}, Recall: {best_recall:.3f}\")\n    \n    return best_threshold\n\ndef calculate_multilabel_metrics(y_true, y_pred, y_score=None):\n    \"\"\"\n    Calculate metrics for multilabel classification\n    \n    Args:\n        y_true: True labels\n        y_pred: Predicted binary labels\n        y_score: Prediction scores (probabilities)\n    \n    Returns:\n        Dictionary of metrics\n    \"\"\"\n    metrics = {}\n    \n    # Sample-averaged metrics\n    metrics[\"accuracy\"] = accuracy_score(y_true, y_pred)\n    \n    try:\n        metrics[\"precision\"] = precision_score(y_true, y_pred, average='samples', zero_division=0)\n        metrics[\"recall\"] = recall_score(y_true, y_pred, average='samples', zero_division=0)\n        metrics[\"f1\"] = f1_score(y_true, y_pred, average='samples', zero_division=0)\n    except:\n        # Fallback to macro average if samples doesn't work\n        metrics[\"precision\"] = precision_score(y_true, y_pred, average='macro', zero_division=0)\n        metrics[\"recall\"] = recall_score(y_true, y_pred, average='macro', zero_division=0)\n        metrics[\"f1\"] = f1_score(y_true, y_pred, average='macro', zero_division=0)\n    \n    # Calculate Hamming loss (fraction of incorrect labels)\n    metrics[\"hamming_loss\"] = hamming_loss(y_true, y_pred)\n    \n    # Calculate AUC if scores are provided\n    if y_score is not None:\n        try:\n            metrics[\"macro_auc\"] = roc_auc_score(y_true, y_score, average='macro')\n            metrics[\"micro_auc\"] = roc_auc_score(y_true, y_score, average='micro')\n        except:\n            print(\"Warning: Could not calculate AUC (possibly due to single-class issues)\")\n    \n    # Print out metrics\n    for metric, value in metrics.items():\n        print(f\"  {metric}: {value:.4f}\")\n    \n    return metrics\n\ndef calculate_tpr(y_true, y_pred):\n    \"\"\"\n    Calculate True Positive Rate (Recall/Sensitivity) across all labels\n    \n    Args:\n        y_true: True labels\n        y_pred: Predicted binary labels\n    \n    Returns:\n        TPR value\n    \"\"\"\n    # Calculate TPR for each label\n    tpr_by_label = []\n    \n    for i in range(y_true.shape[1]):\n        y_true_i = y_true[:, i]\n        y_pred_i = y_pred[:, i]\n        \n        # Only calculate if there are positive examples\n        if np.sum(y_true_i) > 0:\n            # True positives / (True positives + False negatives)\n            tp = np.sum((y_true_i == 1) & (y_pred_i == 1))\n            fn = np.sum((y_true_i == 1) & (y_pred_i == 0))\n            \n            if tp + fn > 0:\n                tpr_by_label.append(tp / (tp + fn))\n    \n    # Return macro-averaged TPR\n    if len(tpr_by_label) > 0:\n        return np.mean(tpr_by_label)\n    else:\n        return 0.0\n\ndef evaluate_with_demographics(test_loader, generator, attacker_model, fair_model, device):\n    \"\"\"\n    Evaluate models on test data with demographic subgroup analysis.\n    Compares performance of original biased embeddings vs debiased embeddings.\n    Uses optimal thresholds to maximize F1 score for each label.\n    \n    Args:\n        test_loader: DataLoader for test data\n        generator: Trained generator model\n        attacker_model: Trained attacker model\n        fair_model: Trained fair model\n        device: Computation device\n    \"\"\"\n    print(\"Starting evaluation with demographic analysis...\")\n    \n    # Set models to evaluation mode\n    generator.eval()\n    attacker_model.eval()\n    fair_model.eval()\n    \n    # Initialize collectors for predictions and metadata\n    all_preds_original = []  # Predictions using original embeddings\n    all_preds_debiased = []  # Predictions using debiased embeddings (fair model)\n    all_labels = []\n    all_demographics = {\n        'gender': [],\n        'insurance': [],\n        'race': [],\n        'anchor_age': []\n    }\n    all_subject_ids = []\n    \n    # Collect all predictions and demographics\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Evaluating on test data\"):\n            # Get batch data\n            embeddings = batch['embedding'].to(device)\n            labels = batch['labels'].to(device)\n            demographics = batch['demographics']\n            subject_ids = batch['subject_id']\n            \n            # Generate debiased embeddings\n            reconstructed, _, _, _ = generator(embeddings)\n            \n            # Get predictions\n            original_preds = torch.sigmoid(attacker_model(embeddings))\n            debiased_preds = torch.sigmoid(fair_model(reconstructed))\n            \n            # Store predictions and metadata\n            all_preds_original.append(original_preds.cpu().numpy())\n            all_preds_debiased.append(debiased_preds.cpu().numpy())\n            all_labels.append(labels.cpu().numpy())\n            \n            # Store demographics\n            for demo_key in all_demographics.keys():\n                if demo_key in demographics:\n                    all_demographics[demo_key].extend(demographics[demo_key])\n            \n            all_subject_ids.extend(subject_ids)\n    \n    # Convert lists to numpy arrays for easier processing\n    all_preds_original = np.concatenate(all_preds_original, axis=0)\n    all_preds_debiased = np.concatenate(all_preds_debiased, axis=0)\n    all_labels = np.concatenate(all_labels, axis=0)\n    \n    # Find optimal threshold for each label\n    print(\"\\n=== FINDING OPTIMAL THRESHOLDS ===\")\n    num_labels = all_labels.shape[1]\n    original_thresholds = np.zeros(num_labels)\n    debiased_thresholds = np.zeros(num_labels)\n    \n    for i in range(num_labels):\n        print(f\"\\nLabel {i+1}:\")\n        \n        # Get data for this label\n        label_true = all_labels[:, i]\n        orig_pred = all_preds_original[:, i]\n        debias_pred = all_preds_debiased[:, i]\n        \n        # Calculate class distribution\n        pos_rate = np.mean(label_true)\n        print(f\"  Class distribution: {pos_rate*100:.1f}% positive, {(1-pos_rate)*100:.1f}% negative\")\n        \n        # Find optimal thresholds\n        print(\"  Original model:\")\n        original_thresholds[i] = find_optimal_threshold(label_true, orig_pred)\n        \n        print(\"  Debiased model:\")\n        debiased_thresholds[i] = find_optimal_threshold(label_true, debias_pred)\n    \n    # Apply optimal thresholds to get binary predictions\n    binary_preds_original = np.zeros_like(all_preds_original, dtype=int)\n    binary_preds_debiased = np.zeros_like(all_preds_debiased, dtype=int)\n    \n    for i in range(num_labels):\n        binary_preds_original[:, i] = (all_preds_original[:, i] >= original_thresholds[i]).astype(int)\n        binary_preds_debiased[:, i] = (all_preds_debiased[:, i] >= debiased_thresholds[i]).astype(int)\n    \n    # Overall performance metrics with optimal thresholds\n    print(\"\\n=== OVERALL PERFORMANCE WITH OPTIMAL THRESHOLDS ===\")\n    \n    print(\"\\nOriginal Model Performance:\")\n    original_metrics = calculate_multilabel_metrics(all_labels, binary_preds_original, all_preds_original)\n    \n    print(\"\\nDebiased Model Performance:\")\n    debiased_metrics = calculate_multilabel_metrics(all_labels, binary_preds_debiased, all_preds_debiased)\n    \n    # Calculate performance gap between original and debiased\n    print(\"\\nPerformance Change (Debiased - Original):\")\n    for metric in original_metrics:\n        if metric in debiased_metrics:\n            change = debiased_metrics[metric] - original_metrics[metric]\n            print(f\"  {metric}: {change:.4f}\")\n    \n    # Demographic subgroup analysis\n    print(\"\\n\\n=== DEMOGRAPHIC SUBGROUP ANALYSIS ===\")\n    \n    # Analyze each demographic category\n    for demo_key in all_demographics.keys():\n        if len(all_demographics[demo_key]) == 0:\n            print(f\"\\nSkipping {demo_key} - No data available\")\n            continue\n            \n        print(f\"\\n--- {demo_key.upper()} ANALYSIS ---\")\n        \n        # Get unique values for this demographic\n        unique_values = np.unique(all_demographics[demo_key])\n        \n        # Skip if only one value (no comparison needed)\n        if len(unique_values) <= 1:\n            print(f\"  Only one value for {demo_key}: {unique_values[0]}\")\n            continue\n        \n        # Calculate TPR for each subgroup\n        tpr_results = {}\n        \n        for model_name, binary_preds in [(\"Original\", binary_preds_original), \n                                         (\"Debiased\", binary_preds_debiased)]:\n            tpr_results[model_name] = {}\n            \n            # Calculate overall TPR first\n            overall_tpr = calculate_tpr(all_labels, binary_preds)\n            tpr_results[model_name][\"Overall\"] = overall_tpr\n            \n            # Calculate TPR for each demographic subgroup\n            for value in unique_values:\n                # Create mask for this subgroup\n                mask = np.array(all_demographics[demo_key]) == value\n                \n                # Skip if too few samples\n                if np.sum(mask) < 10:\n                    print(f\"  Skipping {demo_key}={value} (insufficient samples: {np.sum(mask)})\")\n                    continue\n                \n                # Calculate TPR for this subgroup\n                subgroup_tpr = calculate_tpr(all_labels[mask], binary_preds[mask])\n                tpr_results[model_name][value] = subgroup_tpr\n        \n        # Display TPR results and disparities\n        print(f\"\\nTrue Positive Rate (TPR) by {demo_key} subgroups:\")\n        print(f\"{'Subgroup':<15} {'Original TPR':<15} {'Debiased TPR':<15} {'Difference':<15}\")\n        print(\"-\" * 60)\n        \n        # First show overall\n        orig_overall = tpr_results[\"Original\"][\"Overall\"]\n        deb_overall = tpr_results[\"Debiased\"][\"Overall\"]\n        diff = deb_overall - orig_overall\n        print(f\"{'Overall':<15} {orig_overall:.4f}{'':<9} {deb_overall:.4f}{'':<9} {diff:.4f}{'':<9}\")\n        \n        # Then show each subgroup\n        for value in unique_values:\n            if value in tpr_results[\"Original\"] and value in tpr_results[\"Debiased\"]:\n                orig_tpr = tpr_results[\"Original\"][value]\n                deb_tpr = tpr_results[\"Debiased\"][value]\n                diff = deb_tpr - orig_tpr\n                print(f\"{str(value)[:13]:<15} {orig_tpr:.4f}{'':<9} {deb_tpr:.4f}{'':<9} {diff:.4f}{'':<9}\")\n        \n        # Calculate and display TPR disparity (max difference between any two groups)\n        print(\"\\nTPR Disparity (max difference between subgroups):\")\n        \n        # Calculate disparities\n        orig_values = [v for k, v in tpr_results[\"Original\"].items() if k != \"Overall\"]\n        deb_values = [v for k, v in tpr_results[\"Debiased\"].items() if k != \"Overall\"]\n        \n        if len(orig_values) >= 2 and len(deb_values) >= 2:\n            orig_disparity = max(orig_values) - min(orig_values)\n            deb_disparity = max(deb_values) - min(deb_values)\n            diff = deb_disparity - orig_disparity\n            \n            print(f\"  Original model disparity: {orig_disparity:.4f}\")\n            print(f\"  Debiased model disparity: {deb_disparity:.4f}\")\n            print(f\"  Disparity change: {diff:.4f} ({'reduced' if diff < 0 else 'increased'})\")\n        else:\n            print(\"  Not enough subgroups to calculate disparity\")\n    \n    # Calculate per-label F1 scores\n    print(\"\\n=== PER-LABEL F1 SCORES ===\")\n    original_f1 = []\n    debiased_f1 = []\n    \n    for i in range(num_labels):\n        label_true = all_labels[:, i]\n        orig_pred = binary_preds_original[:, i]\n        debias_pred = binary_preds_debiased[:, i]\n        \n        orig_f1 = f1_score(label_true, orig_pred, zero_division=0)\n        deb_f1 = f1_score(label_true, debias_pred, zero_division=0)\n        \n        original_f1.append(orig_f1)\n        debiased_f1.append(deb_f1)\n        \n        print(f\"Label {i+1}:\")\n        print(f\"  Original F1: {orig_f1:.4f} (threshold: {original_thresholds[i]:.3f})\")\n        print(f\"  Debiased F1: {deb_f1:.4f} (threshold: {debiased_thresholds[i]:.3f})\")\n        print(f\"  F1 Change: {deb_f1 - orig_f1:.4f}\")\n    \n    print(f\"\\nAverage Original F1: {np.mean(original_f1):.4f}\")\n    print(f\"Average Debiased F1: {np.mean(debiased_f1):.4f}\")\n    print(f\"Average F1 Change: {np.mean(debiased_f1) - np.mean(original_f1):.4f}\")\n    \n    # Return results for potential further analysis\n    return {\n        \"original_preds\": all_preds_original,\n        \"debiased_preds\": all_preds_debiased,\n        \"labels\": all_labels,\n        \"demographics\": all_demographics,\n        \"subject_ids\": all_subject_ids,\n        \"original_thresholds\": original_thresholds,\n        \"debiased_thresholds\": debiased_thresholds,\n        \"binary_preds_original\": binary_preds_original,\n        \"binary_preds_debiased\": binary_preds_debiased\n    }\n\n# Run the evaluation\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"Running evaluation on device: {device}\")\nprint(f\"Test data has {len(test_loader.dataset)} samples\")\n\nevaluation_results = evaluate_with_demographics(\n    test_loader=test_loader,\n    generator=generator,\n    attacker_model=attacker_model,\n    fair_model=fair_model,\n    device=device\n)\n\n# Visualize TPR by demographic subgroups\nplt.figure(figsize=(12, 8))\n\n# Choose which demographic to visualize\ndemo_key = 'race'  # Change to 'gender', 'insurance', or 'anchor_age' as needed\nif len(evaluation_results['demographics'][demo_key]) > 0:\n    # Get unique subgroups\n    unique_values = np.unique(evaluation_results['demographics'][demo_key])\n    \n    # Calculate TPR for original and debiased models\n    original_tprs = []\n    debiased_tprs = []\n    labels = []\n    \n    # Overall TPR first\n    orig_overall = calculate_tpr(evaluation_results['labels'], \n                                evaluation_results['binary_preds_original'])\n    deb_overall = calculate_tpr(evaluation_results['labels'], \n                               evaluation_results['binary_preds_debiased'])\n    \n    original_tprs.append(orig_overall)\n    debiased_tprs.append(deb_overall)\n    labels.append('Overall')\n    \n    # Calculate for each subgroup\n    for value in unique_values:\n        # Create mask for this subgroup\n        mask = np.array(evaluation_results['demographics'][demo_key]) == value\n        \n        # Skip if too few samples\n        if np.sum(mask) < 10:\n            continue\n            \n        # Calculate TPR\n        orig_tpr = calculate_tpr(\n            evaluation_results['labels'][mask], \n            evaluation_results['binary_preds_original'][mask]\n        )\n        \n        deb_tpr = calculate_tpr(\n            evaluation_results['labels'][mask], \n            evaluation_results['binary_preds_debiased'][mask]\n        )\n        \n        original_tprs.append(orig_tpr)\n        debiased_tprs.append(deb_tpr)\n        labels.append(str(value))\n    \n    # Create bar chart\n    x = np.arange(len(labels))\n    width = 0.35\n    \n    plt.bar(x - width/2, original_tprs, width, label='Original Model')\n    plt.bar(x + width/2, debiased_tprs, width, label='Debiased Model')\n    \n    plt.ylabel('True Positive Rate (TPR)')\n    plt.title(f'TPR Comparison by {demo_key.capitalize()} Subgroups')\n    plt.xticks(x, labels, rotation=45 if len(labels) > 4 else 0)\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig(f'tpr_comparison_{demo_key}.png')\n    plt.show()\nelse:\n    print(f\"No data available for demographic: {demo_key}\")\n\n# Create a visualization of optimal thresholds\nplt.figure(figsize=(10, 6))\nx = np.arange(len(evaluation_results['original_thresholds']))\nwidth = 0.35\n\nplt.bar(x - width/2, evaluation_results['original_thresholds'], width, \n        label='Original Model')\nplt.bar(x + width/2, evaluation_results['debiased_thresholds'], width,\n        label='Debiased Model')\n\nplt.xlabel('Label Index')\nplt.ylabel('Optimal Threshold')\nplt.title('Optimal F1 Thresholds by Label')\nplt.xticks(x, [f\"Label {i+1}\" for i in x])\nplt.legend()\n\nplt.tight_layout()\nplt.savefig('optimal_thresholds.png')\nplt.show()\n\n# Save the evaluation results\nnp.save('evaluation_results.npy', evaluation_results)\nprint(\"Evaluation completed and results saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T03:47:48.679521Z","iopub.status.idle":"2025-03-21T03:47:48.679768Z","shell.execute_reply":"2025-03-21T03:47:48.679666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}