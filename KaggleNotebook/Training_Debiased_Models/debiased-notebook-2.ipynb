{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11118745,"sourceType":"datasetVersion","datasetId":6933200},{"sourceId":11118787,"sourceType":"datasetVersion","datasetId":6933232},{"sourceId":306607,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":261453,"modelId":282602}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport os\nimport pickle\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\n\n# Path to processed data\ndata_path = \"/kaggle/input/mimic-embedding/processed_mimic_data\"\n\nclass ProcessedMIMICDataset(Dataset):\n    def __init__(self, data_path, data_format='pt'):\n        \"\"\"\n        Load a processed MIMIC dataset\n        \n        Args:\n            data_path: Path to the processed data directory\n            data_format: Format to load ('pt' for PyTorch tensors, 'npy' for NumPy, 'pkl' for Pickle)\n        \"\"\"\n        self.data_path = data_path\n        self.data_format = data_format\n        \n        if data_format == 'pkl':\n            # Load the pickle file\n            with open(os.path.join(data_path, \"all_data.pkl\"), 'rb') as f:\n                self.all_data = pickle.load(f)\n            \n            self.embeddings = self.all_data['embeddings']\n            self.labels = self.all_data['labels']\n            self.subject_ids = self.all_data['subject_ids']\n            self.study_ids = self.all_data['study_ids']\n            self.demographics = self.all_data['demographics']\n            \n        elif data_format == 'pt':\n            # Load PyTorch tensors with weights_only=True to avoid security warnings\n            self.embeddings = torch.load(os.path.join(data_path, \"embeddings.pt\"), weights_only=True)\n            self.labels = torch.load(os.path.join(data_path, \"labels.pt\"), weights_only=True)\n            \n            # Load IDs from CSV\n            ids_df = pd.read_csv(os.path.join(data_path, \"ids.csv\"))\n            self.subject_ids = ids_df['subject_id'].tolist()\n            self.study_ids = ids_df['study_id'].tolist()\n            \n            # Load demographics\n            with open(os.path.join(data_path, \"demographics.pkl\"), 'rb') as f:\n                self.demographics = pickle.load(f)\n                \n        elif data_format == 'npy':\n            # Load NumPy arrays\n            self.embeddings = np.load(os.path.join(data_path, \"embeddings.npy\"))\n            self.labels = np.load(os.path.join(data_path, \"labels.npy\"))\n            \n            # Load IDs from CSV\n            ids_df = pd.read_csv(os.path.join(data_path, \"ids.csv\"))\n            self.subject_ids = ids_df['subject_id'].tolist()\n            self.study_ids = ids_df['study_id'].tolist()\n            \n            # Load demographics\n            with open(os.path.join(data_path, \"demographics.pkl\"), 'rb') as f:\n                self.demographics = pickle.load(f)\n                \n        else:\n            raise ValueError(f\"Unsupported data format: {data_format}\")\n        \n        print(f\"Loaded dataset from {data_path} with {len(self.embeddings)} samples\")\n        \n    def __len__(self):\n        return len(self.embeddings)\n    \n    def __getitem__(self, idx):\n        if self.data_format == 'pt':\n            embedding = self.embeddings[idx]\n            labels = self.labels[idx]\n        else:\n            embedding = torch.tensor(self.embeddings[idx], dtype=torch.float32)\n            labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n            \n        return {\n            'embedding': embedding,\n            'labels': labels,\n            'subject_id': self.subject_ids[idx],\n            'study_id': self.study_ids[idx],\n            'demographics': self.demographics[idx]\n        }\n\n# Load the datasets\ntrain_dataset = ProcessedMIMICDataset(os.path.join(data_path, \"train\"), data_format='pt')\ntest_dataset = ProcessedMIMICDataset(os.path.join(data_path, \"test\"), data_format='pt')\n\n# Create validation set from train (if needed)\ndef create_train_val_split(train_dataset, val_ratio=0.1, random_seed=42):\n    \"\"\"Split training dataset into train and validation sets\"\"\"\n    dataset_size = len(train_dataset)\n    val_size = int(val_ratio * dataset_size)\n    train_size = dataset_size - val_size\n    \n    train_subset, val_subset = torch.utils.data.random_split(\n        train_dataset, \n        [train_size, val_size],\n        generator=torch.Generator().manual_seed(random_seed)\n    )\n    \n    print(f\"Split train dataset: {train_size} training samples, {val_size} validation samples\")\n    \n    return train_subset, val_subset\n\n# Create train/val split (optional)\ntrain_subset, val_subset = create_train_val_split(train_dataset)\n\n# Create data loaders\nbatch_size = 128\ntrain_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_subset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# Display dataset statistics\nprint(f\"Training samples: {len(train_subset)}\")\nprint(f\"Validation samples: {len(val_subset)}\")\nprint(f\"Test samples: {len(test_dataset)}\")\n\n# Example of accessing a batch\nsample_batch = next(iter(train_loader))\nprint(f\"Sample batch shapes:\")\nprint(f\"  Embeddings: {sample_batch['embedding'].shape}\")\nprint(f\"  Labels: {sample_batch['labels'].shape}\")\nprint(f\"  Batch keys {sample_batch.keys()}\")\nprint(f\"  Batch[demographic] keys {sample_batch['demographics'].keys()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(pd.Series(sample_batch['demographics']['gender']).unique()),len(pd.Series(sample_batch['demographics']['insurance']).unique()),len(pd.Series(sample_batch['demographics']['race']).unique()),","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LWBC Test","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, Subset, random_split\nimport numpy as np\nimport random\nfrom tqdm import tqdm\nfrom copy import deepcopy\nfrom sklearn.metrics import roc_auc_score\n\n# The MIMICClassifier from your code\nclass MIMICClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.2):\n        \"\"\"\n        Simple feed-forward neural network for multi-label classification\n        \n        Args:\n            input_dim: Dimension of input embeddings\n            hidden_dims: List of hidden layer dimensions\n            output_dim: Number of output classes\n            dropout_rate: Dropout probability for regularization\n        \"\"\"\n        super(MIMICClassifier, self).__init__()\n        \n        # Create the layers\n        layers = []\n        \n        # Input layer\n        layers.append(nn.Linear(input_dim, hidden_dims[0]))\n        layers.append(nn.ReLU())\n        layers.append(nn.BatchNorm1d(hidden_dims[0]))\n        layers.append(nn.Dropout(dropout_rate))\n        \n        # Hidden layers\n        for i in range(len(hidden_dims)-1):\n            layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n            layers.append(nn.ReLU())\n            layers.append(nn.BatchNorm1d(hidden_dims[i+1]))\n            layers.append(nn.Dropout(dropout_rate))\n        \n        # Output layer\n        layers.append(nn.Linear(hidden_dims[-1], output_dim))\n        \n        self.model = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)\n\n# Learning with Biased Committee implementation\nclass LWBC:\n    def __init__(\n        self,\n        train_loader,\n        val_loader,\n        input_dim=1376,\n        hidden_dims=[512, 256, 128],\n        output_dim=14,\n        committee_size=30,\n        subset_size=0.7,\n        alpha=0.02,\n        lambda_kd=0.6,\n        temperature=2.0,\n        device='cuda' if torch.cuda.is_available() else 'cpu'\n    ):\n        \"\"\"\n        LWBC implementation for MIMIC dataset.\n        \n        Args:\n            train_loader: DataLoader for training data\n            val_loader: DataLoader for validation data\n            input_dim: Input embedding dimension\n            hidden_dims: Hidden layer dimensions\n            output_dim: Number of output classes\n            committee_size: Number of classifiers in the committee\n            subset_size: Size of subset for each committee member (proportion)\n            alpha: Scaling parameter for weighting function\n            lambda_kd: Balance parameter for knowledge distillation\n            temperature: Temperature for knowledge distillation\n            device: Device to run computations on\n        \"\"\"\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.input_dim = input_dim\n        self.hidden_dims = hidden_dims\n        self.output_dim = output_dim\n        self.committee_size = committee_size\n        self.subset_size = subset_size\n        self.alpha = alpha\n        self.lambda_kd = lambda_kd\n        self.temperature = temperature\n        self.device = device\n        \n        # Initialize main classifier\n        self.main_classifier = MIMICClassifier(\n            input_dim, hidden_dims, output_dim\n        ).to(device)\n        \n        # Initialize committee of auxiliary classifiers\n        self.committee = [\n            MIMICClassifier(input_dim, hidden_dims, output_dim).to(device)\n            for _ in range(committee_size)\n        ]\n        \n        # Initialize optimizers\n        self.main_optimizer = optim.Adam(self.main_classifier.parameters(), lr=1e-3)\n        self.committee_optimizers = [\n            optim.Adam(classifier.parameters(), lr=1e-3)\n            for classifier in self.committee\n        ]\n        \n        # Loss function for multi-label classification\n        self.criterion = nn.BCEWithLogitsLoss(reduction='none')\n        \n        # Create subsets for each committee member\n        self.create_subsets()\n        \n    def create_subsets(self):\n        \"\"\"Create random subsets of training data for each committee member\"\"\"\n        # Count total samples in the training dataset\n        dataset_size = len(self.train_loader.dataset)\n        subset_count = int(dataset_size * self.subset_size)\n        \n        # Create subsets for each committee member\n        self.subsets = []\n        for _ in range(self.committee_size):\n            # Sample indices with replacement\n            subset_indices = random.choices(range(dataset_size), k=subset_count)\n            self.subsets.append(sorted(subset_indices))\n    \n    def compute_sample_weights(self, outputs, labels):\n        \"\"\"\n        Compute sample weights based on committee consensus\n        \n        Args:\n            outputs: List of outputs from committee members\n            labels: Ground truth labels\n            \n        Returns:\n            Tensor of sample weights\n        \"\"\"\n        batch_size = labels.size(0)\n        correct_count = torch.zeros(batch_size, device=self.device)\n        \n        # Count correct predictions for each sample across committee\n        for output in outputs:\n            preds = (torch.sigmoid(output) > 0.25).float()\n            correct = (preds == labels).all(dim=1).float()\n            correct_count += correct\n        \n        # Calculate proportion of committee members that predicted correctly\n        correct_proportion = correct_count / self.committee_size\n        \n        # Apply weighting function w(x) = 1 / (proportion + alpha)\n        weights = 1.0 / (correct_proportion + self.alpha)\n        \n        return weights\n    \n    def knowledge_distillation_loss(self, committee_output, main_output):\n        \"\"\"\n        Calculate knowledge distillation loss\n        \n        Args:\n            committee_output: Output from committee member\n            main_output: Output from main classifier\n            \n        Returns:\n            KD loss\n        \"\"\"\n        # Apply temperature scaling\n        committee_logits = committee_output / self.temperature\n        main_logits = main_output / self.temperature\n        \n        # KL divergence between softmax distributions\n        committee_probs = torch.sigmoid(committee_logits)\n        main_probs = torch.sigmoid(main_logits)\n        \n        # Calculate KL divergence for each output dimension\n        kl_div = main_probs * torch.log(main_probs / (committee_probs + 1e-8) + 1e-8) + \\\n                (1 - main_probs) * torch.log((1 - main_probs) / (1 - committee_probs + 1e-8) + 1e-8)\n                \n        return kl_div.mean()\n    \n    def train_committee_warmup(self, num_epochs=5):\n        \"\"\"Warm-up training for committee members\"\"\"\n        print(\"Starting committee warm-up training...\")\n        \n        # Create sample masks for committee members\n        committee_masks = []\n        dataset_size = len(self.train_loader.dataset)\n        for subset_indices in self.subsets:\n            mask = torch.zeros(dataset_size, dtype=torch.bool)\n            mask[subset_indices] = True\n            committee_masks.append(mask)\n        \n        for classifier_idx, classifier in enumerate(self.committee):\n            classifier.train()\n            optimizer = self.committee_optimizers[classifier_idx]\n            mask = committee_masks[classifier_idx]\n            \n            print(f\"Training committee member {classifier_idx+1}/{self.committee_size}\")\n            \n            for epoch in range(num_epochs):\n                total_loss = 0.0\n                num_batches = 0\n                \n                # Create a subset DataLoader\n                subset_dataset = Subset(self.train_loader.dataset, self.subsets[classifier_idx])\n                subset_loader = DataLoader(\n                    subset_dataset, \n                    batch_size=self.train_loader.batch_size,\n                    shuffle=True,\n                    num_workers=4\n                )\n                \n                for batch in subset_loader:\n                    # Extract data\n                    X = batch['embedding'].to(self.device)\n                    y = batch['labels'].to(self.device)\n                    \n                    # Forward pass\n                    outputs = classifier(X)\n                    loss = self.criterion(outputs, y).mean()\n                    \n                    # Backward pass and optimize\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n                    \n                    total_loss += loss.item()\n                    num_batches += 1\n                \n                avg_loss = total_loss / max(1, num_batches)\n                print(f\"  Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n    \n    def train_epoch(self):\n        \"\"\"Train for one epoch\"\"\"\n        self.main_classifier.train()\n        for classifier in self.committee:\n            classifier.train()\n        \n        total_main_loss = 0.0\n        total_committee_loss = 0.0\n        num_batches = 0\n        \n        # Calculate sample weights for all training data\n        print(\"Computing sample weights based on committee consensus...\")\n        sample_weights_dict = {}  # Map batch_idx -> sample_weights\n        \n        # Create mapping from global index to subset inclusion\n        dataset_size = len(self.train_loader.dataset)\n        subset_masks = []\n        for subset in self.subsets:\n            mask = torch.zeros(dataset_size, dtype=torch.bool)\n            mask[subset] = True\n            subset_masks.append(mask)\n            \n        # Get weights for all samples\n        global_sample_weights = torch.ones(dataset_size, device=self.device)\n        \n        # Since we can't fit all data at once, process in batches\n        batch_size = self.train_loader.batch_size\n        \n        # First, get predictions from committee for all samples\n        with torch.no_grad():\n            all_committee_preds = [[] for _ in range(self.committee_size)]\n            all_labels = []\n            batch_offsets = []\n            \n            # Get predictions for the entire dataset\n            offset = 0\n            for batch in tqdm(self.train_loader, desc=\"Getting committee predictions\"):\n                X = batch['embedding'].to(self.device)\n                y = batch['labels'].to(self.device)\n                \n                batch_offsets.append(offset)\n                \n                # Get predictions from each committee member\n                for i, classifier in enumerate(self.committee):\n                    preds = classifier(X)\n                    all_committee_preds[i].append(preds)\n                \n                all_labels.append(y)\n                offset += len(X)\n            \n            # Determine weights for each sample\n            for batch_idx, offset in enumerate(batch_offsets):\n                y = all_labels[batch_idx]\n                batch_size = y.size(0)\n                \n                # Count correct predictions for each sample\n                correct_count = torch.zeros(batch_size, device=self.device)\n                for i in range(self.committee_size):\n                    output = all_committee_preds[i][batch_idx]\n                    preds = (torch.sigmoid(output) > 0.25).float()\n                    correct = (preds == y).all(dim=1).float()\n                    correct_count += correct\n                \n                # Calculate proportion of committee members that predicted correctly\n                correct_proportion = correct_count / self.committee_size\n                \n                # Apply weighting function w(x) = 1 / (proportion + alpha)\n                weights = 1.0 / (correct_proportion + self.alpha)\n                \n                # Store for later use\n                sample_weights_dict[batch_idx] = weights\n        \n        # Main training loop\n        print(\"Training main classifier with weighted samples...\")\n        for batch_idx, batch in enumerate(tqdm(self.train_loader, desc=\"Training main classifier\")):\n            X = batch['embedding'].to(self.device)\n            y = batch['labels'].to(self.device)\n            batch_size = X.size(0)\n            \n            # Get sample weights for this batch\n            sample_weights = sample_weights_dict[batch_idx]\n            \n            # Train main classifier with weighted loss\n            self.main_optimizer.zero_grad()\n            main_outputs = self.main_classifier(X)\n            main_loss = (self.criterion(main_outputs, y) * sample_weights.unsqueeze(1)).mean()\n            main_loss.backward()\n            self.main_optimizer.step()\n            \n            total_main_loss += main_loss.item()\n            num_batches += 1\n        \n        # Train committee members with knowledge distillation\n        print(\"Training committee with knowledge distillation...\")\n        committee_loss_sum = 0.0\n        committee_batches = 0\n        \n        for classifier_idx, classifier in enumerate(self.committee):\n            classifier.train()\n            optimizer = self.committee_optimizers[classifier_idx]\n            \n            # Create subset dataset for this committee member\n            subset_dataset = Subset(self.train_loader.dataset, self.subsets[classifier_idx])\n            subset_loader = DataLoader(\n                subset_dataset,\n                batch_size=self.train_loader.batch_size,\n                shuffle=True,\n                num_workers=4\n            )\n            \n            # Create complement dataset for knowledge distillation\n            complement_indices = [i for i in range(dataset_size) if i not in self.subsets[classifier_idx]]\n            complement_dataset = Subset(self.train_loader.dataset, complement_indices)\n            complement_loader = DataLoader(\n                complement_dataset,\n                batch_size=self.train_loader.batch_size,\n                shuffle=True,\n                num_workers=4\n            )\n            \n            # Train on subset with supervised loss\n            for batch in subset_loader:\n                X = batch['embedding'].to(self.device)\n                y = batch['labels'].to(self.device)\n                \n                # Forward pass\n                optimizer.zero_grad()\n                outputs = classifier(X)\n                ce_loss = self.criterion(outputs, y).mean()\n                ce_loss.backward()\n                optimizer.step()\n            \n            # Train on complement with knowledge distillation\n            for batch in complement_loader:\n                X = batch['embedding'].to(self.device)\n                \n                # Forward pass\n                optimizer.zero_grad()\n                committee_output = classifier(X)\n                \n                # Get main classifier output\n                with torch.no_grad():\n                    main_output = self.main_classifier(X)\n                \n                # Knowledge distillation loss\n                kd_loss = self.knowledge_distillation_loss(committee_output, main_output)\n                kd_loss.backward()\n                optimizer.step()\n                \n                committee_loss_sum += kd_loss.item()\n                committee_batches += 1\n        \n        avg_committee_loss = committee_loss_sum / max(1, committee_batches)\n        \n        return total_main_loss / num_batches, avg_committee_loss\n    \n    def evaluate(self, loader):\n        \"\"\"Evaluate model on validation or test set\"\"\"\n        self.main_classifier.eval()\n        all_outputs = []\n        all_labels = []\n        \n        with torch.no_grad():\n            for batch in loader:\n                X = batch['embedding'].to(self.device)\n                y = batch['labels'].to(self.device)\n                \n                outputs = self.main_classifier(X)\n                all_outputs.append(outputs.cpu())\n                all_labels.append(y.cpu())\n        \n        all_outputs = torch.cat(all_outputs, dim=0)\n        all_labels = torch.cat(all_labels, dim=0)\n        \n        # Compute ROC-AUC score\n        all_outputs_sigmoid = torch.sigmoid(all_outputs).numpy()\n        all_labels_numpy = all_labels.numpy()\n        \n        # Handle case where a class might have all 0s or all 1s\n        auc_scores = []\n        for i in range(self.output_dim):\n            if len(np.unique(all_labels_numpy[:, i])) > 1:\n                auc_scores.append(roc_auc_score(all_labels_numpy[:, i], all_outputs_sigmoid[:, i]))\n            else:\n                auc_scores.append(0.25)  # Default for single-class\n        \n        macro_auc = np.mean(auc_scores)\n        \n        # Compute accuracy\n        predictions = (torch.sigmoid(all_outputs) > 0.5).float()\n        accuracy = (predictions == all_labels).float().mean().item()\n        \n        return accuracy, macro_auc, auc_scores\n    \n    def evaluate_by_demographic(self, loader, demographic_attr='gender'):\n        \"\"\"Evaluate model performance across demographic groups\"\"\"\n        self.main_classifier.eval()\n        results = {}\n        \n        # Initialize dictionaries to store outputs and labels for each group\n        group_outputs = {}\n        group_labels = {}\n        \n        with torch.no_grad():\n            for batch in loader:\n                X = batch['embedding'].to(self.device)\n                y = batch['labels'].to(self.device)\n                \n                # Get demographic attributes\n                demographic_values = batch['demographics'][demographic_attr]\n                \n                # Get model outputs\n                outputs = self.main_classifier(X)\n                \n                # Group by demographic\n                for i, demo_val in enumerate(demographic_values):\n                    demo_val = demo_val.item() if isinstance(demo_val, torch.Tensor) else demo_val\n                    if demo_val not in group_outputs:\n                        group_outputs[demo_val] = []\n                        group_labels[demo_val] = []\n                    \n                    group_outputs[demo_val].append(outputs[i:i+1].cpu())\n                    group_labels[demo_val].append(y[i:i+1].cpu())\n        \n        # Calculate metrics for each group\n        for group in group_outputs:\n            group_output_tensor = torch.cat(group_outputs[group], dim=0)\n            group_label_tensor = torch.cat(group_labels[group], dim=0)\n            \n            # Compute ROC-AUC\n            group_output_sigmoid = torch.sigmoid(group_output_tensor).numpy()\n            group_label_numpy = group_label_tensor.numpy()\n            \n            # Handle case where a class might have all 0s or all 1s\n            auc_scores = []\n            for i in range(self.output_dim):\n                if len(np.unique(group_label_numpy[:, i])) > 1:\n                    auc_scores.append(roc_auc_score(group_label_numpy[:, i], group_output_sigmoid[:, i]))\n                else:\n                    auc_scores.append(0.25)  # Default for single-class\n            \n            macro_auc = np.mean(auc_scores)\n            \n            # Compute accuracy\n            predictions = (torch.sigmoid(group_output_tensor) > 0.5).float()\n            accuracy = (predictions == group_label_tensor).float().mean().item()\n            \n            results[group] = {\n                'accuracy': accuracy,\n                'macro_auc': macro_auc,\n                'count': len(group_labels[group])\n            }\n        \n        return results\n    \n    def train(self, num_epochs=20, warmup_epochs=5):\n        \"\"\"Full training procedure\"\"\"\n        # Warm-up training for committee\n        self.train_committee_warmup(num_epochs=warmup_epochs)\n        \n        # Main training loop\n        best_auc = 0.0\n        best_model = None\n        history = {\n            'train_loss': [],\n            'committee_loss': [],\n            'val_accuracy': [],\n            'val_auc': []\n        }\n        \n        for epoch in range(num_epochs):\n            # Train one epoch\n            train_loss, committee_loss = self.train_epoch()\n            \n            # Evaluate\n            val_accuracy, val_auc, _ = self.evaluate(self.val_loader)\n            \n            # Store history\n            history['train_loss'].append(train_loss)\n            history['committee_loss'].append(committee_loss)\n            history['val_accuracy'].append(val_accuracy)\n            history['val_auc'].append(val_auc)\n            \n            # Print metrics\n            print(f\"Epoch {epoch+1}/{num_epochs}:\")\n            print(f\"  Train Loss: {train_loss:.4f}, Committee Loss: {committee_loss:.4f}\")\n            print(f\"  Val Accuracy: {val_accuracy:.4f}, Val AUC: {val_auc:.4f}\")\n            \n            # Save best model\n            if val_auc > best_auc:\n                best_auc = val_auc\n                best_model = deepcopy(self.main_classifier.state_dict())\n                print(f\"  New best model with Val AUC: {val_auc:.4f}\")\n        \n        # Load best model\n        if best_model is not None:\n            self.main_classifier.load_state_dict(best_model)\n        \n        return history\n    \n    def save_model(self, path):\n        \"\"\"Save the model to disk\"\"\"\n        torch.save(self.main_classifier.state_dict(), path)\n    \n    def load_model(self, path):\n        \"\"\"Load the model from disk\"\"\"\n        self.main_classifier.load_state_dict(torch.load(path, map_location=self.device))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize LWBC\nlwbc = LWBC(\n    train_loader=train_loader,\n    val_loader=val_loader,\n    input_dim=1376,\n    hidden_dims=[512, 256, 128],\n    output_dim=14,       \n    committee_size=3,\n    subset_size=0.3,\n    alpha=0.02,\n    lambda_kd=0.6\n)\n\n# Train the model\nhistory = lwbc.train(num_epochs=100, warmup_epochs=5)\n\n# Evaluate on test set\ntest_accuracy, test_auc, _ = lwbc.evaluate(test_loader)\nprint(f\"Test Accuracy: {test_accuracy:.4f}, Test AUC: {test_auc:.4f}\")\n\n# Evaluate across demographic groups\ngender_results = lwbc.evaluate_by_demographic(test_loader, demographic_attr='gender')\nfor gender, metrics in gender_results.items():\n    print(f\"Gender {gender}: Accuracy: {metrics['accuracy']:.4f}, AUC: {metrics['macro_auc']:.4f}, Count: {metrics['count']}\")\n\n# Save model\nlwbc.save_model('lwbc_mimic_model.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Downsampling","metadata":{}},{"cell_type":"code","source":"train_subset[0],val_subset[0],test_dataset[0]\n# DownSample Train, if it is is too small - FineTune the biased","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom collections import defaultdict\nimport random\n\ndef create_fair_dataset(train_subset, random_seed=42):\n    \"\"\"\n    Create a fair dataset by ensuring each demographic category \n    and label class has exactly the same count.\n    \n    Parameters:\n    -----------\n    train_subset : list\n        List of dictionaries containing patient data with PyTorch tensors\n    random_seed : int\n        Random seed for reproducibility\n    \n    Returns:\n    --------\n    list\n        A perfectly balanced dataset\n    \"\"\"\n    random.seed(random_seed)\n    np.random.seed(random_seed)\n    \n    # Step 1: First independently downsample each demographic category\n    \n    # Gender downsampling\n    male_samples = [item for item in train_subset if item['demographics']['gender'] == 'M']\n    female_samples = [item for item in train_subset if item['demographics']['gender'] == 'F']\n    \n    min_gender_count = min(len(male_samples), len(female_samples))\n    male_samples = random.sample(male_samples, min_gender_count)\n    female_samples = random.sample(female_samples, min_gender_count)\n    \n    balanced_by_gender = male_samples + female_samples\n    print(f\"After gender balancing: {len(balanced_by_gender)} samples\")\n    \n    # Insurance downsampling\n    insurance_groups = defaultdict(list)\n    for item in balanced_by_gender:\n        insurance_groups[item['demographics']['insurance']].append(item)\n    \n    min_insurance_count = min(len(group) for group in insurance_groups.values())\n    \n    balanced_by_insurance = []\n    for insurance_type, samples in insurance_groups.items():\n        balanced_by_insurance.extend(random.sample(samples, min_insurance_count))\n    \n    print(f\"After insurance balancing: {len(balanced_by_insurance)} samples\")\n    \n    # Race downsampling\n    race_groups = defaultdict(list)\n    for item in balanced_by_insurance:\n        race_groups[item['demographics']['race']].append(item)\n    \n    min_race_count = min(len(group) for group in race_groups.values())\n    \n    balanced_by_race = []\n    for race, samples in race_groups.items():\n        balanced_by_race.extend(random.sample(samples, min_race_count))\n    \n    print(f\"After race balancing: {len(balanced_by_race)} samples\")\n    \n    # Label downsampling\n    label_groups = defaultdict(list)\n    for item in balanced_by_race:\n        if isinstance(item['labels'], torch.Tensor):\n            label_key = tuple(item['labels'].cpu().numpy().tolist())\n        else:\n            label_key = tuple(item['labels'])\n        \n        label_groups[label_key].append(item)\n    \n    min_label_count = min(len(group) for group in label_groups.values())\n    \n    balanced_by_label = []\n    for label, samples in label_groups.items():\n        balanced_by_label.extend(random.sample(samples, min_label_count))\n    \n    print(f\"After label balancing: {len(balanced_by_label)} samples\")\n    \n    return balanced_by_label\n\ndef verify_fairness(dataset):\n    \"\"\"\n    Simple function to verify the fairness of the dataset.\n    Handles PyTorch tensor data.\n    \n    Parameters:\n    -----------\n    dataset : list\n        The dataset to verify\n    \n    Returns:\n    --------\n    dict\n        Distribution statistics\n    \"\"\"\n    # Count demographics\n    gender_count = defaultdict(int)\n    insurance_count = defaultdict(int)\n    race_count = defaultdict(int)\n    label_count = defaultdict(int)\n    \n    for item in dataset:\n        gender_count[item['demographics']['gender']] += 1\n        insurance_count[item['demographics']['insurance']] += 1\n        race_count[item['demographics']['race']] += 1\n        \n        # Handle PyTorch tensors properly\n        labels_tensor = item['labels']\n        if isinstance(labels_tensor, torch.Tensor):\n            # Convert to a hashable format\n            label_tuple = tuple(labels_tensor.cpu().numpy().tolist())\n        else:\n            label_tuple = tuple(labels_tensor)\n            \n        label_count[label_tuple] += 1\n    \n    return {\n        'gender': dict(gender_count),\n        'insurance': dict(insurance_count),\n        'race': dict(race_count),\n        'labels': dict(label_count),\n        'total_samples': len(dataset)\n    }\n\n# Example usage:\nfair_train_subset = create_fair_dataset(train_subset)\nfairness_metrics = verify_fairness(fair_train_subset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nimport time\nfrom tqdm import tqdm\nimport os\n\n# Define the neural network model\nclass MIMICClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.2):\n        \"\"\"\n        Simple feed-forward neural network for multi-label classification\n        \n        Args:\n            input_dim: Dimension of input embeddings\n            hidden_dims: List of hidden layer dimensions\n            output_dim: Number of output classes\n            dropout_rate: Dropout probability for regularization\n        \"\"\"\n        super(MIMICClassifier, self).__init__()\n        \n        # Create the layers\n        layers = []\n        \n        # Input layer\n        layers.append(nn.Linear(input_dim, hidden_dims[0]))\n        layers.append(nn.ReLU())\n        layers.append(nn.BatchNorm1d(hidden_dims[0]))\n        layers.append(nn.Dropout(dropout_rate))\n        \n        # Hidden layers\n        for i in range(len(hidden_dims)-1):\n            layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n            layers.append(nn.ReLU())\n            layers.append(nn.BatchNorm1d(hidden_dims[i+1]))\n            layers.append(nn.Dropout(dropout_rate))\n        \n        # Output layer\n        layers.append(nn.Linear(hidden_dims[-1], output_dim))\n        \n        # No activation function here since we're using BCEWithLogitsLoss\n        # which combines sigmoid and binary cross entropy\n        \n        self.model = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\ndef finetune_on_fair_dataset(model, fair_train_subset, val_subset, num_epochs=20, \n                            learning_rate=0.0005, weight_decay=1e-4, batch_size=32):\n    train_embeddings = []\n    train_labels = []\n    \n    for item in fair_train_subset:\n        if isinstance(item['embedding'], torch.Tensor):\n            train_embeddings.append(item['embedding'])\n        else:\n            train_embeddings.append(torch.tensor(item['embedding']))\n            \n        if isinstance(item['labels'], torch.Tensor):\n            train_labels.append(item['labels'])\n        else:\n            train_labels.append(torch.tensor(item['labels']))\n    \n    train_embeddings = torch.stack(train_embeddings)\n    train_labels = torch.stack(train_labels)\n    \n    train_dataset = TensorDataset(train_embeddings, train_labels)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    \n    if isinstance(val_subset, DataLoader):\n        val_loader = val_subset\n        val_dataset = val_subset.dataset\n    else:\n        val_embeddings = []\n        val_labels = []\n        \n        for item in val_subset:\n            if isinstance(item['embedding'], torch.Tensor):\n                val_embeddings.append(item['embedding'])\n            else:\n                val_embeddings.append(torch.tensor(item['embedding']))\n                \n            if isinstance(item['labels'], torch.Tensor):\n                val_labels.append(item['labels'])\n            else:\n                val_labels.append(torch.tensor(item['labels']))\n        \n        val_embeddings = torch.stack(val_embeddings)\n        val_labels = torch.stack(val_labels)\n        \n        val_dataset = TensorDataset(val_embeddings, val_labels)\n        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    \n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    \n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n    \n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'val_auc': []\n    }\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    \n    print(f\"Fine-tuning on fair dataset with {len(train_dataset)} samples\")\n    print(f\"Using device: {device}\")\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for inputs, targets in train_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            optimizer.zero_grad()\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * inputs.size(0)\n        \n        train_loss /= len(train_dataset)\n        \n        model.eval()\n        val_loss = 0.0\n        val_preds = []\n        val_targets = []\n        \n        with torch.no_grad():\n            for inputs, targets in val_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n                \n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                \n                val_loss += loss.item() * inputs.size(0)\n                \n                val_preds.append(torch.sigmoid(outputs).cpu().numpy())\n                val_targets.append(targets.cpu().numpy())\n        \n        val_loss /= len(val_dataset)\n        \n        val_preds = np.vstack(val_preds)\n        val_targets = np.vstack(val_targets)\n        \n        aucs = []\n        for i in range(val_targets.shape[1]):\n            if np.sum(val_targets[:, i] > 0) > 0 and np.sum(val_targets[:, i] == 0) > 0:\n                auc = roc_auc_score(val_targets[:, i], val_preds[:, i])\n                aucs.append(auc)\n        \n        val_auc = np.mean(aucs) if aucs else 0.0\n        \n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['val_auc'].append(val_auc)\n        \n        scheduler.step(val_loss)\n        \n        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n              f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}\")\n    \n    return model, history\n\nhidden_dims = [512, 256, 128]\ndropout_rate = 0.3\nlearning_rate = 0.0005\nweight_decay = 1e-4\nnum_epochs = 20\nlabel_columns = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', \n            'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', \n            'Atelectasis', 'Pneumothorax', 'Pleural Effusion', \n            'Pleural Other', 'Fracture', 'Support Devices', 'No Finding']\n\nmodel.load_state_dict(torch.load(\"/kaggle/input/biased-basline/pytorch/default/1/baseline_classifier_model.pt\"))\n\nfair_train_subset = create_fair_dataset(train_subset)\n\nfinetuned_model, training_history = finetune_on_fair_dataset(\n    model=model,\n    fair_train_subset=fair_train_subset,\n    val_subset=val_subset,\n    learning_rate=0.0005,\n    weight_decay=1e-4,\n    num_epochs=20\n)\n\ntorch.save(finetuned_model.state_dict(), \"finetuned_fair_model.pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensemble","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\n\ndef train_from_scratch(fair_train_subset, val_subset, input_dim=1376, \n                      hidden_dims=[512, 256, 128], output_dim=14, \n                      learning_rate=0.001, weight_decay=1e-5, \n                      num_epochs=50, batch_size=32, dropout_rate=0.3):\n    # Initialize a new model\n    model = MIMICClassifier(\n        input_dim=input_dim,\n        hidden_dims=hidden_dims,\n        output_dim=output_dim,\n        dropout_rate=dropout_rate\n    )\n    \n    # Process training data\n    train_embeddings = []\n    train_labels = []\n    \n    for item in fair_train_subset:\n        if isinstance(item['embedding'], torch.Tensor):\n            train_embeddings.append(item['embedding'])\n        else:\n            train_embeddings.append(torch.tensor(item['embedding']))\n            \n        if isinstance(item['labels'], torch.Tensor):\n            train_labels.append(item['labels'])\n        else:\n            train_labels.append(torch.tensor(item['labels']))\n    \n    train_embeddings = torch.stack(train_embeddings)\n    train_labels = torch.stack(train_labels)\n    \n    train_dataset = TensorDataset(train_embeddings, train_labels)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    \n    # Process validation data\n    if isinstance(val_subset, DataLoader):\n        val_loader = val_subset\n        val_dataset = val_subset.dataset\n    else:\n        val_embeddings = []\n        val_labels = []\n        \n        for item in val_subset:\n            if isinstance(item['embedding'], torch.Tensor):\n                val_embeddings.append(item['embedding'])\n            else:\n                val_embeddings.append(torch.tensor(item['embedding']))\n                \n            if isinstance(item['labels'], torch.Tensor):\n                val_labels.append(item['labels'])\n            else:\n                val_labels.append(torch.tensor(item['labels']))\n        \n        val_embeddings = torch.stack(val_embeddings)\n        val_labels = torch.stack(val_labels)\n        \n        val_dataset = TensorDataset(val_embeddings, val_labels)\n        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    \n    # Loss function, optimizer and scheduler\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n    \n    # Training history\n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'val_auc': []\n    }\n    \n    # Use GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    \n    print(f\"Training new model from scratch on fair dataset with {len(train_dataset)} samples\")\n    print(f\"Using device: {device}\")\n    \n    # Training loop\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        \n        for inputs, targets in train_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            optimizer.zero_grad()\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * inputs.size(0)\n        \n        train_loss /= len(train_dataset)\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        val_preds = []\n        val_targets = []\n        \n        with torch.no_grad():\n            for inputs, targets in val_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n                \n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                \n                val_loss += loss.item() * inputs.size(0)\n                \n                val_preds.append(torch.sigmoid(outputs).cpu().numpy())\n                val_targets.append(targets.cpu().numpy())\n        \n        val_loss /= len(val_dataset)\n        \n        # Calculate AUC\n        val_preds = np.vstack(val_preds)\n        val_targets = np.vstack(val_targets)\n        \n        aucs = []\n        for i in range(val_targets.shape[1]):\n            if np.sum(val_targets[:, i] > 0) > 0 and np.sum(val_targets[:, i] == 0) > 0:\n                auc = roc_auc_score(val_targets[:, i], val_preds[:, i])\n                aucs.append(auc)\n        \n        val_auc = np.mean(aucs) if aucs else 0.0\n        \n        # Update history\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['val_auc'].append(val_auc)\n        \n        # Update learning rate\n        scheduler.step(val_loss)\n        \n        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n              f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}\")\n    \n    return model, history\n\n# Example usage with your code structure\nhidden_dims = [512, 256, 128]\ndropout_rate = 0.3\nlearning_rate = 0.001  # Higher learning rate for training from scratch\nweight_decay = 1e-5\nnum_epochs = 50  # More epochs for training from scratch\nlabel_columns = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', \n            'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', \n            'Atelectasis', 'Pneumothorax', 'Pleural Effusion', \n            'Pleural Other', 'Fracture', 'Support Devices', 'No Finding']\n\n# Create fair dataset\nfair_train_subset = create_fair_dataset(train_subset)\n\n# Train a new model from scratch\nmodel_from_scratch, training_history = train_from_scratch(\n    fair_train_subset=fair_train_subset,\n    val_subset=val_subset,\n    input_dim=1376,\n    hidden_dims=hidden_dims,\n    output_dim=len(label_columns),\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    num_epochs=num_epochs,\n    dropout_rate=dropout_rate\n)\n\n# Save the trained model\ntorch.save(model_from_scratch.state_dict(), \"fair_model_from_scratch.pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Adversary Models","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nimport time\nfrom tqdm import tqdm\nimport os\n\n# Define the neural network model\nclass MIMICClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.2):\n        \"\"\"\n        Simple feed-forward neural network for multi-label classification\n        \n        Args:\n            input_dim: Dimension of input embeddings\n            hidden_dims: List of hidden layer dimensions\n            output_dim: Number of output classes\n            dropout_rate: Dropout probability for regularization\n        \"\"\"\n        super(MIMICClassifier, self).__init__()\n        \n        # Create the layers\n        layers = []\n        \n        # Input layer\n        layers.append(nn.Linear(input_dim, hidden_dims[0]))\n        layers.append(nn.ReLU())\n        layers.append(nn.BatchNorm1d(hidden_dims[0]))\n        layers.append(nn.Dropout(dropout_rate))\n        \n        # Hidden layers\n        for i in range(len(hidden_dims)-1):\n            layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n            layers.append(nn.ReLU())\n            layers.append(nn.BatchNorm1d(hidden_dims[i+1]))\n            layers.append(nn.Dropout(dropout_rate))\n        \n        # Output layer\n        layers.append(nn.Linear(hidden_dims[-1], output_dim))\n        \n        # No activation function here since we're using BCEWithLogitsLoss\n        # which combines sigmoid and binary cross entropy\n        \n        self.model = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LinearVAE(nn.Module):\n    def __init__(self, input_dim=1376, hidden_dim=512, latent_dim=128):\n        super().__init__()\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.latent_dim = latent_dim\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.BatchNorm1d(hidden_dim // 2),\n            nn.ReLU()\n        )\n        \n        # Latent space parameters\n        self.fc_mu = nn.Linear(hidden_dim // 2, latent_dim)\n        self.fc_logvar = nn.Linear(hidden_dim // 2, latent_dim)\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim // 2),\n            nn.BatchNorm1d(hidden_dim // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 2, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, input_dim),\n            nn.Sigmoid()  # Use sigmoid if your embeddings are normalized between 0-1\n                          # or remove if using other normalization\n        )\n        \n    def encode(self, x):\n        hidden = self.encoder(x)\n        mu = self.fc_mu(hidden)\n        logvar = self.fc_logvar(hidden)\n        return mu, logvar\n    \n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        z = mu + eps * std\n        return z\n    \n    def decode(self, z):\n        return self.decoder(z)\n    \n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        reconstructed = self.decode(z)\n        return reconstructed, mu, logvar, z\n    \n    def get_latent(self, x):\n        \"\"\"Get latent representation without reconstruction\"\"\"\n        mu, logvar = self.encode(x)\n        return self.reparameterize(mu, logvar)\n\ndef VAE_LOSS(reconstructed, x, mu, logvar, kld_weight=0.005):\n    \"\"\"\n    VAE loss with KL divergence and reconstruction loss\n    \n    Args:\n        reconstructed: Reconstructed input from decoder\n        x: Original input \n        mu: Mean from encoder\n        logvar: Log variance from encoder\n        kld_weight: Weight for KL divergence term\n    \"\"\"\n    # Reconstruction loss (MSE or BCE depending on your data)\n    recon_loss = F.mse_loss(reconstructed, x, reduction='sum')\n    \n    # KL divergence: -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    \n    # Total loss\n    loss = recon_loss + kld_weight * kld_loss\n    \n    return loss, recon_loss, kld_loss\n    \n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, Subset # Added Subset\nimport torch.nn.functional as F # Added for loss functions\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score, mean_squared_error # Added MSE\nfrom sklearn.preprocessing import LabelEncoder # To handle categorical labels\nimport time\nfrom tqdm import tqdm\nimport os\nimport pickle\nimport copy # To copy models if needed\n\n\n# Path to processed data\ndata_path = \"/kaggle/input/mimic-embedding/processed_mimic_data\"\n\nclass ProcessedMIMICDataset(Dataset):\n    def __init__(self, data_path, data_format='pt', demographic_mappings=None):\n        self.data_path = data_path\n        self.data_format = data_format\n        self.demographic_mappings = demographic_mappings if demographic_mappings else {}\n\n        # --- Load data based on format ---\n        if data_format == 'pkl':\n            with open(os.path.join(data_path, \"all_data.pkl\"), 'rb') as f:\n                self.all_data = pickle.load(f)\n            self.embeddings = self.all_data['embeddings']\n            self.labels = self.all_data['labels']\n            self.subject_ids = self.all_data['subject_ids']\n            self.study_ids = self.all_data['study_ids']\n            self.demographics = self.all_data['demographics']\n\n        elif data_format == 'pt':\n            self.embeddings = torch.load(os.path.join(data_path, \"embeddings.pt\"), map_location='cpu') # Use map_location for flexibility\n            self.labels = torch.load(os.path.join(data_path, \"labels.pt\"), map_location='cpu')\n            ids_df = pd.read_csv(os.path.join(data_path, \"ids.csv\"))\n            self.subject_ids = ids_df['subject_id'].tolist()\n            self.study_ids = ids_df['study_id'].tolist()\n            with open(os.path.join(data_path, \"demographics.pkl\"), 'rb') as f:\n                # Demographics is often a list of dictionaries\n                self.demographics_raw = pickle.load(f)\n                # Pre-process demographics into a more usable format if needed\n                # For now, assume it's a list of dicts, one per sample\n\n        elif data_format == 'npy':\n            self.embeddings = np.load(os.path.join(data_path, \"embeddings.npy\"))\n            self.labels = np.load(os.path.join(data_path, \"labels.npy\"))\n            ids_df = pd.read_csv(os.path.join(data_path, \"ids.csv\"))\n            self.subject_ids = ids_df['subject_id'].tolist()\n            self.study_ids = ids_df['study_id'].tolist()\n            with open(os.path.join(data_path, \"demographics.pkl\"), 'rb') as f:\n                self.demographics_raw = pickle.load(f)\n\n        else:\n            raise ValueError(f\"Unsupported data format: {data_format}\")\n\n        print(f\"Loaded dataset from {data_path} with {len(self.embeddings)} samples\")\n\n        # --- Precompute demographic mappings if not provided ---\n        if not self.demographic_mappings:\n            print(\"Computing demographic mappings...\")\n            all_genders = [d['gender'] for d in self.demographics_raw]\n            all_insurances = [d['insurance'] for d in self.demographics_raw]\n            all_races = [d['race'] for d in self.demographics_raw]\n\n            self.demographic_mappings['gender'] = {label: i for i, label in enumerate(sorted(pd.Series(all_genders).unique()))}\n            self.demographic_mappings['insurance'] = {label: i for i, label in enumerate(sorted(pd.Series(all_insurances).unique()))}\n            self.demographic_mappings['race'] = {label: i for i, label in enumerate(sorted(pd.Series(all_races).unique()))}\n            print(\"Mappings computed:\", self.demographic_mappings)\n\n\n    def __len__(self):\n        return len(self.embeddings)\n\n    def __getitem__(self, idx):\n        if self.data_format == 'pt':\n            embedding = self.embeddings[idx]\n            labels = self.labels[idx]\n        else:\n            embedding = torch.tensor(self.embeddings[idx], dtype=torch.float32)\n            labels = torch.tensor(self.labels[idx], dtype=torch.float32) # Assuming labels are multi-label float\n\n        # Process demographics for the current item\n        demo_raw = self.demographics_raw[idx]\n        demographics_processed = {\n            'gender': torch.tensor(self.demographic_mappings['gender'].get(demo_raw['gender'], -1), dtype=torch.long), # Use .get for safety\n            'insurance': torch.tensor(self.demographic_mappings['insurance'].get(demo_raw['insurance'], -1), dtype=torch.long),\n            'race': torch.tensor(self.demographic_mappings['race'].get(demo_raw['race'], -1), dtype=torch.long),\n            'anchor_age': torch.tensor(demo_raw['anchor_age'], dtype=torch.float32)\n        }\n\n        # Handle potential missing values if necessary (e.g., if get returned -1)\n\n        return {\n            'embedding': embedding,\n            'labels': labels,\n            'subject_id': self.subject_ids[idx],\n            'study_id': self.study_ids[idx],\n            'demographics': demographics_processed # Return processed demographics\n        }\n\n# --- Define Models ---\n\nclass MIMICClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.2):\n        super(MIMICClassifier, self).__init__()\n        layers = []\n        layers.append(nn.Linear(input_dim, hidden_dims[0]))\n        layers.append(nn.ReLU())\n        layers.append(nn.BatchNorm1d(hidden_dims[0]))\n        layers.append(nn.Dropout(dropout_rate))\n        for i in range(len(hidden_dims)-1):\n            layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n            layers.append(nn.ReLU())\n            layers.append(nn.BatchNorm1d(hidden_dims[i+1]))\n            layers.append(nn.Dropout(dropout_rate))\n        layers.append(nn.Linear(hidden_dims[-1], output_dim))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)\n\n\nclass LinearVAE(nn.Module):\n    def __init__(self, input_dim=1376, hidden_dim=512, latent_dim=128):\n        super().__init__()\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.latent_dim = latent_dim\n\n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.BatchNorm1d(hidden_dim // 2),\n            nn.ReLU()\n        )\n        self.fc_mu = nn.Linear(hidden_dim // 2, latent_dim)\n        self.fc_logvar = nn.Linear(hidden_dim // 2, latent_dim)\n\n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim // 2),\n            nn.BatchNorm1d(hidden_dim // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 2, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, input_dim),\n            # nn.Sigmoid() # Sigmoid removed - usually better without for embeddings unless strictly 0-1 normalized\n        )\n\n    def encode(self, x):\n        hidden = self.encoder(x)\n        mu = self.fc_mu(hidden)\n        logvar = self.fc_logvar(hidden)\n        return mu, logvar\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        z = mu + eps * std\n        return z\n\n    def decode(self, z):\n        return self.decoder(z)\n\n    def forward(self, x):\n        mu, logvar = self.encode(x.view(-1, self.input_dim)) # Ensure correct shape\n        z = self.reparameterize(mu, logvar)\n        reconstructed = self.decode(z)\n        return reconstructed, mu, logvar, z\n\n    def get_latent(self, x):\n        mu, logvar = self.encode(x.view(-1, self.input_dim))\n        return self.reparameterize(mu, logvar)\n\n    def get_reconstructed(self, x):\n         mu, logvar = self.encode(x.view(-1, self.input_dim))\n         z = self.reparameterize(mu, logvar)\n         return self.decode(z)\n\n\nclass Adversary(nn.Module):\n    \"\"\" Predicts demographics from latent space \"\"\"\n    def __init__(self, latent_dim=128, hidden_dim=256, num_genders=2, num_insurances=3, num_races=7):\n        super().__init__()\n        self.layer1 = nn.Linear(latent_dim, hidden_dim)\n        self.bn1 = nn.BatchNorm1d(hidden_dim)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.3) # Slightly higher dropout for adversary\n\n        # Output heads for each demographic attribute\n        self.gender_head = nn.Linear(hidden_dim, num_genders) # Use num_genders (usually 2)\n        self.insurance_head = nn.Linear(hidden_dim, num_insurances)\n        self.race_head = nn.Linear(hidden_dim, num_races)\n        self.age_head = nn.Linear(hidden_dim, 1) # Regression for age\n\n    def forward(self, z):\n        shared = self.dropout(self.relu(self.bn1(self.layer1(z))))\n        gender_pred = self.gender_head(shared)\n        insurance_pred = self.insurance_head(shared)\n        race_pred = self.race_head(shared)\n        age_pred = self.age_head(shared)\n\n        return {\n            'gender': gender_pred,\n            'insurance': insurance_pred,\n            'race': race_pred,\n        }\n\n# --- Loss Functions ---\n\ndef VAE_LOSS(reconstructed, x, mu, logvar, kld_weight=1.0): # Adjusted default kld_weight\n    \"\"\" Calculate VAE Loss (Reconstruction + KL Divergence) \"\"\"\n    batch_size = x.size(0)\n    # Ensure shapes match\n    x_flat = x.view(batch_size, -1)\n    reconstructed_flat = reconstructed.view(batch_size, -1)\n\n    recon_loss = F.mse_loss(reconstructed_flat, x_flat, reduction='sum') / batch_size # Per sample avg\n    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / batch_size # Per sample avg\n\n    loss = recon_loss + kld_weight * kld_loss\n    return loss, recon_loss, kld_loss\n\ndef ADVERSARY_LOSS(adv_preds, true_demographics, device):\n    \"\"\" Calculate loss for the adversary \"\"\"\n    # Move true labels to the correct device\n    true_gender = true_demographics['gender'].to(device)\n    true_insurance = true_demographics['insurance'].to(device)\n    true_race = true_demographics['race'].to(device)\n    true_age = true_demographics['anchor_age'].to(device)\n\n    # --- Handle potential missing labels (-1) ---\n    # We will calculate loss only for valid labels\n    valid_gender_mask = true_gender != -1\n    valid_insurance_mask = true_insurance != -1\n    valid_race_mask = true_race != -1\n    # Assuming age is always present, if not add mask\n\n    loss_gender = F.cross_entropy(adv_preds['gender'][valid_gender_mask], true_gender[valid_gender_mask]) if valid_gender_mask.any() else torch.tensor(0.0).to(device)\n    loss_insurance = F.cross_entropy(adv_preds['insurance'][valid_insurance_mask], true_insurance[valid_insurance_mask]) if valid_insurance_mask.any() else torch.tensor(0.0).to(device)\n    loss_race = F.cross_entropy(adv_preds['race'][valid_race_mask], true_race[valid_race_mask]) if valid_race_mask.any() else torch.tensor(0.0).to(device)\n    # Combine losses (can add weights here if needed)\n    total_loss = loss_gender + loss_insurance + loss_race\n\n    return total_loss, {'gender': loss_gender, 'insurance': loss_insurance, 'race': loss_race}\n\n# --- Training Functions ---\n\ndef train_vae_adversarial(vae, adversary, train_loader, val_loader, vae_optimizer, adv_optimizer,\n                          num_epochs, device, kld_weight=1.0, adversary_weight=5.0, # adversary_weight > 1 typically needed\n                          log_interval=100, save_path='models'):\n    \"\"\" Trains the VAE with adversarial debiasing \"\"\"\n    vae.to(device)\n    adversary.to(device)\n    os.makedirs(save_path, exist_ok=True)\n    best_val_loss = float('inf')\n\n    print(f\"Starting adversarial VAE training for {num_epochs} epochs...\")\n    print(f\"KLD Weight: {kld_weight}, Adversary Weight: {adversary_weight}\")\n\n    for epoch in range(num_epochs):\n        vae.train()\n        adversary.train()\n        total_vae_loss_epoch = 0.0\n        total_recon_loss_epoch = 0.0\n        total_kld_loss_epoch = 0.0\n        total_adv_loss_epoch = 0.0\n        start_time = time.time()\n\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n        for batch_idx, batch in enumerate(progress_bar):\n            embeddings = batch['embedding'].to(device)\n            demographics = batch['demographics'] # Keep dict on CPU until needed in loss\n\n            # --- Adversary Training Step ---\n            adv_optimizer.zero_grad()\n            with torch.no_grad(): # Get latent space without tracking VAE grads\n                 _, mu, logvar, z = vae(embeddings)\n            # Detach z so VAE encoder is not updated during adversary's step\n            adv_preds = adversary(z.detach())\n            adv_loss, _ = ADVERSARY_LOSS(adv_preds, demographics, device)\n            adv_loss.backward()\n            adv_optimizer.step()\n            total_adv_loss_epoch += adv_loss.item()\n\n            # --- VAE Training Step ---\n            vae_optimizer.zero_grad()\n            reconstructed, mu, logvar, z_vae = vae(embeddings) # Forward pass through VAE\n            # Calculate VAE's reconstruction and KLD loss\n            vae_loss, recon_loss, kld_loss = VAE_LOSS(reconstructed, embeddings, mu, logvar, kld_weight)\n            # Calculate Adversary loss for the VAE's objective (fooling the adversary)\n            # IMPORTANT: Use z_vae (which tracks grads back to encoder) here\n            adv_preds_for_vae = adversary(z_vae)\n            adv_loss_for_vae, _ = ADVERSARY_LOSS(adv_preds_for_vae, demographics, device)\n            # VAE aims to minimize reconstruction/KLD AND maximize adversary loss\n            combined_vae_loss = vae_loss - adversary_weight * adv_loss_for_vae # Note the minus sign!\n            combined_vae_loss.backward()\n            vae_optimizer.step()\n\n            total_vae_loss_epoch += combined_vae_loss.item()\n            total_recon_loss_epoch += recon_loss.item()\n            total_kld_loss_epoch += kld_loss.item()\n\n            if batch_idx % log_interval == 0:\n                 progress_bar.set_postfix({\n                     'VAE Loss': f\"{combined_vae_loss.item():.4f}\",\n                     'Recon Loss': f\"{recon_loss.item():.4f}\",\n                     'KLD Loss': f\"{kld_loss.item():.4f}\",\n                     'Adv Loss': f\"{adv_loss.item():.4f}\"\n                 })\n\n        # --- Validation ---\n        vae.eval()\n        adversary.eval()\n        val_vae_loss = 0.0\n        val_adv_loss = 0.0\n        with torch.no_grad():\n            for batch in val_loader:\n                embeddings = batch['embedding'].to(device)\n                demographics = batch['demographics']\n                reconstructed, mu, logvar, z = vae(embeddings)\n                vae_loss, _, _ = VAE_LOSS(reconstructed, embeddings, mu, logvar, kld_weight)\n                adv_preds = adversary(z)\n                adv_loss, _ = ADVERSARY_LOSS(adv_preds, demographics, device)\n\n                # For validation, we often care about the non-adversarial VAE loss\n                # Or track both VAE loss and adversary performance separately\n                val_vae_loss += vae_loss.item() # Track basic VAE loss for model saving\n                val_adv_loss += adv_loss.item()\n\n        avg_train_vae_loss = total_vae_loss_epoch / len(train_loader)\n        avg_train_adv_loss = total_adv_loss_epoch / len(train_loader)\n        avg_val_vae_loss = val_vae_loss / len(val_loader)\n        avg_val_adv_loss = val_adv_loss / len(val_loader)\n        epoch_time = time.time() - start_time\n\n        print(f\"Epoch {epoch+1} Summary | Time: {epoch_time:.2f}s\")\n        print(f\"  Train VAE Loss: {avg_train_vae_loss:.4f} | Train Adv Loss: {avg_train_adv_loss:.4f}\")\n        print(f\"  Val VAE Loss  : {avg_val_vae_loss:.4f} | Val Adv Loss  : {avg_val_adv_loss:.4f}\")\n\n        # Save best model based on validation VAE loss (reconstruction focus)\n        if avg_val_vae_loss < best_val_loss:\n            best_val_loss = avg_val_vae_loss\n            torch.save(vae.state_dict(), os.path.join(save_path, 'best_vae_adversarial.pt'))\n            torch.save(adversary.state_dict(), os.path.join(save_path, 'best_adversary.pt'))\n            print(f\"  Saved best models with Val VAE Loss: {best_val_loss:.4f}\")\n\n    print(\"Adversarial VAE training finished.\")\n    # Load best models for returning\n    vae.load_state_dict(torch.load(os.path.join(save_path, 'best_vae_adversarial.pt')))\n    adversary.load_state_dict(torch.load(os.path.join(save_path, 'best_adversary.pt')))\n    return vae, adversary\n\n\ndef train_classifier(classifier, train_loader, val_loader, criterion, optimizer, num_epochs, device,\n                     log_interval=100, save_path='models', model_name='best_classifier.pt',\n                     use_debiased_embeddings=False, vae=None): # Added options for debiased input\n    \"\"\" Trains the downstream classifier \"\"\"\n    classifier.to(device)\n    if use_debiased_embeddings and vae is not None:\n        vae.to(device)\n        vae.eval() # VAE should be frozen if used for debiasing input\n        print(\"Training classifier on DEBIASED embeddings.\")\n    else:\n        print(\"Training classifier on ORIGINAL embeddings.\")\n\n    os.makedirs(save_path, exist_ok=True)\n    best_val_auc = 0.0\n\n    print(f\"Starting classifier training for {num_epochs} epochs...\")\n\n    for epoch in range(num_epochs):\n        classifier.train()\n        total_loss_epoch = 0.0\n        start_time = time.time()\n\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n        for batch_idx, batch in enumerate(progress_bar):\n            embeddings = batch['embedding'].to(device)\n            labels = batch['labels'].to(device) # Assuming labels are multi-label float (0 or 1)\n\n            # Get embeddings: original or debiased\n            if use_debiased_embeddings and vae is not None:\n                 with torch.no_grad(): # Don't train VAE here\n                    # Use reconstructed embeddings as debiased input\n                    input_embeddings = vae.get_reconstructed(embeddings)\n                    # Alternative: use latent space z directly if classifier input_dim matches latent_dim\n                    # input_embeddings = vae.get_latent(embeddings)\n            else:\n                input_embeddings = embeddings\n\n            # --- Classifier Training Step ---\n            optimizer.zero_grad()\n            outputs = classifier(input_embeddings)\n            loss = criterion(outputs, labels) # BCEWithLogitsLoss expects raw logits\n            loss.backward()\n            optimizer.step()\n\n            total_loss_epoch += loss.item()\n\n            if batch_idx % log_interval == 0:\n                 progress_bar.set_postfix({'Loss': f\"{loss.item():.4f}\"})\n\n        # --- Validation ---\n        avg_val_loss, avg_val_auc = evaluate_classifier(classifier, val_loader, criterion, device, use_debiased_embeddings, vae)\n        avg_train_loss = total_loss_epoch / len(train_loader)\n        epoch_time = time.time() - start_time\n\n        print(f\"Epoch {epoch+1} Summary | Time: {epoch_time:.2f}s\")\n        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n        print(f\"  Val Loss  : {avg_val_loss:.4f} | Val AUC  : {avg_val_auc:.4f}\")\n\n        # Save best model based on validation AUC\n        if avg_val_auc > best_val_auc:\n            best_val_auc = avg_val_auc\n            torch.save(classifier.state_dict(), os.path.join(save_path, model_name))\n            print(f\"  Saved best model with Val AUC: {best_val_auc:.4f}\")\n\n    print(\"Classifier training finished.\")\n    # Load best model\n    classifier.load_state_dict(torch.load(os.path.join(save_path, model_name)))\n    return classifier\n\n\ndef evaluate_classifier(classifier, data_loader, criterion, device, use_debiased_embeddings=False, vae=None):\n    \"\"\" Evaluates the classifier on a given dataset \"\"\"\n    classifier.eval()\n    if use_debiased_embeddings and vae is not None:\n        vae.to(device)\n        vae.eval()\n\n    total_loss = 0.0\n    all_labels = []\n    all_preds = []\n\n    with torch.no_grad():\n        for batch in data_loader:\n            embeddings = batch['embedding'].to(device)\n            labels = batch['labels'].to(device)\n\n            if use_debiased_embeddings and vae is not None:\n                input_embeddings = vae.get_reconstructed(embeddings)\n            else:\n                input_embeddings = embeddings\n\n            outputs = classifier(input_embeddings)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            # Store labels and predictions (probabilities) for AUC calculation\n            all_labels.append(labels.cpu().numpy())\n            all_preds.append(torch.sigmoid(outputs).cpu().numpy()) # Apply sigmoid to get probs\n\n    avg_loss = total_loss / len(data_loader)\n\n    # Concatenate results from all batches\n    all_labels = np.concatenate(all_labels, axis=0)\n    all_preds = np.concatenate(all_preds, axis=0)\n\n    # Calculate AUC (macro average over labels)\n    # Handle cases where a label might not be present or have only one class\n    auc_scores = []\n    for i in range(all_labels.shape[1]): # Iterate over each label column\n        try:\n            auc = roc_auc_score(all_labels[:, i], all_preds[:, i])\n            auc_scores.append(auc)\n        except ValueError:\n            # Handle error (e.g., only one class present in labels) - skip or assign 0.5?\n             # print(f\"Warning: Cannot compute AUC for label {i}, possibly only one class present.\")\n             auc_scores.append(np.nan) # Append NaN, handle later\n\n    avg_auc = np.nanmean(auc_scores) # Calculate mean ignoring NaNs\n\n    return avg_loss, avg_auc\n\n\n# --- Main Execution ---\nif __name__ == \"__main__\":\n\n    # --- Configuration ---\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {DEVICE}\")\n\n    VAE_LATENT_DIM = 128 \n    VAE_HIDDEN_DIM = 512\n    ADV_HIDDEN_DIM = 256\n    CLASSIFIER_INPUT_DIM = 1376 # Original embedding size\n    CLASSIFIER_HIDDEN_DIMS = [512, 256]\n    CLASSIFIER_OUTPUT_DIM = 14 # Number of labels\n    EMBEDDING_DIM = 1376\n\n    VAE_EPOCHS = 50\n    CLASSIFIER_EPOCHS = 30 \n    BATCH_SIZE = 128\n    VAE_LR = 1e-4\n    ADV_LR = 1e-4\n    CLASSIFIER_LR = 1e-3\n    KLD_WEIGHT = 1.0 # Weight for KL divergence in VAE loss\n    ADVERSARY_WEIGHT = 10.0 # How much to penalize VAE for demographic leakage\n\n    # --- Load Data ---\n    print(\"Loading datasets...\")\n    # Load train once to get mappings\n    full_train_dataset = ProcessedMIMICDataset(os.path.join(data_path, \"train\"), data_format='pt')\n    demographic_mappings = full_train_dataset.demographic_mappings\n\n    test_dataset = ProcessedMIMICDataset(os.path.join(data_path, \"test\"), data_format='pt', demographic_mappings=demographic_mappings)\n\n    # Create validation split using Subset\n    val_ratio = 0.1\n    dataset_size = len(full_train_dataset)\n    val_size = int(val_ratio * dataset_size)\n    train_size = dataset_size - val_size\n    indices = list(range(dataset_size))\n    np.random.seed(42) # for reproducibility\n    np.random.shuffle(indices)\n    train_indices, val_indices = indices[:train_size], indices[train_size:]\n\n    train_subset = Subset(full_train_dataset, train_indices)\n    val_subset = Subset(full_train_dataset, val_indices)\n\n    print(f\"Data loaded: Train={len(train_subset)}, Val={len(val_subset)}, Test={len(test_dataset)}\")\n\n    # Create data loaders\n    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n    # --- Initialize Models ---\n    print(\"Initializing models...\")\n    # Get number of unique classes for adversary heads from mappings\n    num_genders = len(demographic_mappings['gender'])\n    num_insurances = len(demographic_mappings['insurance'])\n    num_races = len(demographic_mappings['race'])\n\n    vae = LinearVAE(input_dim=EMBEDDING_DIM, hidden_dim=VAE_HIDDEN_DIM, latent_dim=VAE_LATENT_DIM)\n    adversary = Adversary(latent_dim=VAE_LATENT_DIM, hidden_dim=ADV_HIDDEN_DIM,\n                          num_genders=num_genders, num_insurances=num_insurances, num_races=num_races)\n    classifier_original = MIMICClassifier(input_dim=CLASSIFIER_INPUT_DIM, hidden_dims=CLASSIFIER_HIDDEN_DIMS, output_dim=CLASSIFIER_OUTPUT_DIM)\n    # Classifier for debiased embeddings might need different input dim if using latent space\n    classifier_debiased = MIMICClassifier(input_dim=CLASSIFIER_INPUT_DIM, hidden_dims=CLASSIFIER_HIDDEN_DIMS, output_dim=CLASSIFIER_OUTPUT_DIM) # Assuming reconstructed embeddings\n\n    # --- Optimizers and Criterion ---\n    vae_optimizer = optim.Adam(vae.parameters(), lr=VAE_LR)\n    adv_optimizer = optim.Adam(adversary.parameters(), lr=ADV_LR)\n    # Using BCEWithLogitsLoss for multi-label classification is standard\n    classifier_criterion = nn.BCEWithLogitsLoss()\n    classifier_orig_optimizer = optim.Adam(classifier_original.parameters(), lr=CLASSIFIER_LR)\n    classifier_debiased_optimizer = optim.Adam(classifier_debiased.parameters(), lr=CLASSIFIER_LR)\n\n    # --- Train Adversarial VAE ---\n    print(\"\\n--- Training Adversarial VAE ---\")\n    trained_vae, trained_adversary = train_vae_adversarial(\n        vae, adversary, train_loader, val_loader, vae_optimizer, adv_optimizer,\n        num_epochs=VAE_EPOCHS, device=DEVICE, kld_weight=KLD_WEIGHT,\n        adversary_weight=ADVERSARY_WEIGHT, save_path='models/vae_adv'\n    )\n\n    # --- Train Downstream Classifiers ---\n    # 1. Train on ORIGINAL embeddings\n    print(\"\\n--- Training Classifier on ORIGINAL Embeddings ---\")\n    trained_classifier_original = train_classifier(\n        classifier_original, train_loader, val_loader, classifier_criterion, classifier_orig_optimizer,\n        num_epochs=CLASSIFIER_EPOCHS, device=DEVICE, save_path='models/classifier',\n        model_name='best_classifier_original.pt', use_debiased_embeddings=False\n    )\n\n    # 2. Train on DEBIASED (reconstructed) embeddings\n    print(\"\\n--- Training Classifier on DEBIASED Embeddings ---\")\n    trained_classifier_debiased = train_classifier(\n        classifier_debiased, train_loader, val_loader, classifier_criterion, classifier_debiased_optimizer,\n        num_epochs=CLASSIFIER_EPOCHS, device=DEVICE, save_path='models/classifier',\n        model_name='best_classifier_debiased.pt', use_debiased_embeddings=True, vae=trained_vae # Pass the trained VAE\n    )\n\n    # --- Final Evaluation on Test Set ---\n    print(\"\\n--- Evaluating on Test Set ---\")\n\n    # Evaluate Original Classifier\n    test_loss_orig, test_auc_orig = evaluate_classifier(\n        trained_classifier_original, test_loader, classifier_criterion, DEVICE,\n        use_debiased_embeddings=False\n    )\n    print(f\"Classifier (Original Embeddings) Test Loss: {test_loss_orig:.4f}, Test AUC: {test_auc_orig:.4f}\")\n\n    # Evaluate Debiased Classifier\n    test_loss_debiased, test_auc_debiased = evaluate_classifier(\n        trained_classifier_debiased, test_loader, classifier_criterion, DEVICE,\n        use_debiased_embeddings=True, vae=trained_vae\n    )\n    print(f\"Classifier (Debiased Embeddings) Test Loss: {test_loss_debiased:.4f}, Test AUC: {test_auc_debiased:.4f}\")\n\n    # Optional: Evaluate how well the adversary predicts demographics on the test set\n    # (using the latent space from the trained VAE)\n    trained_vae.eval()\n    trained_adversary.eval()\n    test_adv_loss_total = 0\n    all_true_demos = {'gender': [], 'insurance': [], 'race': []}\n    all_pred_demos = {'gender': [], 'insurance': [], 'race': []}\n\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Evaluating Adversary on Test Set\", leave=False):\n            embeddings = batch['embedding'].to(DEVICE)\n            demographics = batch['demographics']\n            _, _, _, z = trained_vae(embeddings)\n            adv_preds = trained_adversary(z)\n            adv_loss, adv_losses_dict = ADVERSARY_LOSS(adv_preds, demographics, DEVICE)\n            test_adv_loss_total += adv_loss.item()\n\n            # Store true and predicted values for detailed analysis (accuracy, MSE etc.)\n            for key in all_true_demos.keys():\n                 valid_mask = demographics[key] != -1 # Use the same masking logic\n                 if valid_mask.any():\n                    all_true_demos[key].append(demographics[key][valid_mask].cpu().numpy())\n                    # Get predicted class index\n                    pred_classes = torch.argmax(adv_preds[key][valid_mask], dim=1)\n                    all_pred_demos[key].append(pred_classes.cpu().numpy())\n\n\n    avg_test_adv_loss = test_adv_loss_total / len(test_loader)\n    print(f\"\\nAdversary Final Test Loss: {avg_test_adv_loss:.4f}\")\n\n    # Calculate and print accuracy/MSE for demographics\n    for key in all_true_demos.keys():\n        if not all_true_demos[key]: continue # Skip if no valid data for this demographic\n        true_vals = np.concatenate(all_true_demos[key])\n        pred_vals = np.concatenate(all_pred_demos[key])\n        accuracy = np.mean(true_vals == pred_vals)\n        print(f\"  Adversary {key.capitalize()} Prediction Test Accuracy: {accuracy:.4f}\")\n\n    print(\"\\n--- Script Finished ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T01:43:22.055389Z","iopub.execute_input":"2025-03-31T01:43:22.055726Z","iopub.status.idle":"2025-03-31T02:16:18.167986Z","shell.execute_reply.started":"2025-03-31T01:43:22.055699Z","shell.execute_reply":"2025-03-31T02:16:18.166984Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading datasets...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-4-caa45f7f2a69>:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.embeddings = torch.load(os.path.join(data_path, \"embeddings.pt\"), map_location='cpu') # Use map_location for flexibility\n<ipython-input-4-caa45f7f2a69>:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.labels = torch.load(os.path.join(data_path, \"labels.pt\"), map_location='cpu')\n","output_type":"stream"},{"name":"stdout","text":"Loaded dataset from /kaggle/input/mimic-embedding/processed_mimic_data/train with 207314 samples\nComputing demographic mappings...\nMappings computed: {'gender': {'F': 0, 'M': 1}, 'insurance': {'Medicaid': 0, 'Medicare': 1, 'Other': 2}, 'race': {'AMERICAN INDIAN/ALASKA NATIVE': 0, 'ASIAN': 1, 'BLACK/AFRICAN AMERICAN': 2, 'HISPANIC/LATINO': 3, 'OTHER': 4, 'UNABLE TO OBTAIN': 5, 'UNKNOWN': 6, 'WHITE': 7}}\nLoaded dataset from /kaggle/input/mimic-embedding/processed_mimic_data/test with 21591 samples\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-4-caa45f7f2a69>:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.embeddings = torch.load(os.path.join(data_path, \"embeddings.pt\"), map_location='cpu') # Use map_location for flexibility\n<ipython-input-4-caa45f7f2a69>:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.labels = torch.load(os.path.join(data_path, \"labels.pt\"), map_location='cpu')\n","output_type":"stream"},{"name":"stdout","text":"Data loaded: Train=186583, Val=20731, Test=21591\nInitializing models...\n\n--- Training Adversarial VAE ---\nStarting adversarial VAE training for 50 epochs...\nKLD Weight: 1.0, Adversary Weight: 10.0\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Summary | Time: 22.88s\n  Train VAE Loss: 439.6012 | Train Adv Loss: 2.8074\n  Val VAE Loss  : 257.2622 | Val Adv Loss  : 2.6589\n  Saved best models with Val VAE Loss: 257.2622\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Summary | Time: 22.81s\n  Train VAE Loss: 219.5490 | Train Adv Loss: 2.6666\n  Val VAE Loss  : 229.5839 | Val Adv Loss  : 2.6245\n  Saved best models with Val VAE Loss: 229.5839\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Summary | Time: 22.58s\n  Train VAE Loss: 198.1468 | Train Adv Loss: 2.6385\n  Val VAE Loss  : 210.7411 | Val Adv Loss  : 2.6101\n  Saved best models with Val VAE Loss: 210.7411\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Summary | Time: 22.84s\n  Train VAE Loss: 182.0475 | Train Adv Loss: 2.6288\n  Val VAE Loss  : 196.8231 | Val Adv Loss  : 2.6117\n  Saved best models with Val VAE Loss: 196.8231\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Summary | Time: 22.91s\n  Train VAE Loss: 170.1875 | Train Adv Loss: 2.6240\n  Val VAE Loss  : 186.6139 | Val Adv Loss  : 2.6036\n  Saved best models with Val VAE Loss: 186.6139\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Summary | Time: 22.58s\n  Train VAE Loss: 161.8059 | Train Adv Loss: 2.6205\n  Val VAE Loss  : 179.6211 | Val Adv Loss  : 2.5953\n  Saved best models with Val VAE Loss: 179.6211\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Summary | Time: 22.79s\n  Train VAE Loss: 155.7518 | Train Adv Loss: 2.6135\n  Val VAE Loss  : 174.1435 | Val Adv Loss  : 2.5854\n  Saved best models with Val VAE Loss: 174.1435\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Summary | Time: 22.70s\n  Train VAE Loss: 151.6310 | Train Adv Loss: 2.6080\n  Val VAE Loss  : 170.4801 | Val Adv Loss  : 2.5801\n  Saved best models with Val VAE Loss: 170.4801\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Summary | Time: 22.70s\n  Train VAE Loss: 148.4655 | Train Adv Loss: 2.6044\n  Val VAE Loss  : 168.0477 | Val Adv Loss  : 2.5741\n  Saved best models with Val VAE Loss: 168.0477\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Summary | Time: 22.75s\n  Train VAE Loss: 146.0656 | Train Adv Loss: 2.6024\n  Val VAE Loss  : 166.1689 | Val Adv Loss  : 2.5781\n  Saved best models with Val VAE Loss: 166.1689\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Summary | Time: 22.93s\n  Train VAE Loss: 144.1415 | Train Adv Loss: 2.5974\n  Val VAE Loss  : 164.5329 | Val Adv Loss  : 2.5720\n  Saved best models with Val VAE Loss: 164.5329\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Summary | Time: 22.61s\n  Train VAE Loss: 142.6411 | Train Adv Loss: 2.5965\n  Val VAE Loss  : 162.9445 | Val Adv Loss  : 2.5711\n  Saved best models with Val VAE Loss: 162.9445\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Summary | Time: 22.69s\n  Train VAE Loss: 141.3231 | Train Adv Loss: 2.5933\n  Val VAE Loss  : 162.4651 | Val Adv Loss  : 2.5693\n  Saved best models with Val VAE Loss: 162.4651\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Summary | Time: 22.79s\n  Train VAE Loss: 140.2041 | Train Adv Loss: 2.5903\n  Val VAE Loss  : 161.2158 | Val Adv Loss  : 2.5652\n  Saved best models with Val VAE Loss: 161.2158\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Summary | Time: 22.93s\n  Train VAE Loss: 139.3136 | Train Adv Loss: 2.5902\n  Val VAE Loss  : 160.2457 | Val Adv Loss  : 2.5611\n  Saved best models with Val VAE Loss: 160.2457\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16 Summary | Time: 22.74s\n  Train VAE Loss: 138.5566 | Train Adv Loss: 2.5871\n  Val VAE Loss  : 159.8294 | Val Adv Loss  : 2.5644\n  Saved best models with Val VAE Loss: 159.8294\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17 Summary | Time: 22.65s\n  Train VAE Loss: 137.8285 | Train Adv Loss: 2.5868\n  Val VAE Loss  : 159.4091 | Val Adv Loss  : 2.5603\n  Saved best models with Val VAE Loss: 159.4091\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18 Summary | Time: 22.82s\n  Train VAE Loss: 137.1714 | Train Adv Loss: 2.5829\n  Val VAE Loss  : 158.1226 | Val Adv Loss  : 2.5546\n  Saved best models with Val VAE Loss: 158.1226\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19 Summary | Time: 22.65s\n  Train VAE Loss: 136.6484 | Train Adv Loss: 2.5817\n  Val VAE Loss  : 157.9289 | Val Adv Loss  : 2.5542\n  Saved best models with Val VAE Loss: 157.9289\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20 Summary | Time: 22.53s\n  Train VAE Loss: 136.1526 | Train Adv Loss: 2.5779\n  Val VAE Loss  : 157.2107 | Val Adv Loss  : 2.5525\n  Saved best models with Val VAE Loss: 157.2107\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21 Summary | Time: 22.73s\n  Train VAE Loss: 135.6436 | Train Adv Loss: 2.5754\n  Val VAE Loss  : 156.6194 | Val Adv Loss  : 2.5515\n  Saved best models with Val VAE Loss: 156.6194\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22 Summary | Time: 22.83s\n  Train VAE Loss: 135.3284 | Train Adv Loss: 2.5734\n  Val VAE Loss  : 156.0278 | Val Adv Loss  : 2.5428\n  Saved best models with Val VAE Loss: 156.0278\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23 Summary | Time: 22.86s\n  Train VAE Loss: 135.0027 | Train Adv Loss: 2.5713\n  Val VAE Loss  : 156.3340 | Val Adv Loss  : 2.5416\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24 Summary | Time: 22.84s\n  Train VAE Loss: 134.5364 | Train Adv Loss: 2.5670\n  Val VAE Loss  : 155.6024 | Val Adv Loss  : 2.5377\n  Saved best models with Val VAE Loss: 155.6024\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25 Summary | Time: 22.75s\n  Train VAE Loss: 134.1848 | Train Adv Loss: 2.5662\n  Val VAE Loss  : 155.2099 | Val Adv Loss  : 2.5387\n  Saved best models with Val VAE Loss: 155.2099\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26 Summary | Time: 22.89s\n  Train VAE Loss: 133.8772 | Train Adv Loss: 2.5640\n  Val VAE Loss  : 155.6491 | Val Adv Loss  : 2.5360\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27 Summary | Time: 22.70s\n  Train VAE Loss: 133.6078 | Train Adv Loss: 2.5628\n  Val VAE Loss  : 155.2398 | Val Adv Loss  : 2.5333\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28 Summary | Time: 22.97s\n  Train VAE Loss: 133.2900 | Train Adv Loss: 2.5610\n  Val VAE Loss  : 154.3463 | Val Adv Loss  : 2.5288\n  Saved best models with Val VAE Loss: 154.3463\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29 Summary | Time: 22.81s\n  Train VAE Loss: 132.9565 | Train Adv Loss: 2.5594\n  Val VAE Loss  : 154.2978 | Val Adv Loss  : 2.5314\n  Saved best models with Val VAE Loss: 154.2978\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30 Summary | Time: 22.48s\n  Train VAE Loss: 132.7996 | Train Adv Loss: 2.5594\n  Val VAE Loss  : 154.5430 | Val Adv Loss  : 2.5288\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31 Summary | Time: 22.70s\n  Train VAE Loss: 132.4689 | Train Adv Loss: 2.5579\n  Val VAE Loss  : 153.8357 | Val Adv Loss  : 2.5272\n  Saved best models with Val VAE Loss: 153.8357\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32 Summary | Time: 22.77s\n  Train VAE Loss: 132.1838 | Train Adv Loss: 2.5588\n  Val VAE Loss  : 154.3584 | Val Adv Loss  : 2.5223\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33 Summary | Time: 22.62s\n  Train VAE Loss: 131.9648 | Train Adv Loss: 2.5575\n  Val VAE Loss  : 153.9225 | Val Adv Loss  : 2.5239\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34 Summary | Time: 22.55s\n  Train VAE Loss: 131.7948 | Train Adv Loss: 2.5562\n  Val VAE Loss  : 153.0954 | Val Adv Loss  : 2.5288\n  Saved best models with Val VAE Loss: 153.0954\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35 Summary | Time: 22.82s\n  Train VAE Loss: 131.5300 | Train Adv Loss: 2.5569\n  Val VAE Loss  : 153.5816 | Val Adv Loss  : 2.5307\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 36 Summary | Time: 22.77s\n  Train VAE Loss: 131.3298 | Train Adv Loss: 2.5566\n  Val VAE Loss  : 152.5787 | Val Adv Loss  : 2.5257\n  Saved best models with Val VAE Loss: 152.5787\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 37 Summary | Time: 23.12s\n  Train VAE Loss: 131.0881 | Train Adv Loss: 2.5565\n  Val VAE Loss  : 152.8988 | Val Adv Loss  : 2.5238\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 38 Summary | Time: 22.78s\n  Train VAE Loss: 130.9157 | Train Adv Loss: 2.5579\n  Val VAE Loss  : 152.6945 | Val Adv Loss  : 2.5247\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 39 Summary | Time: 22.77s\n  Train VAE Loss: 130.8138 | Train Adv Loss: 2.5554\n  Val VAE Loss  : 152.6319 | Val Adv Loss  : 2.5237\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 40 Summary | Time: 22.80s\n  Train VAE Loss: 130.6246 | Train Adv Loss: 2.5557\n  Val VAE Loss  : 152.1912 | Val Adv Loss  : 2.5244\n  Saved best models with Val VAE Loss: 152.1912\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 41 Summary | Time: 22.55s\n  Train VAE Loss: 130.4412 | Train Adv Loss: 2.5557\n  Val VAE Loss  : 151.7469 | Val Adv Loss  : 2.5227\n  Saved best models with Val VAE Loss: 151.7469\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 42 Summary | Time: 22.79s\n  Train VAE Loss: 130.2314 | Train Adv Loss: 2.5566\n  Val VAE Loss  : 151.8168 | Val Adv Loss  : 2.5244\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 43 Summary | Time: 22.76s\n  Train VAE Loss: 130.0816 | Train Adv Loss: 2.5559\n  Val VAE Loss  : 151.7312 | Val Adv Loss  : 2.5265\n  Saved best models with Val VAE Loss: 151.7312\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 44 Summary | Time: 22.45s\n  Train VAE Loss: 130.0748 | Train Adv Loss: 2.5559\n  Val VAE Loss  : 151.7638 | Val Adv Loss  : 2.5264\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 45 Summary | Time: 22.59s\n  Train VAE Loss: 129.8252 | Train Adv Loss: 2.5558\n  Val VAE Loss  : 151.5553 | Val Adv Loss  : 2.5236\n  Saved best models with Val VAE Loss: 151.5553\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 46 Summary | Time: 22.80s\n  Train VAE Loss: 129.6323 | Train Adv Loss: 2.5541\n  Val VAE Loss  : 151.0754 | Val Adv Loss  : 2.5230\n  Saved best models with Val VAE Loss: 151.0754\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 47 Summary | Time: 22.66s\n  Train VAE Loss: 129.5246 | Train Adv Loss: 2.5539\n  Val VAE Loss  : 151.0880 | Val Adv Loss  : 2.5226\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 48 Summary | Time: 22.62s\n  Train VAE Loss: 129.4947 | Train Adv Loss: 2.5532\n  Val VAE Loss  : 151.0502 | Val Adv Loss  : 2.5244\n  Saved best models with Val VAE Loss: 151.0502\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 49 Summary | Time: 22.60s\n  Train VAE Loss: 129.2381 | Train Adv Loss: 2.5531\n  Val VAE Loss  : 151.2663 | Val Adv Loss  : 2.5312\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-4-caa45f7f2a69>:359: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  vae.load_state_dict(torch.load(os.path.join(save_path, 'best_vae_adversarial.pt')))\n<ipython-input-4-caa45f7f2a69>:360: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  adversary.load_state_dict(torch.load(os.path.join(save_path, 'best_adversary.pt')))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50 Summary | Time: 23.08s\n  Train VAE Loss: 129.1322 | Train Adv Loss: 2.5536\n  Val VAE Loss  : 150.6480 | Val Adv Loss  : 2.5209\n  Saved best models with Val VAE Loss: 150.6480\nAdversarial VAE training finished.\n\n--- Training Classifier on ORIGINAL Embeddings ---\nTraining classifier on ORIGINAL embeddings.\nStarting classifier training for 30 epochs...\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Summary | Time: 14.05s\n  Train Loss: 0.2821\n  Val Loss  : 0.2546 | Val AUC  : 0.8143\n  Saved best model with Val AUC: 0.8143\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Summary | Time: 13.79s\n  Train Loss: 0.2552\n  Val Loss  : 0.2502 | Val AUC  : 0.8232\n  Saved best model with Val AUC: 0.8232\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Summary | Time: 14.16s\n  Train Loss: 0.2533\n  Val Loss  : 0.2496 | Val AUC  : 0.8242\n  Saved best model with Val AUC: 0.8242\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Summary | Time: 14.10s\n  Train Loss: 0.2522\n  Val Loss  : 0.2489 | Val AUC  : 0.8281\n  Saved best model with Val AUC: 0.8281\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Summary | Time: 14.46s\n  Train Loss: 0.2513\n  Val Loss  : 0.2508 | Val AUC  : 0.8288\n  Saved best model with Val AUC: 0.8288\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Summary | Time: 13.99s\n  Train Loss: 0.2506\n  Val Loss  : 0.2474 | Val AUC  : 0.8310\n  Saved best model with Val AUC: 0.8310\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Summary | Time: 14.23s\n  Train Loss: 0.2502\n  Val Loss  : 0.2478 | Val AUC  : 0.8305\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Summary | Time: 13.66s\n  Train Loss: 0.2497\n  Val Loss  : 0.2478 | Val AUC  : 0.8308\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Summary | Time: 13.89s\n  Train Loss: 0.2492\n  Val Loss  : 0.2487 | Val AUC  : 0.8300\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Summary | Time: 14.09s\n  Train Loss: 0.2488\n  Val Loss  : 0.2462 | Val AUC  : 0.8315\n  Saved best model with Val AUC: 0.8315\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Summary | Time: 13.88s\n  Train Loss: 0.2485\n  Val Loss  : 0.2505 | Val AUC  : 0.8322\n  Saved best model with Val AUC: 0.8322\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Summary | Time: 13.85s\n  Train Loss: 0.2483\n  Val Loss  : 0.2472 | Val AUC  : 0.8329\n  Saved best model with Val AUC: 0.8329\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Summary | Time: 13.54s\n  Train Loss: 0.2481\n  Val Loss  : 0.2459 | Val AUC  : 0.8342\n  Saved best model with Val AUC: 0.8342\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Summary | Time: 13.85s\n  Train Loss: 0.2479\n  Val Loss  : 0.2472 | Val AUC  : 0.8329\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Summary | Time: 14.15s\n  Train Loss: 0.2479\n  Val Loss  : 0.2466 | Val AUC  : 0.8339\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16 Summary | Time: 13.91s\n  Train Loss: 0.2476\n  Val Loss  : 0.3052 | Val AUC  : 0.8336\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17 Summary | Time: 13.66s\n  Train Loss: 0.2475\n  Val Loss  : 0.2476 | Val AUC  : 0.8351\n  Saved best model with Val AUC: 0.8351\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18 Summary | Time: 14.24s\n  Train Loss: 0.2473\n  Val Loss  : 0.2468 | Val AUC  : 0.8351\n  Saved best model with Val AUC: 0.8351\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19 Summary | Time: 14.16s\n  Train Loss: 0.2468\n  Val Loss  : 0.2478 | Val AUC  : 0.8339\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20 Summary | Time: 13.96s\n  Train Loss: 0.2469\n  Val Loss  : 0.2471 | Val AUC  : 0.8346\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21 Summary | Time: 14.04s\n  Train Loss: 0.2467\n  Val Loss  : 0.2486 | Val AUC  : 0.8352\n  Saved best model with Val AUC: 0.8352\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22 Summary | Time: 13.37s\n  Train Loss: 0.2465\n  Val Loss  : 0.2455 | Val AUC  : 0.8352\n  Saved best model with Val AUC: 0.8352\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23 Summary | Time: 13.18s\n  Train Loss: 0.2465\n  Val Loss  : 0.2456 | Val AUC  : 0.8344\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24 Summary | Time: 13.28s\n  Train Loss: 0.2461\n  Val Loss  : 0.2466 | Val AUC  : 0.8339\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25 Summary | Time: 13.14s\n  Train Loss: 0.2460\n  Val Loss  : 0.2460 | Val AUC  : 0.8348\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26 Summary | Time: 13.11s\n  Train Loss: 0.2459\n  Val Loss  : 0.2455 | Val AUC  : 0.8361\n  Saved best model with Val AUC: 0.8361\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27 Summary | Time: 13.05s\n  Train Loss: 0.2456\n  Val Loss  : 0.2451 | Val AUC  : 0.8358\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28 Summary | Time: 13.30s\n  Train Loss: 0.2456\n  Val Loss  : 0.2456 | Val AUC  : 0.8348\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29 Summary | Time: 13.28s\n  Train Loss: 0.2454\n  Val Loss  : 0.2454 | Val AUC  : 0.8355\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-4-caa45f7f2a69>:430: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  classifier.load_state_dict(torch.load(os.path.join(save_path, model_name)))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 Summary | Time: 12.87s\n  Train Loss: 0.2454\n  Val Loss  : 0.2457 | Val AUC  : 0.8356\nClassifier training finished.\n\n--- Training Classifier on DEBIASED Embeddings ---\nTraining classifier on DEBIASED embeddings.\nStarting classifier training for 30 epochs...\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Summary | Time: 14.06s\n  Train Loss: 0.2852\n  Val Loss  : 0.2569 | Val AUC  : 0.8055\n  Saved best model with Val AUC: 0.8055\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Summary | Time: 13.89s\n  Train Loss: 0.2602\n  Val Loss  : 0.2551 | Val AUC  : 0.8046\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Summary | Time: 14.02s\n  Train Loss: 0.2591\n  Val Loss  : 0.2557 | Val AUC  : 0.8109\n  Saved best model with Val AUC: 0.8109\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Summary | Time: 13.88s\n  Train Loss: 0.2585\n  Val Loss  : 0.2553 | Val AUC  : 0.8121\n  Saved best model with Val AUC: 0.8121\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Summary | Time: 13.96s\n  Train Loss: 0.2582\n  Val Loss  : 0.2556 | Val AUC  : 0.8134\n  Saved best model with Val AUC: 0.8134\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Summary | Time: 14.00s\n  Train Loss: 0.2579\n  Val Loss  : 0.2547 | Val AUC  : 0.8125\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Summary | Time: 13.80s\n  Train Loss: 0.2577\n  Val Loss  : 0.2529 | Val AUC  : 0.8124\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Summary | Time: 13.95s\n  Train Loss: 0.2574\n  Val Loss  : 0.2528 | Val AUC  : 0.8137\n  Saved best model with Val AUC: 0.8137\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Summary | Time: 14.05s\n  Train Loss: 0.2572\n  Val Loss  : 0.2542 | Val AUC  : 0.8133\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Summary | Time: 13.99s\n  Train Loss: 0.2571\n  Val Loss  : 0.2528 | Val AUC  : 0.8142\n  Saved best model with Val AUC: 0.8142\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Summary | Time: 14.08s\n  Train Loss: 0.2573\n  Val Loss  : 0.2854 | Val AUC  : 0.8128\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Summary | Time: 14.22s\n  Train Loss: 0.2570\n  Val Loss  : 0.2527 | Val AUC  : 0.8133\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Summary | Time: 14.03s\n  Train Loss: 0.2568\n  Val Loss  : 0.2528 | Val AUC  : 0.8145\n  Saved best model with Val AUC: 0.8145\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Summary | Time: 13.95s\n  Train Loss: 0.2567\n  Val Loss  : 0.2529 | Val AUC  : 0.8152\n  Saved best model with Val AUC: 0.8152\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Summary | Time: 14.12s\n  Train Loss: 0.2567\n  Val Loss  : 0.2983 | Val AUC  : 0.8140\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16 Summary | Time: 14.09s\n  Train Loss: 0.2565\n  Val Loss  : 0.2717 | Val AUC  : 0.8163\n  Saved best model with Val AUC: 0.8163\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17 Summary | Time: 14.05s\n  Train Loss: 0.2564\n  Val Loss  : 0.2524 | Val AUC  : 0.8150\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18 Summary | Time: 13.71s\n  Train Loss: 0.2564\n  Val Loss  : 0.2522 | Val AUC  : 0.8145\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19 Summary | Time: 14.03s\n  Train Loss: 0.2562\n  Val Loss  : 0.2519 | Val AUC  : 0.8152\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20 Summary | Time: 13.90s\n  Train Loss: 0.2562\n  Val Loss  : 0.2519 | Val AUC  : 0.8157\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21 Summary | Time: 14.09s\n  Train Loss: 0.2561\n  Val Loss  : 0.2521 | Val AUC  : 0.8159\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22 Summary | Time: 13.91s\n  Train Loss: 0.2562\n  Val Loss  : 0.2516 | Val AUC  : 0.8163\n  Saved best model with Val AUC: 0.8163\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23 Summary | Time: 13.94s\n  Train Loss: 0.2560\n  Val Loss  : 0.2517 | Val AUC  : 0.8146\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24 Summary | Time: 13.97s\n  Train Loss: 0.2557\n  Val Loss  : 0.2512 | Val AUC  : 0.8169\n  Saved best model with Val AUC: 0.8169\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25 Summary | Time: 14.03s\n  Train Loss: 0.2560\n  Val Loss  : 0.2523 | Val AUC  : 0.8160\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26 Summary | Time: 14.15s\n  Train Loss: 0.2558\n  Val Loss  : 0.2517 | Val AUC  : 0.8161\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27 Summary | Time: 13.98s\n  Train Loss: 0.2557\n  Val Loss  : 0.2521 | Val AUC  : 0.8155\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28 Summary | Time: 14.02s\n  Train Loss: 0.2557\n  Val Loss  : 0.2524 | Val AUC  : 0.8161\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29 Summary | Time: 13.85s\n  Train Loss: 0.2556\n  Val Loss  : 0.2515 | Val AUC  : 0.8163\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30 Summary | Time: 13.70s\n  Train Loss: 0.2556\n  Val Loss  : 0.2520 | Val AUC  : 0.8160\nClassifier training finished.\n\n--- Evaluating on Test Set ---\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-4-caa45f7f2a69>:430: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  classifier.load_state_dict(torch.load(os.path.join(save_path, model_name)))\n","output_type":"stream"},{"name":"stdout","text":"Classifier (Original Embeddings) Test Loss: 0.2451, Test AUC: 0.8347\nClassifier (Debiased Embeddings) Test Loss: 0.2511, Test AUC: 0.8187\n","output_type":"stream"},{"name":"stderr","text":"                                                                                    ","output_type":"stream"},{"name":"stdout","text":"\nAdversary Final Test Loss: 2.5136\n  Adversary Gender Prediction Test Accuracy: 0.6743\n  Adversary Insurance Prediction Test Accuracy: 0.5946\n  Adversary Race Prediction Test Accuracy: 0.6755\n\n--- Script Finished ---\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}